{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# íŠ¹í—ˆÂ·ì‹¤ìš© ê³µê°œÂ·ë“±ë¡ê³µë³´(DARTì— ì—†ëŠ” ê¸°ì—…ë„ í¬í•¨)\n",
    "- applicantNameê³¼ company_name ì¼ì¹˜í•˜ê²Œ\n",
    "- ì•ë’¤ ê³µë°± ì œê±°, ëª¨ë“  ê³µë°± ì œê±°, ëŒ€ì†Œë¬¸ì í†µì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# =========================================================\n",
    "# 1. ê¸°ë³¸ ì„¤ì •\n",
    "# =========================================================\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"KIPRIS_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"KIPRIS_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "BASE_URL = (\n",
    "    \"http://plus.kipris.or.kr/kipo-api/\"\n",
    "    \"kipi/patUtiModInfoSearchSevice/getAdvancedSearch\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 2. ëª¨ë“  ê¸°ì—…\n",
    "# =========================================================\n",
    "company_df = pd.read_csv('./data/ì†Œë¶€ì¥_ê¸°ì—…_DART_ë§¤í•‘.csv', encoding='cp949')\n",
    "company_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_df[\"dart_corp_code\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(company_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 3. ê¸°ì—…ëª… ì •ê·œí™” í•¨ìˆ˜\n",
    "#    - ê³µë°± ì œê±°\n",
    "#    - (ì£¼), ì£¼ì‹íšŒì‚¬, ãˆœ ì œê±°\n",
    "#    - ëŒ€ì†Œë¬¸ì í†µì¼\n",
    "# =========================================================\n",
    "def normalize_name_for_match(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.lower()\n",
    "    name = name.strip()\n",
    "    name = re.sub(r\"\\s+\", \"\", name)\n",
    "    name = re.sub(r\"\\(ì£¼\\)|ãˆœ|ì£¼ì‹íšŒì‚¬\", \"\", name)\n",
    "    return name\n",
    "\n",
    "# =========================================================\n",
    "# 4. ê¸°ì—… 1ê³³ íŠ¹í—ˆ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ (KIPRIS)\n",
    "# =========================================================\n",
    "def fetch_patent_by_company(company_name, page_no=1, num_rows=50):\n",
    "    params = {\n",
    "        \"ServiceKey\": API_KEY,     \n",
    "        \"applicant\": company_name,\n",
    "        \"patent\": \"true\",\n",
    "        \"utility\": \"true\",\n",
    "        \"numOfRows\": num_rows,\n",
    "        \"pageNo\": page_no\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params, timeout=10)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = xmltodict.parse(response.text)\n",
    "\n",
    "    try:\n",
    "        items = data[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "    except (KeyError, TypeError):\n",
    "        return []\n",
    "\n",
    "    if isinstance(items, dict):\n",
    "        items = [items]\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# 5. ê¸°ì—… ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ (ì „ì²´ ê¸°ì—…ë§Œ)\n",
    "# =========================================================\n",
    "all_results = []\n",
    "\n",
    "company_list = company_df[\"title\"].unique()\n",
    "\n",
    "for company in tqdm(company_list, total=len(company_list), desc=\"ê¸°ì—…ë³„ íŠ¹í—ˆ ìˆ˜ì§‘\"):\n",
    "    print(f\"ìˆ˜ì§‘ ì¤‘: {company}\")\n",
    "\n",
    "    patents = fetch_patent_by_company(company)\n",
    "\n",
    "    for p in patents:\n",
    "        p[\"company_name\"] = company  # ê²€ìƒ‰ ê¸°ì¤€ ê¸°ì—…ëª…\n",
    "        all_results.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 6. DataFrame ìƒì„±\n",
    "# =========================================================\n",
    "patent_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"íŠ¹í—ˆ ìˆ˜ì§‘ ëŒ€ìƒ ê¸°ì—… ìˆ˜:\", patent_df[\"company_name\"].nunique())\n",
    "print(\"ì „ì²´ ìˆ˜ì§‘ íŠ¹í—ˆ ìˆ˜:\", len(patent_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 7. company_name / applicantName ì •ê·œí™” ì»¬ëŸ¼ ì¶”ê°€\n",
    "# =========================================================\n",
    "patent_df[\"company_norm\"] = patent_df[\"company_name\"].apply(normalize_name_for_match)\n",
    "patent_df[\"applicant_norm\"] = patent_df[\"applicantName\"].apply(normalize_name_for_match)\n",
    "\n",
    "# =========================================================\n",
    "# 8. ë™ì¼ ê¸°ì—… íŠ¹í—ˆë§Œ í•„í„°ë§\n",
    "#    (ê³µë°±Â·íšŒì‚¬í˜•íƒœ ì°¨ì´ë§Œ í—ˆìš©)\n",
    "# =========================================================\n",
    "matched_df = patent_df[\n",
    "    patent_df[\"company_norm\"] == patent_df[\"applicant_norm\"]\n",
    "].copy()\n",
    "\n",
    "# =========================================================\n",
    "# 9. ê²°ê³¼ í™•ì¸\n",
    "# =========================================================\n",
    "print(\"ë™ì¼ ê¸°ì—… íŠ¹í—ˆ ìˆ˜:\", len(matched_df))\n",
    "\n",
    "matched_df[[\"company_name\", \"applicantName\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df = matched_df[\n",
    "    [\n",
    "        \"ipcNumber\",\n",
    "        \"applicationDate\",\n",
    "        \"astrtCont\",\n",
    "        \"applicationNumber\",\n",
    "        \"indexNo\",\n",
    "        \"registerStatus\",\n",
    "        \"inventionTitle\",\n",
    "        \"applicantName\"    ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df = matched_df.rename(columns={\n",
    "    \"ipcNumber\": \"ipcNumber(IPCì½”ë“œ)\",\n",
    "    \"applicationDate\": \"applicationDate(ì¶œì›ì¼ì)\",\n",
    "    \"astrtCont\": \"astrtCont(ì´ˆë¡)\",\n",
    "    \"applicationNumber\": \"applicationNumber(ì¶œì›ë²ˆí˜¸)\",\n",
    "    \"indexNo\": \"indexNo(ì¼ë ¨ë²ˆí˜¸)\",\n",
    "    \"registerStatus\": \"registerStatus(ë“±ë¡ìƒíƒœ)\",\n",
    "    \"inventionTitle\": \"inventionTitle(ë°œëª…ì˜ëª…ì¹­)\",\n",
    "    \"applicantName\": \"applicantName(ì¶œì›ì¸ëª…)\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 10. CSV ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "matched_df.to_csv(\"./preprocessed_data/company_patent_all_2.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 11. Excel ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "matched_df.to_excel(\"./preprocessed_data/company_patent_all_2.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# DART mapping ëœ ì†Œë¶€ì¥ ê¸°ì—…\n",
    "- `dart_corp_code` ê°€ null ì¸ ê¸°ì—…ëª…ì€ ë‚ ë¦¬ê¸°\n",
    "- ê¸°ì—…ëª…(`title`)ë¡œ íŠ¹í—ˆ ë§¤í•‘ ì‹œí‚¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#=====================\n",
    "\n",
    "company_df = pd.read_csv('./data/ì†Œë¶€ì¥_ê¸°ì—…_DARTë§¤í•‘_ê¸°ì—…ëª…ì •ì œ.csv', encoding='cp949')\n",
    "company_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_nan = company_df[company_df['dart_corp_code'].notna()]\n",
    "remove_nan.shape[0] # DARTì— ë‚˜ì™€ìˆëŠ” ê¸°ì—…ì€ ì´ 478 ê°œì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_nan[\"title\"].nunique()   # 469 ê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title ê¸°ì¤€ ì¤‘ë³µëœ ê¸°ì—…ëª…ë§Œ ì¶”ì¶œ\n",
    "duplicate_titles = remove_nan[\n",
    "    remove_nan[\"title\"].duplicated(keep=False)\n",
    "].sort_values(\"title\")\n",
    "\n",
    "duplicate_titles[[\"title\", \"dart_corp_code\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## íŠ¹í—ˆÂ·ì‹¤ìš© ê³µê°œÂ·ë“±ë¡ê³µë³´(DARTì— ì—†ëŠ” ê¸°ì—…ì€ ì œì™¸)\n",
    "- applicantNameê³¼ company_name ì¼ì¹˜í•˜ê²Œ\n",
    "- ì•ë’¤ ê³µë°± ì œê±°, ëª¨ë“  ê³µë°± ì œê±°, ëŒ€ì†Œë¬¸ì í†µì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "#====================================\n",
    "# 1. ê¸°ë³¸ ì„¤ì •\n",
    "#====================================\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"KIPRIS_API_KEY\")\n",
    "\n",
    "BASE_URL = (\n",
    "    \"http://plus.kipris.or.kr/kipo-api/\"\n",
    "    \"kipi/patUtiModInfoSearchSevice/getAdvancedSearch\"\n",
    ")\n",
    "\n",
    "#====================================\n",
    "# 2. ê¸°ì—…ëª… ì •ê·œí™” í•¨ìˆ˜ (ê³µë°±, (ì£¼) ì œê±°ìš©)\n",
    "#====================================\n",
    "def normalize_name_for_match(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.lower()\n",
    "    name = name.strip()\n",
    "    name = re.sub(r\"\\s+\", \"\", name)              # ëª¨ë“  ê³µë°± ì œê±°\n",
    "    name = re.sub(r\"\\(ì£¼\\)|ãˆœ|ì£¼ì‹íšŒì‚¬\", \"\", name)\n",
    "    return name\n",
    "\n",
    "#====================================\n",
    "# 3. ê¸°ì—…ì˜ í•œ ê³³ íŠ¹í—ˆ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "#====================================\n",
    "def fetch_patent_by_company(company_name, page_no=1, num_rows=50):\n",
    "    params = {\n",
    "        \"ServiceKey\": API_KEY,          \n",
    "        \"applicant\": company_name,      # ê²€ìƒ‰ ê¸°ì¤€ ê¸°ì—…ëª…\n",
    "        \"patent\": \"true\",\n",
    "        \"utility\": \"true\",\n",
    "        \"numOfRows\": num_rows,\n",
    "        \"pageNo\": page_no\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = xmltodict.parse(response.text)\n",
    "\n",
    "    try:\n",
    "        items = data[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "    except (KeyError, TypeError):\n",
    "        return []\n",
    "\n",
    "    if isinstance(items, dict):\n",
    "        items = [items]\n",
    "\n",
    "    return items\n",
    "\n",
    "#====================================\n",
    "# 4. ê¸°ì—…ëª… ì „ì²´ ìˆœíšŒ\n",
    "#====================================\n",
    "all_results = []\n",
    "\n",
    "for company in remove_nan[\"title\"].unique():\n",
    "    print(f\"ìˆ˜ì§‘ ì¤‘: {company}\")\n",
    "\n",
    "    patents = fetch_patent_by_company(company)\n",
    "\n",
    "    for p in patents:\n",
    "        p[\"company_name\"] = company\n",
    "        all_results.append(p)\n",
    "\n",
    "#====================================\n",
    "# 5. DataFrame ìƒì„±\n",
    "#====================================\n",
    "patent_df = pd.DataFrame(all_results)\n",
    "\n",
    "#====================================\n",
    "# 6. company_name / applicantName ì •ê·œí™” ì»¬ëŸ¼ ì¶”ê°€\n",
    "#====================================\n",
    "patent_df[\"company_norm\"] = patent_df[\"company_name\"].apply(normalize_name_for_match)\n",
    "patent_df[\"applicant_norm\"] = patent_df[\"applicantName\"].apply(normalize_name_for_match)\n",
    "\n",
    "#====================================\n",
    "# 7. ë™ì¼ ê¸°ì—… íŠ¹í—ˆë§Œ í•„í„°ë§\n",
    "#====================================\n",
    "matched_df = patent_df[\n",
    "    patent_df[\"company_norm\"] == patent_df[\"applicant_norm\"]\n",
    "].copy()\n",
    "\n",
    "#====================================\n",
    "# 8. ê²°ê³¼ í™•ì¸\n",
    "#====================================\n",
    "print(\"ì „ì²´ ìˆ˜ì§‘ íŠ¹í—ˆ ìˆ˜:\", len(patent_df))\n",
    "print(\"ë™ì¼ ê¸°ì—… íŠ¹í—ˆ ìˆ˜:\", len(matched_df))\n",
    "\n",
    "matched_df[[\"company_name\", \"applicantName\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 6. CSV ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "matched_df.to_csv(\"./preprocessed_data/company_patent_raw_3.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 7. Excel ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "matched_df.to_excel(\n",
    "    \"./preprocessed_data/company_patent_raw_3.xlsx\",\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## dart nan ì¸ ê°’ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "# =========================================================\n",
    "# 1. ê¸°ë³¸ ì„¤ì •\n",
    "# =========================================================\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"KIPRIS_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"KIPRIS_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "BASE_URL = (\n",
    "    \"http://plus.kipris.or.kr/kipo-api/\"\n",
    "    \"kipi/patUtiModInfoSearchSevice/getAdvancedSearch\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 2. DART ë“±ë¡ ê¸°ì—…ë§Œ í•„í„°ë§ (company_df ì ìš©)\n",
    "# =========================================================\n",
    "company_df = pd.read_csv('./data/ì†Œë¶€ì¥_ê¸°ì—…_DARTë§¤í•‘_ê¸°ì—…ëª…ì •ì œ.csv', encoding='cp949')\n",
    "remove_nan = company_df[company_df[\"dart_corp_code\"].notna()].copy()    # dart_corp_code ê°€ ìˆëŠ” ê²ƒë“¤ë§Œ ì‚´ë ¤ë‘ \n",
    "\n",
    "print(\"DART ë“±ë¡ ê¸°ì—… ìˆ˜:\", remove_nan.shape[0])  # 478\n",
    "\n",
    "# =========================================================\n",
    "# 3. ê¸°ì—…ëª… ì •ê·œí™” í•¨ìˆ˜\n",
    "#    - ê³µë°± ì œê±°\n",
    "#    - (ì£¼), ì£¼ì‹íšŒì‚¬, ãˆœ ì œê±°\n",
    "#    - ëŒ€ì†Œë¬¸ì í†µì¼\n",
    "# =========================================================\n",
    "def normalize_name_for_match(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = name.lower()\n",
    "    name = name.strip()\n",
    "    name = re.sub(r\"\\s+\", \"\", name)\n",
    "    name = re.sub(r\"\\(ì£¼\\)|ãˆœ|ì£¼ì‹íšŒì‚¬\", \"\", name)\n",
    "    return name\n",
    "\n",
    "# =========================================================\n",
    "# 4. ê¸°ì—… 1ê³³ íŠ¹í—ˆ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜ (KIPRIS)\n",
    "# =========================================================\n",
    "def fetch_patent_by_company(company_name, page_no=1, num_rows=50):\n",
    "    params = {\n",
    "        \"ServiceKey\": API_KEY,     \n",
    "        \"applicant\": company_name,\n",
    "        \"patent\": \"true\",\n",
    "        \"utility\": \"true\",\n",
    "        \"numOfRows\": num_rows,\n",
    "        \"pageNo\": page_no\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params, timeout=10)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = xmltodict.parse(response.text)\n",
    "\n",
    "    try:\n",
    "        items = data[\"response\"][\"body\"][\"items\"][\"item\"]\n",
    "    except (KeyError, TypeError):\n",
    "        return []\n",
    "\n",
    "    if isinstance(items, dict):\n",
    "        items = [items]\n",
    "\n",
    "    return items\n",
    "\n",
    "# =========================================================\n",
    "# 5. ê¸°ì—… ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ (DART ë“±ë¡ ê¸°ì—…ë§Œ)\n",
    "# =========================================================\n",
    "all_results = []\n",
    "\n",
    "for company in remove_nan[\"title\"].unique():\n",
    "    print(f\"ìˆ˜ì§‘ ì¤‘: {company}\")\n",
    "\n",
    "    patents = fetch_patent_by_company(company)\n",
    "\n",
    "    for p in patents:\n",
    "        p[\"company_name\"] = company  # ê²€ìƒ‰ ê¸°ì¤€ ê¸°ì—…ëª…\n",
    "        all_results.append(p)\n",
    "\n",
    "# =========================================================\n",
    "# 6. DataFrame ìƒì„±\n",
    "# =========================================================\n",
    "patent_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"íŠ¹í—ˆ ìˆ˜ì§‘ ëŒ€ìƒ ê¸°ì—… ìˆ˜:\", patent_df[\"company_name\"].nunique())\n",
    "print(\"ì „ì²´ ìˆ˜ì§‘ íŠ¹í—ˆ ìˆ˜:\", len(patent_df))\n",
    "\n",
    "# =========================================================\n",
    "# 7. company_name / applicantName ì •ê·œí™” ì»¬ëŸ¼ ì¶”ê°€\n",
    "# =========================================================\n",
    "patent_df[\"company_norm\"] = patent_df[\"company_name\"].apply(normalize_name_for_match)\n",
    "patent_df[\"applicant_norm\"] = patent_df[\"applicantName\"].apply(normalize_name_for_match)\n",
    "\n",
    "# =========================================================\n",
    "# 8. ë™ì¼ ê¸°ì—… íŠ¹í—ˆë§Œ í•„í„°ë§\n",
    "#    (ê³µë°±Â·íšŒì‚¬í˜•íƒœ ì°¨ì´ë§Œ í—ˆìš©)\n",
    "# =========================================================\n",
    "matched_df = patent_df[\n",
    "    patent_df[\"company_norm\"] == patent_df[\"applicant_norm\"]\n",
    "].copy()\n",
    "\n",
    "# =========================================================\n",
    "# 9. ê²°ê³¼ í™•ì¸\n",
    "# =========================================================\n",
    "print(\"ë™ì¼ ê¸°ì—… íŠ¹í—ˆ ìˆ˜:\", len(matched_df))\n",
    "\n",
    "matched_df[[\"company_name\", \"applicantName\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df[\"applicantName\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 6. CSV ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "matched_df.to_csv(\"./preprocessed_data/company_patent_raw_4.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 7. Excel ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "matched_df.to_excel(\"./preprocessed_data/company_patent_raw_4.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_df['company_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# íŠ¹í—ˆÂ·ì‹¤ìš© í”¼ì¸ìš©ë¬¸í—Œ\n",
    "- matched_df['applicationNumber']ì„ ê°€ì§€ê³  í”¼ì¸ìš©ì •ë³´ ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# =========================================================\n",
    "# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "# =========================================================\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"KIPRIS_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"KIPRIS_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. Endpoint (CitingService)\n",
    "# =========================================================\n",
    "CITING_URL = \"http://plus.kipris.or.kr/openapi/rest/CitingService/citingInfo\"\n",
    "\n",
    "# =========================================================\n",
    "# 3. Session + Retry ì„¤ì •\n",
    "# =========================================================\n",
    "session = requests.Session()\n",
    "\n",
    "retry_strategy = Retry(\n",
    "    total=3,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\"]\n",
    ")\n",
    "\n",
    "adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_citing_info(app_num):\n",
    "    params = {\n",
    "        \"accessKey\": API_KEY,\n",
    "        \"standardCitationApplicationNumber\": app_num\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        res = session.get(CITING_URL, params=params, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        raw = xmltodict.parse(res.text)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    # 1ï¸âƒ£ response ì²´í¬\n",
    "    response = raw.get(\"response\")\n",
    "    if response is None:\n",
    "        return None\n",
    "\n",
    "    # 2ï¸âƒ£ body ì²´í¬\n",
    "    body = response.get(\"body\")\n",
    "    if body is None:\n",
    "        return None\n",
    "\n",
    "    # 3ï¸âƒ£ items ì²´í¬\n",
    "    items_wrapper = body.get(\"items\")\n",
    "    if items_wrapper is None:\n",
    "        return None\n",
    "\n",
    "    # 4ï¸âƒ£ citingInfo ì²´í¬\n",
    "    items = items_wrapper.get(\"citingInfo\")\n",
    "    if items is None:\n",
    "        return None\n",
    "\n",
    "    # 5ï¸âƒ£ dict â†’ list ë³´ì •\n",
    "    if isinstance(items, dict):\n",
    "        items = [items]\n",
    "\n",
    "    df = pd.DataFrame(items)\n",
    "\n",
    "    # 6ï¸âƒ£ ì»¬ëŸ¼ëª… í‘œì¤€í™” (ëŒ€ì†Œë¬¸ì ì•ˆì „)\n",
    "    col_map = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        col_map.get(\"standardcitationapplicationnumber\"): \"StandardCitationApplicationNumber\",\n",
    "        col_map.get(\"applicationnumber\"): \"ApplicationNumber\"\n",
    "    })\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# 5. applicationNumber ê¸°ì¤€ìœ¼ë¡œ CitingService ìˆœíšŒ\n",
    "# =========================================================\n",
    "citing_dfs = []\n",
    "\n",
    "app_nums = (\n",
    "    matched_df[\"applicationNumber(ì¶œì›ë²ˆí˜¸)\"]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "for app_num in tqdm(app_nums, desc=\"ğŸ“¡ í”¼ì¸ìš© ì •ë³´ ìˆ˜ì§‘ ì¤‘\"):\n",
    "    citing_df = fetch_citing_info(app_num)\n",
    "\n",
    "    if citing_df is not None and not citing_df.empty:\n",
    "        citing_dfs.append(citing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================================================\n",
    "# 6. í”¼ì¸ìš© ê²°ê³¼ ë³‘í•©\n",
    "# =========================================================\n",
    "if citing_dfs:\n",
    "    citing_all_df = pd.concat(citing_dfs, ignore_index=True)\n",
    "else:\n",
    "    citing_all_df = pd.DataFrame(\n",
    "        columns=[\"StandardCitationApplicationNumber\", \"ApplicationNumber\"]\n",
    "    )\n",
    "\n",
    "# =========================================================\n",
    "# 7. â­ applicantName ë¶™ì´ê¸° (í•µì‹¬)\n",
    "#    ê¸°ì¤€ íŠ¹í—ˆ(StandardCitationApplicationNumber) ê¸°ì¤€ merge\n",
    "# =========================================================\n",
    "final_df = citing_all_df.merge(\n",
    "    matched_df[[\"applicationNumber(ì¶œì›ë²ˆí˜¸)\", \"applicantName(ì¶œì›ì¸ëª…)\"]],\n",
    "    left_on=\"StandardCitationApplicationNumber\",\n",
    "    right_on=\"applicationNumber(ì¶œì›ë²ˆí˜¸)\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 8. ì»¬ëŸ¼ ì •ë¦¬\n",
    "# =========================================================\n",
    "final_df = final_df[[\n",
    "    \"StandardCitationApplicationNumber\",\n",
    "    \"ApplicationNumber\",\n",
    "    \"applicantName(ì¶œì›ì¸ëª…)\"\n",
    "]]\n",
    "\n",
    "# =========================================================\n",
    "# 9. ê²°ê³¼ í™•ì¸\n",
    "# =========================================================\n",
    "print(f\"âœ… ìµœì¢… í”¼ì¸ìš© ë°ì´í„° ê±´ìˆ˜: {len(final_df)}\")\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 10. CSV ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "final_df.to_csv(\"./preprocessed_data/company_patent_citing.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# 11. Excel ë¡œ ì €ì¥ \n",
    "#====================================\n",
    "matched_df.to_excel(\"./preprocessed_data/company_patent_citing.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
