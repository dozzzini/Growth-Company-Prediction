{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import parallel_backend\n",
    "import contextlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    from joblib import Parallel\n",
    "    old_batch_callback = Parallel.BatchCompletionCallBack\n",
    "\n",
    "    class TqdmBatchCompletionCallBack(old_batch_callback):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    Parallel.BatchCompletionCallBack = TqdmBatchCompletionCallBack\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        Parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# ì¬ë¬´ì •ë³´_final_v2(16~24) íŒŒì¼ ì—´ê¸°\n",
    "- ê¸°ì—… ì •ë³´ë§Œì„ ìœ„í•´ ì—´ì–´ë³´ëŠ” íŒŒì¼\n",
    "    - ì¬ë¬´ ë°ì´í„°ì— ë“±ì¥í•œ ëª¨ë“  ê¸°ì—…\n",
    "    - ì—°ë„ë³„ë¡œ ì‚´ì•„ ìˆì—ˆë˜ ê¸°ì—…\n",
    "    - íŠ¹í—ˆ ì—¬ë¶€ì™€ ë¬´ê´€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df = pd.read_csv('../../data/ì¬ë¬´ì •ë³´_final_v2(16~24)_ìˆ˜ì •_ìµœì¢….csv', encoding=\"utf-8\", encoding_errors='replace', engine=\"python\")\n",
    "# financial_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# íŠ¹í—ˆì •ë³´_final íŒŒì¼ ì—´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final = pd.read_csv('../../data/íŠ¹í—ˆì •ë³´_final_v2.csv', encoding=\"cp949\", encoding_errors='replace', engine=\"python\")\n",
    "# patent_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final = patent_final.rename(columns={\n",
    "    'ipcNumber_IPCì½”ë“œ': 'ipcNumber',\n",
    "    'applicationDate_ì¶œì›ì¼ì': 'applicationDate',\n",
    "    'astrtCont_ì´ˆë¡':'astrtCont',\n",
    "    'applicationNumber_ì¶œì›ë²ˆí˜¸':'applicationNumber',\n",
    "     'registerDate_ë“±ë¡ì¼ì':'registerDate',\n",
    "      'indexNo_ì¼ë ¨ë²ˆí˜¸':'indexNo',\n",
    " 'registerStatus_ë“±ë¡ìƒíƒœ':'registerStatus',\n",
    " 'inventionTitle_ë°œëª…ì˜ëª…ì¹­':'inventionTitle',\n",
    " 'applicantName_ì¶œì›ì¸ëª…':'applicantName'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# ì ê¹ ......."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## íŠ¹í—ˆ ë°ì´í„° ìµœì†Œ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df = patent_final.copy()\n",
    "\n",
    "# ì¶œì›ì¼ datetime ë³´ì¥\n",
    "patent_df['applicationDate'] = pd.to_datetime(patent_df['applicationDate'])\n",
    "\n",
    "# ì¶œì›ë…„ë„ \n",
    "patent_df['application_year'] = patent_df['applicationDate'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df['application_year'] = pd.to_numeric(\n",
    "    patent_df['application_year'],\n",
    "    errors='coerce'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_company_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "\n",
    "    name = str(name)\n",
    "\n",
    "    # 1. ì†Œë¬¸ì ë³€í™˜\n",
    "    name = name.lower()\n",
    "\n",
    "    # 2. ë²•ì¸ í‘œê¸° ì œê±°\n",
    "    name = re.sub(r'\\(ì£¼\\)|ãˆœ|ì£¼ì‹íšŒì‚¬', '', name)\n",
    "\n",
    "    # 3. ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°\n",
    "    name = re.sub(r'\\s+', '', name)\n",
    "\n",
    "    # 4. íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•„ìš” ìµœì†Œ)\n",
    "    name = re.sub(r'[^\\wê°€-í£]', '', name)\n",
    "\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================================================\n",
    "# ë‘ ë°ì´í„°ì— ë™ì¼í•˜ê²Œ ì ìš© \n",
    "#=====================================================================================\n",
    "financial_df['company_norm'] = financial_df['ê¸°ì—…ëª…'].apply(normalize_company_name)\n",
    "patent_df['company_norm'] = patent_df['company_name'].apply(normalize_company_name)\n",
    "\n",
    "#=====================================================================================\n",
    "# ë§¤ì¹­ í’ˆì§ˆ ì§„ë‹¨\n",
    "#=====================================================================================\n",
    "\n",
    "# ì¬ë¬´ ê¸°ì¤€ ê¸°ì—… ìˆ˜\n",
    "financial_companies = set(financial_df['company_norm'].dropna())\n",
    "\n",
    "# íŠ¹í—ˆ ê¸°ì¤€ ê¸°ì—… ìˆ˜\n",
    "patent_companies = set(patent_df['company_norm'].dropna())\n",
    "\n",
    "print(\"ì¬ë¬´ ê¸°ì—… ìˆ˜:\", len(financial_companies))\n",
    "print(\"íŠ¹í—ˆ ê¸°ì—… ìˆ˜:\", len(patent_companies))\n",
    "print(\"êµì§‘í•© ìˆ˜:\", len(financial_companies & patent_companies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_year_df = (\n",
    "    financial_df[['company_norm', 'ì—°ë„']]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(['company_norm', 'ì—°ë„'])\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# [STEP 0] ë§¤ì¶œì•¡ ìˆ«ì ë³€í™˜ (ë°˜ë“œì‹œ growth ê³„ì‚° ì „ì—)\n",
    "# =====================================================\n",
    "\n",
    "financial_df['ë§¤ì¶œì•¡'] = (\n",
    "    financial_df['ë§¤ì¶œì•¡']\n",
    "    .astype(str)                 # í˜¹ì‹œ ëª¨ë¥¼ íƒ€ì… í†µì¼\n",
    "    .str.replace(',', '')        # ì²œ ë‹¨ìœ„ ì½¤ë§ˆ ì œê±°\n",
    "    .str.replace(' ', '')        # ê³µë°± ì œê±°\n",
    ")\n",
    "\n",
    "financial_df['ë§¤ì¶œì•¡'] = pd.to_numeric(\n",
    "    financial_df['ë§¤ì¶œì•¡'],\n",
    "    errors='coerce'              # ìˆ«ì ì•„ë‹Œ ê±´ NaN\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 1] ì •ë ¬ (ì ˆëŒ€ ìƒëµ ê¸ˆì§€)\n",
    "# =====================================================\n",
    "financial_df = financial_df.sort_values(\n",
    "    ['company_norm', 'ì—°ë„']\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 2] ì „ë…„ë„ ë§¤ì¶œ (lag)\n",
    "# =====================================================\n",
    "financial_df['revenue_lag_1'] = (\n",
    "    financial_df\n",
    "    .groupby('company_norm')['ë§¤ì¶œì•¡']\n",
    "    .shift(1)\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 3] ë§¤ì¶œ ì„±ì¥ë¥ \n",
    "# =====================================================\n",
    "financial_df['revenue_growth'] = (\n",
    "    (financial_df['ë§¤ì¶œì•¡'] - financial_df['revenue_lag_1'])\n",
    "    / financial_df['revenue_lag_1']\n",
    ")\n",
    "# =====================================================\n",
    "# [STEP 4] ì„±ì¥ ì—¬ë¶€ ë¼ë²¨\n",
    "# =====================================================\n",
    "financial_df['growth_binary'] = (\n",
    "    financial_df['revenue_growth'] > 0\n",
    ").astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 5] ì„ì‹œ íƒ€ê²Ÿ ë³€ìˆ˜ (ì ˆëŒ€ ì„±ì¥ ì—¬ë¶€)\n",
    "# =====================================================\n",
    "financial_df['y'] = financial_df['growth_binary']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## íŠ¹í—ˆ í”¼ì²˜ ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_patent_features(company_norm, t, patent_df):\n",
    "    \"\"\"\n",
    "    company_norm Ã— ì—°ë„(t) ê¸°ì¤€ íŠ¹í—ˆ í”¼ì²˜ ìƒì„±\n",
    "    - warm-up ì ìš©: t < 2019 â†’ None\n",
    "    - ëˆ„ìˆ˜ ë°©ì§€: t-1 ì‹œì ê¹Œì§€ë§Œ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "\n",
    "    # ===============================\n",
    "    # 0. Warm-up ê°•ì œ\n",
    "    # ===============================\n",
    "    t = int(t)\n",
    "    if t < 2019:\n",
    "        return None\n",
    "\n",
    "    # ê¸°ì—… ê¸°ì¤€ í•„í„°\n",
    "    df = patent_df[patent_df['company_norm'] == company_norm].copy()\n",
    "\n",
    "    # ===============================\n",
    "    # 1. ê¸°ê°„ í•„í„° (ëˆ„ìˆ˜ ë°©ì§€ í•µì‹¬)\n",
    "    # ===============================\n",
    "    window_5y = df[\n",
    "        (df['application_year'] >= t - 4) &\n",
    "        (df['application_year'] <= t - 1)\n",
    "    ]\n",
    "\n",
    "    window_recent = df[\n",
    "        (df['application_year'] >= t - 2) &\n",
    "        (df['application_year'] <= t - 1)\n",
    "    ]\n",
    "\n",
    "    # # ë“±ë¡ë¥  ì½”í˜¸íŠ¸: t-4 ~ t-3\n",
    "    # cohort_register = df[\n",
    "    #     (df['application_year'] >= t - 4) &\n",
    "    #     (df['application_year'] <= t - 3)\n",
    "    # ]\n",
    "\n",
    "    # í”¼ì¸ìš© as-of cutoff\n",
    "    citation_window = window_5y[\n",
    "        window_5y['applicationDate'] <= pd.Timestamp(f\"{t-1}-12-31\")\n",
    "    ].copy()\n",
    "\n",
    "    # ===============================\n",
    "    # 2. í”¼ì²˜ ê³„ì‚°\n",
    "    # ===============================\n",
    "    patent_count_5y = len(window_5y)\n",
    "    patent_count_recent = len(window_recent)\n",
    "\n",
    "    ipc_diversity = (\n",
    "        window_5y['ipcNumber']\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str[:4]\n",
    "        .nunique()\n",
    "        if patent_count_5y > 0 else 0\n",
    "    )\n",
    "\n",
    "    # # ë“±ë¡ë¥ : registerDate ê¸°ì¤€\n",
    "    # if len(cohort_register) > 0:\n",
    "    #     patent_register_rate = (\n",
    "    #         cohort_register['registerDate'].notna().mean()\n",
    "    #     )\n",
    "    # else:\n",
    "    #     patent_register_rate = 0.0\n",
    "    # ===============================\n",
    "    # ë“±ë¡ë¥  ì½”í˜¸íŠ¸: t-4 ~ t-3\n",
    "    # ===============================\n",
    "    VALID_SUCCESS_STATUS = ['ë“±ë¡', 'ê³µê°œ']\n",
    "    cohort_register = df[\n",
    "        (df['application_year'] >= t - 4) &\n",
    "        (df['application_year'] <= t - 3)\n",
    "    ]\n",
    "\n",
    "    if len(cohort_register) > 0:\n",
    "        # ì „ì²´ ì¶œì› ìˆ˜\n",
    "        total_applications = len(cohort_register)\n",
    "\n",
    "        # ë“±ë¡ + ê³µê°œ ê±´ìˆ˜\n",
    "        success_count = cohort_register[\n",
    "            cohort_register['registerStatus'].isin(['ë“±ë¡', 'ê³µê°œ'])\n",
    "        ].shape[0]\n",
    "\n",
    "        patent_register_rate = success_count / total_applications\n",
    "    else:\n",
    "        patent_register_rate = 0.0\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # í”¼ì¸ìš© (ê¸°ë³¸)\n",
    "    # -------------------------------\n",
    "    patent_citation_total = (\n",
    "        citation_window['í”¼ì¸ìš© íšŸìˆ˜'].sum()\n",
    "        if len(citation_window) > 0 else 0.0\n",
    "    )\n",
    "\n",
    "    patent_citation_avg = (\n",
    "        patent_citation_total / max(1, patent_count_5y)\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # ğŸ”¥ ì—°ë ¹ ë³´ì • í”¼ì¸ìš©\n",
    "    # -------------------------------\n",
    "    if len(citation_window) > 0:\n",
    "        citation_window['patent_age'] = (\n",
    "            t - citation_window['application_year']\n",
    "        ).clip(lower=1)\n",
    "\n",
    "        citation_window['citation_per_year'] = (\n",
    "            citation_window['í”¼ì¸ìš© íšŸìˆ˜'] / citation_window['patent_age']\n",
    "        )\n",
    "\n",
    "        patent_citation_age_adj_total = (\n",
    "            citation_window['citation_per_year'].sum()\n",
    "        )\n",
    "    else:\n",
    "        patent_citation_age_adj_total = 0.0\n",
    "\n",
    "    patent_citation_age_adj_avg = (\n",
    "        patent_citation_age_adj_total / max(1, patent_count_5y)\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # íŠ¹í—ˆ 0ê±´ í”Œë˜ê·¸\n",
    "    # -------------------------------\n",
    "    no_patent_flag = int(patent_count_5y == 0)\n",
    "\n",
    "    return {\n",
    "        'company_norm': company_norm,\n",
    "        'ì—°ë„': t,\n",
    "        'patent_count_5y': patent_count_5y,\n",
    "        'patent_count_recent': patent_count_recent,\n",
    "        'ipc_diversity': ipc_diversity,\n",
    "        'patent_register_rate': patent_register_rate,\n",
    "        'patent_citation_total': patent_citation_total,\n",
    "        'patent_citation_avg': patent_citation_avg,\n",
    "        # ğŸ”¥ ì¶”ê°€ í”¼ì²˜\n",
    "        'patent_citation_age_adj_total': patent_citation_age_adj_total,\n",
    "        'patent_citation_age_adj_avg': patent_citation_age_adj_avg,\n",
    "        'no_patent_flag': no_patent_flag\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_feature_rows = []\n",
    "\n",
    "for row in tqdm(\n",
    "    company_year_df.itertuples(index=False),\n",
    "    total=len(company_year_df),\n",
    "    desc=\"íŠ¹í—ˆ í”¼ì²˜ ìƒì„±\"\n",
    "):\n",
    "    feat = make_patent_features(\n",
    "        company_norm=row.company_norm,\n",
    "        t=row.ì—°ë„,\n",
    "        patent_df=patent_df\n",
    "    )\n",
    "\n",
    "    if feat is not None:\n",
    "        patent_feature_rows.append(feat)\n",
    "\n",
    "patent_feature_df = pd.DataFrame(patent_feature_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_feature_df['ì—°ë„'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "- íŠ¹í—ˆ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê³¼ì •ì—ì„œ ë¡¤ë§ ìœˆë„ìš°ì˜ warm-up ê¸°ê°„ì„ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ê°•ì œí•˜ì—¬,\n",
    "ì¶©ë¶„í•œ ê³¼ê±° ë°ì´í„°ê°€ í™•ë³´ë˜ì§€ ì•Šì€ ì—°ë„(2019 ì´ì „)ê°€\n",
    "í•™ìŠµ ë°ì´í„°ì— í¬í•¨ë˜ì§€ ì•Šë„ë¡ ìˆ˜ì •í•˜ì˜€ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## ì¬ë¬´ ë°ì´í„°ì™€ ê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df['ì—°ë„'] = pd.to_numeric(financial_df['ì—°ë„'], errors='coerce').astype('Int64')\n",
    "patent_feature_df['ì—°ë„'] = pd.to_numeric(patent_feature_df['ì—°ë„'], errors='coerce').astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df[['ì—°ë„']].dtypes, patent_feature_df[['ì—°ë„']].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df['ë§¤ì¶œì•¡'].isna().mean(), (financial_df['ë§¤ì¶œì•¡'] == 0).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_agg = (\n",
    "    financial_df\n",
    "    .groupby(['company_norm', 'ì—°ë„'], as_index=False)\n",
    "    .agg({\n",
    "        'ê¸°ì—…ëª…': 'first',\n",
    "        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': 'first',\n",
    "        'crno': 'first',\n",
    "        'dart_corp_code': 'first',\n",
    "        'sectors': 'first',\n",
    "        'field': 'first',\n",
    "\n",
    "        'ë§¤ì¶œì•¡': 'sum',\n",
    "        'ì˜ì—…ì´ìµ': 'sum',\n",
    "        'ë‹¹ê¸°ìˆœì´ìµ': 'sum',\n",
    "        'ìì‚°ì´ê³„': 'max',\n",
    "        'ë¶€ì±„ì´ê³„': 'max',\n",
    "        'ìë³¸ì´ê³„': 'max',\n",
    "        'ì—°êµ¬ê°œë°œë¹„': 'sum',\n",
    "        'CAPEX': 'sum',\n",
    "        'ìœ í˜•ìì‚°_ë‹¹ê¸°': 'max',\n",
    "        'ìœ í˜•ìì‚°_ì „ê¸°': 'max',\n",
    "        'ìœ í˜•ìì‚°_ì¦ê°': 'sum'\n",
    "    })\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = financial_agg.merge(\n",
    "    patent_feature_df,\n",
    "    on=['company_norm', 'ì—°ë„'],\n",
    "    how='left',\n",
    "    validate='one_to_one'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(financial_agg), len(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['ë§¤ì¶œì•¡'].isna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('financial_df:',financial_df.columns)\n",
    "print('patent_feature_df:',patent_feature_df.columns)\n",
    "print('final_df:',final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(financial_df), len(final_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## íƒ€ê¹ƒ(y) ìƒì„± â€” â€œt ì •ë³´ë¡œ t+1 ì„±ì¥ ì—¬ë¶€ ì˜ˆì¸¡â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "money_cols = [\n",
    "    'ë§¤ì¶œì•¡','ì˜ì—…ì´ìµ','ë‹¹ê¸°ìˆœì´ìµ',\n",
    "    'ìì‚°ì´ê³„','ë¶€ì±„ì´ê³„','ìë³¸ì´ê³„',\n",
    "    'ì—°êµ¬ê°œë°œë¹„','CAPEX',\n",
    "    'ìœ í˜•ìì‚°_ë‹¹ê¸°','ìœ í˜•ìì‚°_ì „ê¸°','ìœ í˜•ìì‚°_ì¦ê°'\n",
    "]\n",
    "\n",
    "for col in money_cols:\n",
    "    final_df[col] = (\n",
    "        final_df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(',', '', regex=False)\n",
    "    )\n",
    "    final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['ë§¤ì¶œì•¡']].head()\n",
    "final_df['ë§¤ì¶œì•¡'].isna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['revenue_growth'] = (\n",
    "    final_df\n",
    "    .groupby('company_norm')['ë§¤ì¶œì•¡']\n",
    "    .pct_change()       # pct_changeë¥¼ í†µí•´ì„œ ë§¤ì¶œ ì„±ì¥ë¥  ê³„ì‚°ë¨\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[\n",
    "    (final_df['ì—°ë„'] >= 2019) &\n",
    "    (final_df['ì—°ë„'] <= 2024)\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['ì—°ë„'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_flag : ê°™ì€ ì—°ë„ ì•ˆì—ì„œ ì„±ì¥ë¥ ì´ ìƒìœ„ 30%ë©´ 1\n",
    "final_df['growth_flag'] = (\n",
    "    final_df\n",
    "    .groupby('ì—°ë„')['revenue_growth']\n",
    "    .transform(lambda x: (x >= x.quantile(0.7)).astype(int))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('ì—°ë„')['growth_flag'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y : ì˜¬í•´ì˜ ì •ë³´ë¡œ ë‹¤ìŒ í•´ì— ì˜ ì„±ì¥í•  ê¸°ì—…ì¸ì§€ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œ 1ë…„ ë’¤ë¡œ ë‹¹ê²¨ì„œ ë§Œë“¦\n",
    "final_df['y'] = (\n",
    "    final_df\n",
    "    .groupby('company_norm')['growth_flag']\n",
    "    .shift(-1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = final_df.dropna(subset=['y']).copy()\n",
    "model_df['y'] = model_df['y'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['ì—°ë„'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ì»¬ëŸ¼ë“¤ë§Œ ë‚¨ê¸°ê¸°\n",
    "keep_cols = [\n",
    "    # ì‹ë³„ / ì‹œì \n",
    "    'company_norm',\n",
    "    'ì—°ë„',\n",
    "    'ê¸°ì—…ëª…',\n",
    "\n",
    "    # íŠ¹í—ˆ í”¼ì²˜\n",
    "    'patent_count_5y',\n",
    "    'patent_count_recent',\n",
    "    'ipc_diversity',\n",
    "    'patent_register_rate',\n",
    "    'patent_citation_total',\n",
    "    'patent_citation_avg',\n",
    "    'patent_citation_age_adj_total',\n",
    "    'patent_citation_age_adj_avg',\n",
    "    'no_patent_flag',\n",
    "\n",
    "    # ì„±ì¥ ê´€ë ¨\n",
    "    # 'revenue_growth',\n",
    "    # 'growth_flag',\n",
    "    # 'y'\n",
    "]\n",
    "\n",
    "model_df = model_df[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv('../../output/feature_engineering_dataset_8_patent.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ë§\n",
    "- ëª¨ë¸ : LogReg, RandomForest, LightBGM, XGBoost\n",
    "- ê²€ì¦ ë°©ì‹ : Holdout, GroupKFold, RollingValidation\n",
    "- í‰ê°€ì§€í‘œ: PR-AUC, Top-20/50 Precision, F1, Brier\n",
    "---\n",
    "> - model_df : feature + y í¬í•¨ (ì •ìƒ)\n",
    "> - ì—°ë„ ë²”ìœ„ : 2019â€“2023\n",
    "> - y : të…„ í”¼ì²˜ â†’ t+1ë…„ ì„±ì¥ ì—¬ë¶€(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "## Xë‘ yì— ë“¤ì–´ê°ˆ df ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### feature ë°ì´í„° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_en_df = pd.read_csv('../../data/normalized_patent_features.csv', encoding=\"utf-8\", encoding_errors='replace', engine=\"python\")\n",
    "feat_en_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### ì •ë‹µ ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv('../../data/ì—°ë„ë³„ ì„±ì¥ì—¬ë¶€.csv', encoding=\"utf-8\", encoding_errors='replace', engine=\"python\")\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_long_df = target_df.melt(\n",
    "    id_vars=\"ê¸°ì—…ëª…\",        # ê³ ì •í•  ì»¬ëŸ¼\n",
    "    var_name=\"ì—°ë„\",        # ìƒˆë¡œ ìƒê¸¸ ì—°ë„ ì»¬ëŸ¼ ì´ë¦„\n",
    "    value_name=\"y\"          # íƒ€ê²Ÿ ë³€ìˆ˜\n",
    ")\n",
    "\n",
    "target_long_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_long_df.to_csv('../../output/ì—°ë„ë³„_ì„±ì¥ì—¬ë¶€_ì»¬ëŸ¼ë³€í™˜.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ë°ì´í„° ì—°ë„ â†’ int\n",
    "feat_en_df[\"ì—°ë„\"] = feat_en_df[\"ì—°ë„\"].astype(int)\n",
    "\n",
    "# target ë°ì´í„° ì—°ë„ â†’ int\n",
    "target_long_df[\"ì—°ë„\"] = target_long_df[\"ì—°ë„\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = feat_en_df.merge(\n",
    "    target_long_df,\n",
    "    left_on=[\"ê¸°ì—…ëª…\", \"target_year\"],\n",
    "    right_on=[\"ê¸°ì—…ëª…\", \"ì—°ë„\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "model_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns.tolist()\n",
    "\n",
    "\n",
    "# ì™¼ìª½ ì—°ë„  â†’ ì—°ë„_x\n",
    "# ì˜¤ë¥¸ìª½ ì—°ë„ â†’ ì—°ë„_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## Feature / Label ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ID / Label ì»¬ëŸ¼\n",
    "# id_cols = ['ê¸°ì—…ëª…', 'company_norm', 'ì—°ë„']    # í–‰ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ì •ë³´\n",
    "# label_cols = ['y', 'growth_flag', 'revenue_growth', 'asset_growth']\n",
    "\n",
    "# # ìˆ«ìí˜• í”¼ì²˜ë§Œ ì‚¬ìš©\n",
    "# feature_cols = (\n",
    "#     model_df\n",
    "#     .drop(columns=id_cols + label_cols, errors='ignore')\n",
    "#     .select_dtypes(include=['int64', 'float64'])\n",
    "#     .columns\n",
    "#     .tolist()\n",
    "# )\n",
    "\n",
    "# X = model_df[feature_cols].copy()\n",
    "# y = model_df['y'].copy()\n",
    "# years = model_df['ì—°ë„'].copy()\n",
    "# groups = model_df['company_norm'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Feature / Label ë¶„ë¦¬ (ìµœì¢…)\n",
    "# =========================\n",
    "\n",
    "# ID / Label ì»¬ëŸ¼\n",
    "id_cols = ['ê¸°ì—…ëª…', 'company_norm', 'target_year']\n",
    "label_cols = ['y']\n",
    "\n",
    "# ìˆ«ìí˜• í”¼ì²˜ë§Œ ì‚¬ìš©\n",
    "feature_cols = (\n",
    "    model_df\n",
    "    .drop(columns=id_cols + label_cols, errors='ignore')\n",
    "    .select_dtypes(include=['int64', 'float64'])\n",
    "    .columns\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# ì…ë ¥ / ì •ë‹µ\n",
    "X = model_df[feature_cols].copy()\n",
    "y = model_df['y'].copy()\n",
    "\n",
    "# ê²€ì¦ìš© ë³´ì¡° ì •ë³´\n",
    "years = model_df['target_year'].copy()\n",
    "groups = model_df['company_norm'].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "## train/test ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# STEP 1. ì—°ë„ ê¸°ì¤€ ë¶„ë¦¬\n",
    "# =========================\n",
    "train_mask = years <= 2022\n",
    "test_mask  = years == 2023\n",
    "\n",
    "X_train_full = X[train_mask]\n",
    "y_train_full = y[train_mask]\n",
    "groups_train = groups[train_mask]\n",
    "years_train  = years[train_mask]\n",
    "\n",
    "X_test = X[test_mask]\n",
    "y_test = y[test_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## ê²°ì¸¡ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜(ì ê¹ ì‹¤í–‰ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_train_test(X_tr, X_te, feature_cols):\n",
    "    patent_cols = [c for c in feature_cols if c.startswith('patent_') or c == 'no_patent_flag']\n",
    "    financial_cols = [c for c in feature_cols if c not in patent_cols]\n",
    "\n",
    "    # íŠ¹í—ˆ â†’ 0\n",
    "    X_tr[patent_cols] = X_tr[patent_cols].fillna(0)\n",
    "    X_te[patent_cols] = X_te[patent_cols].fillna(0)\n",
    "\n",
    "    # ì¬ë¬´ â†’ train median\n",
    "    for col in financial_cols:\n",
    "        med = X_tr[col].median()\n",
    "        X_tr[col] = X_tr[col].fillna(med)\n",
    "        X_te[col] = X_te[col].fillna(med)\n",
    "\n",
    "    return X_tr, X_te\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "## ê³µí†µ í‰ê°€ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import (\n",
    "#     accuracy_score, roc_auc_score, f1_score,\n",
    "#     average_precision_score, brier_score_loss\n",
    "# )\n",
    "\n",
    "# def top_k_precision(y_true, y_prob, k):\n",
    "#     k = min(k, len(y_true))\n",
    "#     idx = np.argsort(y_prob)[-k:]\n",
    "#     return y_true.iloc[idx].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss\n",
    ")\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_proba):\n",
    "    \"\"\"\n",
    "    ê³µí†µ ëª¨ë¸ í‰ê°€ í•¨ìˆ˜\n",
    "    - ì´ì§„ ë¶„ë¥˜ ê¸°ì¤€\n",
    "    - í™•ë¥  ì˜ˆì¸¡ ê¸°ë°˜ ì§€í‘œ í¬í•¨\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"avg_precision\": average_precision_score(y_true, y_proba),\n",
    "        \"brier\": brier_score_loss(y_true, y_proba)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì •ì˜(Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogReg\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"XGB\": XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"LGBM\": LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# â‘  baseline ì „ìš©\n",
    "baseline_models = {\n",
    "    \"LogReg\": models[\"LogReg\"]\n",
    "}\n",
    "\n",
    "# â‘¡ ë³¸ ê²Œì„ìš© (íŠ¸ë¦¬ ëª¨ë¸ë§Œ)\n",
    "tree_models = {\n",
    "    k: v for k, v in models.items()\n",
    "    if k != \"LogReg\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def rolling_hyperparam_search(\n",
    "    model_class,\n",
    "    param_grid,\n",
    "    X, y, years,\n",
    "    start_year=2019,\n",
    "    end_year=2022\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    for params in param_combinations:\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "        fold_scores = []\n",
    "\n",
    "        for train_end in range(start_year, end_year + 1):\n",
    "            val_year = train_end + 1\n",
    "\n",
    "            train_mask = years <= train_end\n",
    "            val_mask   = years == val_year\n",
    "\n",
    "            X_tr  = X.loc[train_mask]\n",
    "            y_tr  = y.loc[train_mask]\n",
    "\n",
    "            X_val = X.loc[val_mask]\n",
    "            y_val = y.loc[val_mask]\n",
    "\n",
    "\n",
    "            if X_tr.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            if y_tr.nunique() < 2:\n",
    "                continue\n",
    "\n",
    "\n",
    "            model = model_class(**param_dict)\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            y_pred = model.predict(X_val)\n",
    "            y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "            score = evaluate_model(y_val, y_pred, y_proba)\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        if len(fold_scores) == 0:\n",
    "            continue\n",
    "\n",
    "        avg_score = pd.DataFrame(fold_scores).mean().to_dict()\n",
    "        avg_score.update(param_dict)\n",
    "\n",
    "        results.append(avg_score)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "## ML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# model_configs = {\n",
    "#     \"LogReg\": (\n",
    "#         LogisticRegression,\n",
    "#         {\n",
    "#             \"C\": [0.1, 1.0, 5.0],\n",
    "#             \"penalty\": [\"l2\"],\n",
    "#             \"solver\": [\"lbfgs\"],\n",
    "#             \"max_iter\": [1000]\n",
    "#         }\n",
    "#     ),\n",
    "\n",
    "#     \"RF\": (\n",
    "#         RandomForestClassifier,\n",
    "#         {\n",
    "#             \"n_estimators\": [200, 400],\n",
    "#             \"max_depth\": [5, 10],\n",
    "#             \"min_samples_leaf\": [1, 3],\n",
    "#             \"random_state\": [42],\n",
    "#             \"n_jobs\": [-1]\n",
    "#         }\n",
    "#     ),\n",
    "\n",
    "#     \"XGB\": (\n",
    "#         XGBClassifier,\n",
    "#         {\n",
    "#             \"n_estimators\": [200, 400],\n",
    "#             \"max_depth\": [4, 6],\n",
    "#             \"learning_rate\": [0.03, 0.05],\n",
    "#             \"subsample\": [0.8],\n",
    "#             \"colsample_bytree\": [0.8],\n",
    "#             \"eval_metric\": [\"logloss\"],\n",
    "#             \"random_state\": [42]\n",
    "#         }\n",
    "#     ),\n",
    "\n",
    "#     \"LGBM\": (\n",
    "#         LGBMClassifier,\n",
    "#         {\n",
    "#             \"n_estimators\": [200, 400],\n",
    "#             \"learning_rate\": [0.03, 0.05],\n",
    "#             \"num_leaves\": [15, 31],\n",
    "#             \"max_depth\": [-1, 5],\n",
    "#             \"random_state\": [42]\n",
    "#         }\n",
    "#     )\n",
    "# }\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# import mlflow.sklearn\n",
    "\n",
    "# mlflow.set_experiment(\"growth_prediction_rolling\")\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for model_name, (model_class, param_grid) in model_configs.items():\n",
    "\n",
    "#     print(f\"\\n=== {model_name} tuning ===\")\n",
    "\n",
    "#     with mlflow.start_run(run_name=f\"{model_name}_rolling\"):\n",
    "\n",
    "#         df_results = rolling_hyperparam_search(\n",
    "#             model_class=model_class,\n",
    "#             param_grid=param_grid,\n",
    "#             X=X_train_full,\n",
    "#             y=y_train_full,\n",
    "#             years=years_train,\n",
    "#             start_year=2019,\n",
    "#             end_year=2022\n",
    "#         )\n",
    "\n",
    "#         # â–¶ ê°€ì¥ ì¢‹ì€ íŒŒë¼ë¯¸í„° ì„ íƒ (ROC ê¸°ì¤€)\n",
    "#         best_row = df_results.sort_values(\"roc_auc\", ascending=False).iloc[0]\n",
    "\n",
    "#         # â–¶ íŒŒë¼ë¯¸í„° ë¡œê¹…\n",
    "#         best_params = {\n",
    "#             k: best_row[k]\n",
    "#             for k in param_grid.keys()\n",
    "#         }\n",
    "\n",
    "#         # íƒ€ì… ì •ë¦¬ (ì¤‘ìš”!)\n",
    "#         for k, v in best_params.items():\n",
    "#             if isinstance(v, float) and k not in [\"learning_rate\"]:\n",
    "#                 best_params[k] = int(v)\n",
    "\n",
    "#         mlflow.log_params(best_params)\n",
    "\n",
    "#         # â–¶ ì„±ëŠ¥ ë¡œê¹…\n",
    "#         mlflow.log_metrics({\n",
    "#             \"roc_auc\": best_row[\"roc_auc\"],\n",
    "#             \"f1\": best_row[\"f1\"],\n",
    "#             \"avg_precision\": best_row[\"avg_precision\"],\n",
    "#             \"brier\": best_row[\"brier\"]\n",
    "#         })\n",
    "\n",
    "#         # â–¶ ê²°ê³¼ í…Œì´ë¸”ë„ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥\n",
    "#         result_path = f\"{model_name}_rolling_results.csv\"\n",
    "#         df_results.to_csv(result_path, index=False)\n",
    "#         mlflow.log_artifact(result_path)\n",
    "\n",
    "#         results.append((model_name, best_params, best_row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# =========================================================\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. ëª¨ë¸ ì„¤ì •\n",
    "# =========================================================\n",
    "model_configs = {\n",
    "    \"LogReg\": (\n",
    "        LogisticRegression,\n",
    "        {\n",
    "            \"C\": [0.1, 1.0, 5.0],\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"solver\": [\"lbfgs\"],\n",
    "            \"max_iter\": [1000]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"RF\": (\n",
    "        RandomForestClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [200, 400],\n",
    "            \"max_depth\": [5, 10],\n",
    "            \"min_samples_leaf\": [1, 3],\n",
    "            \"random_state\": [42],\n",
    "            \"n_jobs\": [-1]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"XGB\": (\n",
    "        XGBClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [200, 400],\n",
    "            \"max_depth\": [4, 6],\n",
    "            \"learning_rate\": [0.03, 0.05],\n",
    "            \"subsample\": [0.8],\n",
    "            \"colsample_bytree\": [0.8],\n",
    "            \"eval_metric\": [\"logloss\"],\n",
    "            \"random_state\": [42]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"LGBM\": (\n",
    "        LGBMClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [200, 400],\n",
    "            \"learning_rate\": [0.03, 0.05],\n",
    "            \"num_leaves\": [15, 31],\n",
    "            \"max_depth\": [-1, 5],\n",
    "            \"random_state\": [42]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. MLflow ì„¤ì •\n",
    "# =========================================================\n",
    "mlflow.set_experiment(\"growth_prediction_rolling\")\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. ëª¨ë¸ë³„ ë¡¤ë§ íŠœë‹ + ë¡œê¹…\n",
    "# =========================================================\n",
    "for model_name, (model_class, param_grid) in model_configs.items():\n",
    "\n",
    "    run_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(f\"\\n=== {model_name} rolling tuning ===\")\n",
    "\n",
    "    with mlflow.start_run(\n",
    "        run_name=f\"{model_name}_rolling_{run_ts}\"\n",
    "    ):\n",
    "\n",
    "        # ğŸ”¹ ë¡¤ë§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰\n",
    "        df_results = rolling_hyperparam_search(\n",
    "            model_class=model_class,\n",
    "            param_grid=param_grid,\n",
    "            X=X_train_full,\n",
    "            y=y_train_full,\n",
    "            years=years_train,\n",
    "            start_year=2019,\n",
    "            end_year=2022\n",
    "        )\n",
    "\n",
    "        # ğŸ”¹ ìµœê³  ì„±ëŠ¥ íŒŒë¼ë¯¸í„° ì„ íƒ (ROC ê¸°ì¤€)\n",
    "        best_row = df_results.sort_values(\n",
    "            \"roc_auc\", ascending=False\n",
    "        ).iloc[0]\n",
    "\n",
    "        best_params = {\n",
    "            k: best_row[k]\n",
    "            for k in param_grid.keys()\n",
    "        }\n",
    "\n",
    "        # ğŸ”¥ íƒ€ì… ì •ë¦¬ (int ê°•ì œ)\n",
    "        for k, v in best_params.items():\n",
    "            if isinstance(v, float) and k not in [\"learning_rate\"]:\n",
    "                best_params[k] = int(v)\n",
    "\n",
    "        # ğŸ”¹ MLflow ë¡œê¹…\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"roc_auc\": best_row[\"roc_auc\"],\n",
    "            \"f1\": best_row[\"f1\"],\n",
    "            \"avg_precision\": best_row[\"avg_precision\"],\n",
    "            \"brier\": best_row[\"brier\"]\n",
    "        })\n",
    "\n",
    "        # ğŸ”¹ ê²°ê³¼ CSV ì•„í‹°íŒ©íŠ¸ ì €ì¥ (runë³„ ë…ë¦½)\n",
    "        result_path = f\"{model_name}_rolling_results_{run_ts}.csv\"\n",
    "        df_results.to_csv(result_path, index=False)\n",
    "        mlflow.log_artifact(result_path)\n",
    "\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            **best_params,\n",
    "            \"roc_auc\": best_row[\"roc_auc\"],\n",
    "            \"f1\": best_row[\"f1\"],\n",
    "            \"avg_precision\": best_row[\"avg_precision\"],\n",
    "            \"brier\": best_row[\"brier\"]\n",
    "        })\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. ì „ì²´ ê²°ê³¼ ìš”ì•½ í…Œì´ë¸” (ë…¸íŠ¸ë¶ í™•ì¸ìš©)\n",
    "# =========================================================\n",
    "summary_df = pd.DataFrame(results).sort_values(\n",
    "    \"roc_auc\", ascending=False\n",
    ")\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ë³„ íŠœë‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"num_leaves\": [15, 31],\n",
    "    \"max_depth\": [-1, 5],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "lgbm_results = rolling_hyperparam_search(\n",
    "    LGBMClassifier,\n",
    "    lgbm_param_grid,\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    years_train\n",
    ")\n",
    "\n",
    "lgbm_results.sort_values(\"roc_auc\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.8],\n",
    "    \"eval_metric\": [\"logloss\"],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "xgb_results = rolling_hyperparam_search(\n",
    "    XGBClassifier,\n",
    "    xgb_param_grid,\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    years_train\n",
    ")\n",
    "\n",
    "xgb_results.sort_values(\"roc_auc\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"min_samples_leaf\": [1, 3],\n",
    "    \"random_state\": [42],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "\n",
    "rf_results = rolling_hyperparam_search(\n",
    "    RandomForestClassifier,\n",
    "    rf_param_grid,\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    years_train\n",
    ")\n",
    "\n",
    "rf_results.sort_values(\"roc_auc\", ascending=False).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "### LR(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_param_grid = {\n",
    "    \"C\": [0.1, 1.0, 5.0],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\"],\n",
    "    \"max_iter\": [1000]\n",
    "}\n",
    "\n",
    "lr_results = rolling_hyperparam_search(\n",
    "    LogisticRegression,\n",
    "    lr_param_grid,\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    years_train\n",
    ")\n",
    "\n",
    "lr_results.sort_values(\"roc_auc\", ascending=False).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ë³„ ìµœê³  ì„±ëŠ¥ ë¹„êµ \n",
    "- ROC-AUC ìµœëŒ“ê°’ ê¸°ì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf   = rf_results.sort_values(\"roc_auc\", ascending=False).iloc[0]\n",
    "best_lgbm = lgbm_results.sort_values(\"roc_auc\", ascending=False).iloc[0]\n",
    "best_xgb  = xgb_results.sort_values(\"roc_auc\", ascending=False).iloc[0]\n",
    "best_lr  = lr_results.sort_values(\"roc_auc\", ascending=False).iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame([\n",
    "    {\"model\": \"RF\",   **best_rf},\n",
    "    {\"model\": \"LGBM\", **best_lgbm},\n",
    "    {\"model\": \"XGB\",  **best_xgb},\n",
    "    {\"model\": \"LR\",  **best_lr},\n",
    "])\n",
    "\n",
    "compare_df = compare_df[\n",
    "    [\"model\", \"roc_auc\", \"avg_precision\", \"brier\", \"accuracy\", \"f1\"]\n",
    "]\n",
    "\n",
    "compare_df.sort_values(\"roc_auc\", ascending=False)\n",
    "\n",
    "# LGBM ì„ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "### ìµœì¢… ëª¨ë¸ í•™ìŠµ, í…ŒìŠ¤íŠ¸ (2023 -> 2024) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = lgbm_results.sort_values(\"roc_auc\", ascending=False).iloc[0].to_dict()\n",
    "\n",
    "# ğŸ”¥ intì—¬ì•¼ í•˜ëŠ” íŒŒë¼ë¯¸í„° ê°•ì œ ë³€í™˜\n",
    "int_params = [\"random_state\", \"seed\", \"n_estimators\", \"num_leaves\", \"max_depth\"]\n",
    "\n",
    "for p in int_params:\n",
    "    if p in best_params and best_params[p] is not None:\n",
    "        best_params[p] = int(best_params[p])\n",
    "\n",
    "best_model = LGBMClassifier(**best_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_metrics = evaluate_model(y_test, y_pred_test, y_proba_test)\n",
    "test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "## ê²€ì¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "### Hold-Out \n",
    "> - Train: 2019â€“2022\n",
    "> - Test : 2023 (â†’ 2024 ì„±ì¥ ì—¬ë¶€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# results = []\n",
    "\n",
    "# X_tr = X[years <= 2022].copy()\n",
    "# y_tr = y[years <= 2022]\n",
    "\n",
    "# X_te = X[years == 2023].copy()\n",
    "# y_te = y[years == 2023]\n",
    "\n",
    "# X_tr, X_te = fill_na_train_test(X_tr, X_te, feature_cols)\n",
    "\n",
    "# for name, model in tqdm(models.items(), desc=\"Hold-out\"):\n",
    "#     model.fit(X_tr, y_tr)\n",
    "\n",
    "#     prob = model.predict_proba(X_te)[:, 1]\n",
    "#     pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "#     results.append({\n",
    "#         \"model\": name,\n",
    "#         \"validation\": \"Holdout\",\n",
    "#         \"Accuracy\": accuracy_score(y_te, pred),\n",
    "#         \"ROC_AUC\": roc_auc_score(y_te, prob),\n",
    "#         \"PR_AUC\": average_precision_score(y_te, prob),\n",
    "#         \"Top20_P\": top_k_precision(y_te, prob, 20),\n",
    "#         \"Top50_P\": top_k_precision(y_te, prob, 50),\n",
    "#         \"F1\": f1_score(y_te, pred),\n",
    "#         \"Brier\": brier_score_loss(y_te, prob)\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_validation(model, X, y, years):\n",
    "    train_mask = years <= 2021\n",
    "    val_mask   = years == 2022\n",
    "\n",
    "    X_tr, y_tr = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    return evaluate_model(y_val, y_pred, y_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "### GroupKFold ê²€ì¦\n",
    "- ê°™ì€ ê¸°ì—…ì´ Train / Test ì— ë™ì‹œì— ë“±ì¥ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# for name, model in tqdm(models.items(), desc=\"GroupKFold\"):\n",
    "#     scores = []\n",
    "\n",
    "#     for tr_idx, te_idx in gkf.split(X, y, groups):\n",
    "#         X_tr, X_te = X.iloc[tr_idx].copy(), X.iloc[te_idx].copy()\n",
    "#         y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "#         X_tr, X_te = fill_na_train_test(X_tr, X_te, feature_cols)\n",
    "\n",
    "#         model.fit(X_tr, y_tr)\n",
    "#         prob = model.predict_proba(X_te)[:, 1]\n",
    "#         pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "#         scores.append({\n",
    "#             \"Accuracy\": accuracy_score(y_te, pred),\n",
    "#             \"ROC_AUC\": roc_auc_score(y_te, prob),\n",
    "#             \"PR_AUC\": average_precision_score(y_te, prob),\n",
    "#             \"Top20_P\": top_k_precision(y_te, prob, 20),\n",
    "#             \"Top50_P\": top_k_precision(y_te, prob, 50),\n",
    "#             \"F1\": f1_score(y_te, pred),\n",
    "#             \"Brier\": brier_score_loss(y_te, prob)\n",
    "#         })\n",
    "\n",
    "#     avg = pd.DataFrame(scores).mean().to_dict()\n",
    "#     avg.update({\"model\": name, \"validation\": \"GroupKFold\"})\n",
    "#     results.append(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def group_kfold_validation(model, X, y, groups, n_splits=5):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        scores.append(evaluate_model(y_val, y_pred, y_proba))\n",
    "\n",
    "    return pd.DataFrame(scores).mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "### Rolling Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling_years = [2021, 2022, 2023]\n",
    "\n",
    "# for name, model in tqdm(models.items(), desc=\"Rolling\"):\n",
    "#     scores = []\n",
    "\n",
    "#     for test_year in rolling_years:\n",
    "#         X_tr = X[years < test_year].copy()\n",
    "#         y_tr = y[years < test_year]\n",
    "\n",
    "#         X_te = X[years == test_year].copy()\n",
    "#         y_te = y[years == test_year]\n",
    "\n",
    "#         X_tr, X_te = fill_na_train_test(X_tr, X_te, feature_cols)\n",
    "\n",
    "#         model.fit(X_tr, y_tr)\n",
    "#         prob = model.predict_proba(X_te)[:, 1]\n",
    "#         pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "#         scores.append({\n",
    "#             \"Accuracy\": accuracy_score(y_te, pred),\n",
    "#             \"ROC_AUC\": roc_auc_score(y_te, prob),\n",
    "#             \"PR_AUC\": average_precision_score(y_te, prob),\n",
    "#             \"Top20_P\": top_k_precision(y_te, prob, 20),\n",
    "#             \"Top50_P\": top_k_precision(y_te, prob, 50),\n",
    "#             \"F1\": f1_score(y_te, pred),\n",
    "#             \"Brier\": brier_score_loss(y_te, prob)\n",
    "#         })\n",
    "\n",
    "#     avg = pd.DataFrame(scores).mean().to_dict()\n",
    "#     avg.update({\"model\": name, \"validation\": \"Rolling\"})\n",
    "#     results.append(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rolling_validation(model, X, y, years):\n",
    "#     results = []\n",
    "\n",
    "#     rolling_years = [\n",
    "#         (2019, 2020),\n",
    "#         (2020, 2021),\n",
    "#         (2021, 2022),\n",
    "#         (2022, 2023),\n",
    "#     ]\n",
    "\n",
    "#     for train_end, val_year in rolling_years:\n",
    "#         train_mask = years <= train_end\n",
    "#         val_mask   = years == val_year\n",
    "\n",
    "#         X_tr, y_tr = X[train_mask], y[train_mask]\n",
    "#         X_val, y_val = X[val_mask], y[val_mask]\n",
    "\n",
    "#         model.fit(X_tr, y_tr)\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#         res = evaluate_model(y_val, y_pred, y_proba)\n",
    "#         res[\"train_end\"] = train_end\n",
    "#         res[\"val_year\"] = val_year\n",
    "#         results.append(res)\n",
    "\n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "def rolling_validation(model, X, y, years):\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_end in sorted(years.unique()):\n",
    "        val_year = train_end + 1\n",
    "\n",
    "        train_mask = years <= train_end\n",
    "        val_mask   = years == val_year\n",
    "\n",
    "        # âœ… pandas ê¸°ì¤€ slicing (ì¤‘ìš”)\n",
    "        X_tr  = X.loc[train_mask]\n",
    "        y_tr  = y.loc[train_mask]\n",
    "        X_val = X.loc[val_mask]\n",
    "        y_val = y.loc[val_mask]\n",
    "\n",
    "        # ğŸ”¥ ë°©ì–´ 1: ìƒ˜í”Œ ìˆ˜\n",
    "        if X_tr.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # ğŸ”¥ ë°©ì–´ 2: trainì— í´ë˜ìŠ¤ 2ê°œ ì´ìƒ\n",
    "        if y_tr.nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        # ğŸ”¥ ë°©ì–´ 3: valì— í´ë˜ìŠ¤ ì¡´ì¬\n",
    "        if y_val.nunique() < 1:\n",
    "            continue\n",
    "\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred  = model_clone.predict(X_val)\n",
    "        y_proba = model_clone.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        fold_scores.append(\n",
    "            evaluate_model(y_val, y_pred, y_proba)\n",
    "        )\n",
    "\n",
    "    if len(fold_scores) == 0:\n",
    "        return None\n",
    "\n",
    "    return pd.DataFrame(fold_scores).mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ë³„ ì „ë¶€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "# ğŸ”¥ íŠ¸ë¦¬ ëª¨ë¸ë§Œ 3ì¢… ê²€ì¦\n",
    "for name, model in tree_models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "\n",
    "    all_results[name] = {\n",
    "        \"holdout\": holdout_validation(\n",
    "            model, X_train_full, y_train_full, years_train\n",
    "        ),\n",
    "        \"groupkfold\": group_kfold_validation(\n",
    "            model, X_train_full, y_train_full, groups_train\n",
    "        ),\n",
    "        \"rolling\": rolling_validation(\n",
    "            model, X_train_full, y_train_full, years_train\n",
    "        )\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model_name, validations in all_results.items():\n",
    "    for val_type, metrics in validations.items():\n",
    "\n",
    "        if metrics is None:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"model\": model_name,\n",
    "            \"validation\": val_type\n",
    "        }\n",
    "        row.update(metrics)\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "run_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=f\"validation_summary_{run_ts}\"\n",
    "):\n",
    "\n",
    "    # 1ï¸âƒ£ ì „ì²´ ê²°ê³¼ CSV ì €ì¥\n",
    "    summary_path = f\"validation_results_summary_{run_ts}.csv\"\n",
    "    results_df.to_csv(summary_path, index=False)\n",
    "    mlflow.log_artifact(summary_path)\n",
    "\n",
    "    # 2ï¸âƒ£ í•µì‹¬ metricë§Œ ìš”ì•½í•´ì„œ logging (ì„ íƒ)\n",
    "    for _, row in results_df.iterrows():\n",
    "        prefix = f\"{row['model']}_{row['validation']}\"\n",
    "\n",
    "        mlflow.log_metric(f\"{prefix}_roc_auc\", row[\"roc_auc\"])\n",
    "        mlflow.log_metric(f\"{prefix}_f1\", row[\"f1\"])\n",
    "        mlflow.log_metric(f\"{prefix}_avg_precision\", row[\"avg_precision\"])\n",
    "        mlflow.log_metric(f\"{prefix}_brier\", row[\"brier\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_metrics = [\"roc_auc\", \"avg_precision\", \"brier\"]\n",
    "\n",
    "compare_table = (\n",
    "    results_df\n",
    "    .pivot_table(\n",
    "        index=\"model\",\n",
    "        columns=\"validation\",\n",
    "        values=key_metrics\n",
    "    )\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "compare_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "- â‘  ê²€ì¦ì—ì„œ ê³ ë¥¸ best_paramsë¡œ\n",
    "- â‘¡ 2023ë…„ê¹Œì§€ ëª¨ë“  ë°ì´í„°ë¡œ ì¬í•™ìŠµí•˜ê³ \n",
    "- â‘¢ 2024ë…„ ë§ í”¼ì²˜ë¥¼ ë„£ì–´\n",
    "- â‘£ 2025ë…„ ì„±ì¥ í™•ë¥ ì„ ì˜ˆì¸¡í•œë‹¤"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
