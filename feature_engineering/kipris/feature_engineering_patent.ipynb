{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import parallel_backend\n",
    "import contextlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @contextlib.contextmanager\n",
    "# def tqdm_joblib(tqdm_object):\n",
    "#     from joblib import Parallel\n",
    "#     old_batch_callback = Parallel.BatchCompletionCallBack\n",
    "\n",
    "#     class TqdmBatchCompletionCallBack(old_batch_callback):\n",
    "#         def __call__(self, *args, **kwargs):\n",
    "#             tqdm_object.update(n=self.batch_size)\n",
    "#             return super().__call__(*args, **kwargs)\n",
    "\n",
    "#     Parallel.BatchCompletionCallBack = TqdmBatchCompletionCallBack\n",
    "#     try:\n",
    "#         yield tqdm_object\n",
    "#     finally:\n",
    "#         Parallel.BatchCompletionCallBack = old_batch_callback\n",
    "#         tqdm_object.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# ì¬ë¬´ì •ë³´_final_v2(16~24) íŒŒì¼ ì—´ê¸°\n",
    "- ê¸°ì—… ì •ë³´ë§Œì„ ìœ„í•´ ì—´ì–´ë³´ëŠ” íŒŒì¼\n",
    "    - ì¬ë¬´ ë°ì´í„°ì— ë“±ì¥í•œ ëª¨ë“  ê¸°ì—…\n",
    "    - ì—°ë„ë³„ë¡œ ì‚´ì•„ ìˆì—ˆë˜ ê¸°ì—…\n",
    "    - íŠ¹í—ˆ ì—¬ë¶€ì™€ ë¬´ê´€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df = pd.read_csv('../../data/ì¬ë¬´ì •ë³´_final_v2(16~24)_ìˆ˜ì •_ìµœì¢….csv', encoding=\"utf-8\", encoding_errors='replace', engine=\"python\")\n",
    "# financial_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "---\n",
    "- ì¬ë¬´ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì • ì „: financial_df['ë§¤ì¶œì•¡']ë§Œ ì²˜ë¦¬í•˜ë˜ ë¶€ë¶„ (cell_id: e58a3433 ë¶€ê·¼)\n",
    "# ìˆ˜ì • í›„: ëª¨ë“  ì£¼ìš” ì¬ë¬´ ì»¬ëŸ¼ì— ëŒ€í•´ ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "\n",
    "financial_cols = [\n",
    "    'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', \n",
    "    'ìë³¸ì´ê³„', 'ì—°êµ¬ê°œë°œë¹„', 'ìœ í˜•ìì‚°_ë‹¹ê¸°', 'ìœ í˜•ìì‚°_ì „ê¸°', 'ìœ í˜•ìì‚°_ì¦ê°'\n",
    "]\n",
    "\n",
    "for col in financial_cols:\n",
    "    if col in financial_df.columns:\n",
    "        # 1. ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì½¤ë§ˆ(,) ì œê±° ë° ê³µë°± ì œê±°\n",
    "        # 2. '-' í‘œì‹œë¥¼ '0'ìœ¼ë¡œ ë³€ê²½\n",
    "        financial_df[col] = (\n",
    "            financial_df[col]\n",
    "            .astype(str)\n",
    "            .str.replace(',', '', regex=False)\n",
    "            .str.replace(' ', '', regex=False)\n",
    "            .replace('-', '0')\n",
    "        )\n",
    "        # 3. ìˆ˜ì¹˜í˜•(float)ìœ¼ë¡œ ë³€í™˜, ë³€í™˜ ë¶ˆê°€ í•­ëª©ì€ NaN ì²˜ë¦¬ í›„ 0ìœ¼ë¡œ ì±„ì›€\n",
    "        financial_df[col] = pd.to_numeric(financial_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "print(\"ì¬ë¬´ ë°ì´í„° ìˆ˜ì¹˜í˜• ë³€í™˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# íŠ¹í—ˆì •ë³´_final íŒŒì¼ ì—´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final = pd.read_csv('../../data/íŠ¹í—ˆì •ë³´_final_v2.csv', encoding=\"cp949\", encoding_errors='replace', engine=\"python\")\n",
    "# patent_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final = patent_final.rename(columns={\n",
    "    'ipcNumber_IPCì½”ë“œ': 'ipcNumber',\n",
    "    'applicationDate_ì¶œì›ì¼ì': 'applicationDate',\n",
    "    'astrtCont_ì´ˆë¡':'astrtCont',\n",
    "    'applicationNumber_ì¶œì›ë²ˆí˜¸':'applicationNumber',\n",
    "     'registerDate_ë“±ë¡ì¼ì':'registerDate',\n",
    "      'indexNo_ì¼ë ¨ë²ˆí˜¸':'indexNo',\n",
    " 'registerStatus_ë“±ë¡ìƒíƒœ':'registerStatus',\n",
    " 'inventionTitle_ë°œëª…ì˜ëª…ì¹­':'inventionTitle',\n",
    " 'applicantName_ì¶œì›ì¸ëª…':'applicantName'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "---\n",
    "- íŠ¹í—ˆ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df = patent_final.copy()\n",
    "\n",
    "# ì¶œì›ì¼ datetime ë³´ì¥\n",
    "patent_df['applicationDate'] = pd.to_datetime(patent_df['applicationDate'])\n",
    "\n",
    "# ì¶œì›ë…„ë„ \n",
    "patent_df['application_year'] = patent_df['applicationDate'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df['application_year'] = pd.to_numeric(\n",
    "    patent_df['application_year'],\n",
    "    errors='coerce'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "---\n",
    "- ê¸°ì—…ëª… ì •ê·œí™”\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_company_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "\n",
    "    name = str(name)\n",
    "\n",
    "    # 1. ì†Œë¬¸ì ë³€í™˜\n",
    "    name = name.lower()\n",
    "\n",
    "    # 2. ë²•ì¸ í‘œê¸° ì œê±°\n",
    "    name = re.sub(r'\\(ì£¼\\)|ãˆœ|ì£¼ì‹íšŒì‚¬', '', name)\n",
    "\n",
    "    # 3. ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°\n",
    "    name = re.sub(r'\\s+', '', name)\n",
    "\n",
    "    # 4. íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•„ìš” ìµœì†Œ)\n",
    "    name = re.sub(r'[^\\wê°€-í£]', '', name)\n",
    "\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================================================\n",
    "# ë‘ ë°ì´í„°ì— ë™ì¼í•˜ê²Œ ì ìš© \n",
    "#=====================================================================================\n",
    "financial_df['company_norm'] = financial_df['ê¸°ì—…ëª…'].apply(normalize_company_name)\n",
    "patent_df['company_norm'] = patent_df['company_name'].apply(normalize_company_name)\n",
    "\n",
    "#=====================================================================================\n",
    "# ë§¤ì¹­ í’ˆì§ˆ ì§„ë‹¨\n",
    "#=====================================================================================\n",
    "\n",
    "# ì¬ë¬´ ê¸°ì¤€ ê¸°ì—… ìˆ˜\n",
    "financial_companies = set(financial_df['company_norm'].dropna())\n",
    "\n",
    "# íŠ¹í—ˆ ê¸°ì¤€ ê¸°ì—… ìˆ˜\n",
    "patent_companies = set(patent_df['company_norm'].dropna())\n",
    "\n",
    "print(\"ì¬ë¬´ ê¸°ì—… ìˆ˜:\", len(financial_companies))\n",
    "print(\"íŠ¹í—ˆ ê¸°ì—… ìˆ˜:\", len(patent_companies))\n",
    "print(\"êµì§‘í•© ìˆ˜:\", len(financial_companies & patent_companies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_year_df = (\n",
    "    financial_df[['company_norm', 'ì—°ë„']]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(['company_norm', 'ì—°ë„'])\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# íŠ¹í—ˆ í”¼ì²˜ ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_patent_features(company_norm, t, patent_df):\n",
    "    \"\"\"\n",
    "    company_norm Ã— ì—°ë„(t) ê¸°ì¤€ íŠ¹í—ˆ í”¼ì²˜ ìƒì„±\n",
    "    - warm-up ì ìš©: t < 2019 â†’ None\n",
    "    - ëˆ„ìˆ˜ ë°©ì§€: t-1 ì‹œì ê¹Œì§€ë§Œ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "\n",
    "    # ===============================\n",
    "    # 0. Warm-up ê°•ì œ\n",
    "    # ===============================\n",
    "    t = int(t)\n",
    "    if t < 2019:\n",
    "        return None\n",
    "\n",
    "    # ê¸°ì—… ê¸°ì¤€ í•„í„°\n",
    "    df = patent_df[patent_df['company_norm'] == company_norm].copy()\n",
    "\n",
    "    # ===============================\n",
    "    # 1. ê¸°ê°„ í•„í„° (ëˆ„ìˆ˜ ë°©ì§€ í•µì‹¬)\n",
    "    # ===============================\n",
    "    window_5y = df[\n",
    "        (df['application_year'] >= t - 4) &\n",
    "        (df['application_year'] <= t - 1)\n",
    "    ]\n",
    "\n",
    "    window_recent = df[\n",
    "        (df['application_year'] >= t - 2) &\n",
    "        (df['application_year'] <= t - 1)\n",
    "    ]\n",
    "\n",
    "    # # ë“±ë¡ë¥  ì½”í˜¸íŠ¸: t-4 ~ t-3\n",
    "    # cohort_register = df[\n",
    "    #     (df['application_year'] >= t - 4) &\n",
    "    #     (df['application_year'] <= t - 3)\n",
    "    # ]\n",
    "\n",
    "    # í”¼ì¸ìš© as-of cutoff\n",
    "    citation_window = window_5y[\n",
    "        window_5y['applicationDate'] <= pd.Timestamp(f\"{t-1}-12-31\")\n",
    "    ].copy()\n",
    "\n",
    "    # ===============================\n",
    "    # 2. í”¼ì²˜ ê³„ì‚°\n",
    "    # ===============================\n",
    "    patent_count_5y = len(window_5y)\n",
    "    patent_count_recent = len(window_recent)\n",
    "\n",
    "    ipc_diversity = (\n",
    "        window_5y['ipcNumber']\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str[:4]\n",
    "        .nunique()\n",
    "        if patent_count_5y > 0 else 0\n",
    "    )\n",
    "\n",
    "    # # ë“±ë¡ë¥ : registerDate ê¸°ì¤€\n",
    "    # if len(cohort_register) > 0:\n",
    "    #     patent_register_rate = (\n",
    "    #         cohort_register['registerDate'].notna().mean()\n",
    "    #     )\n",
    "    # else:\n",
    "    #     patent_register_rate = 0.0\n",
    "    # ===============================\n",
    "    # ë“±ë¡ë¥  ì½”í˜¸íŠ¸: t-4 ~ t-3\n",
    "    # ===============================\n",
    "    VALID_SUCCESS_STATUS = ['ë“±ë¡', 'ê³µê°œ']\n",
    "    cohort_register = df[\n",
    "        (df['application_year'] >= t - 4) &\n",
    "        (df['application_year'] <= t - 3)\n",
    "    ]\n",
    "\n",
    "    if len(cohort_register) > 0:\n",
    "        # ì „ì²´ ì¶œì› ìˆ˜\n",
    "        total_applications = len(cohort_register)\n",
    "\n",
    "        # ë“±ë¡ + ê³µê°œ ê±´ìˆ˜\n",
    "        success_count = cohort_register[\n",
    "            cohort_register['registerStatus'].isin(['ë“±ë¡', 'ê³µê°œ'])\n",
    "        ].shape[0]\n",
    "\n",
    "        patent_register_rate = success_count / total_applications\n",
    "    else:\n",
    "        patent_register_rate = 0.0\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # í”¼ì¸ìš© (ê¸°ë³¸)\n",
    "    # -------------------------------\n",
    "    patent_citation_total = (\n",
    "        citation_window['í”¼ì¸ìš© íšŸìˆ˜'].sum()\n",
    "        if len(citation_window) > 0 else 0.0\n",
    "    )\n",
    "\n",
    "    patent_citation_avg = (\n",
    "        patent_citation_total / max(1, patent_count_5y)\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # ğŸ”¥ ì—°ë ¹ ë³´ì • í”¼ì¸ìš©\n",
    "    # -------------------------------\n",
    "    if len(citation_window) > 0:\n",
    "        citation_window['patent_age'] = (\n",
    "            t - citation_window['application_year']\n",
    "        ).clip(lower=1)\n",
    "\n",
    "        citation_window['citation_per_year'] = (\n",
    "            citation_window['í”¼ì¸ìš© íšŸìˆ˜'] / citation_window['patent_age']\n",
    "        )\n",
    "\n",
    "        patent_citation_age_adj_total = (\n",
    "            citation_window['citation_per_year'].sum()\n",
    "        )\n",
    "    else:\n",
    "        patent_citation_age_adj_total = 0.0\n",
    "\n",
    "    patent_citation_age_adj_avg = (\n",
    "        patent_citation_age_adj_total / max(1, patent_count_5y)\n",
    "    )\n",
    "\n",
    "    # ===============================\n",
    "    # ìµœê·¼ í™œë™ ë¹„ì¤‘\n",
    "    # ===============================\n",
    "    patent_recent_ratio = (\n",
    "        patent_count_recent / patent_count_5y\n",
    "        if patent_count_5y > 0 else 0.0\n",
    "    )\n",
    "\n",
    "    citation_recent = (\n",
    "        window_recent['í”¼ì¸ìš© íšŸìˆ˜'].sum()\n",
    "        if len(window_recent) > 0 else 0.0\n",
    "    )\n",
    "\n",
    "    citation_recent_ratio = (\n",
    "        citation_recent / patent_citation_total\n",
    "        if patent_citation_total > 0 else 0.0\n",
    "    )\n",
    "\n",
    "    # ===============================\n",
    "    # ì—°ë„ë³„ íŠ¹í—ˆ ìˆ˜ (ì¦ê°€ìœ¨ ê³„ì‚°ìš©)\n",
    "    # ===============================\n",
    "    yearly_counts = (\n",
    "        window_5y\n",
    "        .groupby('application_year')\n",
    "        .size()\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    if len(yearly_counts) >= 2:\n",
    "        patent_growth_rate = yearly_counts.pct_change().iloc[-1]\n",
    "    else:\n",
    "        patent_growth_rate = 0.0\n",
    "\n",
    "    if len(yearly_counts) >= 3:\n",
    "        patent_growth_accel = (\n",
    "            yearly_counts.pct_change().diff().iloc[-1]\n",
    "        )\n",
    "    else:\n",
    "        patent_growth_accel = 0.0\n",
    "\n",
    "    # ===============================\n",
    "    # IPC êµ¬ì¡° ë³€í™”\n",
    "    # ===============================\n",
    "    ipc_old = set(\n",
    "        window_5y[\n",
    "            window_5y['application_year'] <= t - 3\n",
    "        ]['ipcNumber']\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str[:4]\n",
    "    )\n",
    "\n",
    "    ipc_recent = set(\n",
    "        window_recent['ipcNumber']\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str[:4]\n",
    "    )\n",
    "\n",
    "    if len(ipc_old) > 0:\n",
    "        new_ipc_ratio = len(ipc_recent - ipc_old) / len(ipc_old)\n",
    "        recent_ipc_overlap = len(ipc_recent & ipc_old) / len(ipc_old)\n",
    "    else:\n",
    "        new_ipc_ratio = 0.0\n",
    "        recent_ipc_overlap = 0.0\n",
    "\n",
    "    # ===============================\n",
    "    # ìµœê·¼ íŠ¹í—ˆ ì§ˆ\n",
    "    # ===============================\n",
    "    citation_per_patent_recent = (\n",
    "        citation_recent / max(1, patent_count_recent)\n",
    "    )\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # íŠ¹í—ˆ 0ê±´ í”Œë˜ê·¸\n",
    "    # -------------------------------\n",
    "    no_patent_flag = int(patent_count_5y == 0)\n",
    "\n",
    "    return {\n",
    "        'company_norm': company_norm,\n",
    "        'ì—°ë„': t,\n",
    "        'patent_count_5y': patent_count_5y,\n",
    "        'patent_count_recent': patent_count_recent,\n",
    "        'ipc_diversity': ipc_diversity,\n",
    "        'patent_register_rate': patent_register_rate,\n",
    "        'patent_citation_total': patent_citation_total,\n",
    "        'patent_citation_avg': patent_citation_avg,\n",
    "        # ğŸ”¥ ì¶”ê°€ í”¼ì²˜\n",
    "        'patent_citation_age_adj_total': patent_citation_age_adj_total,\n",
    "        'patent_citation_age_adj_avg': patent_citation_age_adj_avg,\n",
    "        'no_patent_flag': no_patent_flag,\n",
    "\n",
    "            # ğŸ”¥ ë³€í™”í˜• í”¼ì²˜\n",
    "        'patent_recent_ratio': patent_recent_ratio,\n",
    "        'citation_recent_ratio': citation_recent_ratio,\n",
    "        'patent_growth_rate': patent_growth_rate,\n",
    "        'patent_growth_accel': patent_growth_accel,\n",
    "        'new_ipc_ratio': new_ipc_ratio,\n",
    "        'recent_ipc_overlap': recent_ipc_overlap,\n",
    "        'citation_per_patent_recent': citation_per_patent_recent\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_feature_rows = []\n",
    "\n",
    "for row in tqdm(\n",
    "    company_year_df.itertuples(index=False),\n",
    "    total=len(company_year_df),\n",
    "    desc=\"íŠ¹í—ˆ í”¼ì²˜ ìƒì„±\"\n",
    "):\n",
    "    feat = make_patent_features(\n",
    "        company_norm=row.company_norm,\n",
    "        t=row.ì—°ë„,\n",
    "        patent_df=patent_df\n",
    "    )\n",
    "\n",
    "    if feat is not None:\n",
    "        patent_feature_rows.append(feat)\n",
    "\n",
    "patent_feature_df = pd.DataFrame(patent_feature_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_feature_df['ì—°ë„'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_feature_df.to_csv('../../output/feature_engineering_dataset_13_patent.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "- íŠ¹í—ˆ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê³¼ì •ì—ì„œ ë¡¤ë§ ìœˆë„ìš°ì˜ warm-up ê¸°ê°„ì„ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ê°•ì œí•˜ì—¬,\n",
    "ì¶©ë¶„í•œ ê³¼ê±° ë°ì´í„°ê°€ í™•ë³´ë˜ì§€ ì•Šì€ ì—°ë„(2019 ì´ì „)ê°€\n",
    "í•™ìŠµ ë°ì´í„°ì— í¬í•¨ë˜ì§€ ì•Šë„ë¡ ìˆ˜ì •í•˜ì˜€ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# ì¬ë¬´ ë°ì´í„°ì™€ ê²°í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df['ì—°ë„'] = pd.to_numeric(financial_df['ì—°ë„'], errors='coerce').astype('Int64')\n",
    "patent_feature_df['ì—°ë„'] = pd.to_numeric(patent_feature_df['ì—°ë„'], errors='coerce').astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df[['ì—°ë„']].dtypes, patent_feature_df[['ì—°ë„']].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df['ë§¤ì¶œì•¡'].isna().mean(), (financial_df['ë§¤ì¶œì•¡'] == 0).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_agg = (\n",
    "    financial_df\n",
    "    .groupby(['company_norm', 'ì—°ë„'], as_index=False)\n",
    "    .agg({\n",
    "        'ê¸°ì—…ëª…': 'first',\n",
    "        'ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸': 'first',\n",
    "        'crno': 'first',\n",
    "        'dart_corp_code': 'first',\n",
    "        'sectors': 'first',\n",
    "        'field': 'first',\n",
    "\n",
    "        'ë§¤ì¶œì•¡': 'sum',\n",
    "        'ì˜ì—…ì´ìµ': 'sum',\n",
    "        'ë‹¹ê¸°ìˆœì´ìµ': 'sum',\n",
    "        'ìì‚°ì´ê³„': 'max',\n",
    "        'ë¶€ì±„ì´ê³„': 'max',\n",
    "        'ìë³¸ì´ê³„': 'max',\n",
    "        'ì—°êµ¬ê°œë°œë¹„': 'sum',\n",
    "        'CAPEX': 'sum',\n",
    "        'ìœ í˜•ìì‚°_ë‹¹ê¸°': 'max',\n",
    "        'ìœ í˜•ìì‚°_ì „ê¸°': 'max',\n",
    "        'ìœ í˜•ìì‚°_ì¦ê°': 'sum'\n",
    "    })\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = financial_agg.merge(\n",
    "    patent_feature_df,\n",
    "    on=['company_norm', 'ì—°ë„'],\n",
    "    how='left',\n",
    "    validate='one_to_one'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(financial_agg), len(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['ë§¤ì¶œì•¡'].isna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('financial_df:',financial_df.columns)\n",
    "print('patent_feature_df:',patent_feature_df.columns)\n",
    "print('final_df:',final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(financial_df), len(final_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## íƒ€ê¹ƒ(y) ìƒì„± â€” â€œt ì •ë³´ë¡œ t+1 ì„±ì¥ ì—¬ë¶€ ì˜ˆì¸¡â€\n",
    "- í”¼ì²˜ ë°ì´í„°ì…‹ ì €ì¥í•  ë•Œ final_df ë¡œ í•´ì¤˜ì•¼ company_norm, ê¸°ì—…ëª… ì»¬ëŸ¼ ë‘˜ ë‹¤ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['revenue_growth'] = (\n",
    "    final_df\n",
    "    .groupby('company_norm')['ë§¤ì¶œì•¡']\n",
    "    .pct_change()       # pct_changeë¥¼ í†µí•´ì„œ ë§¤ì¶œ ì„±ì¥ë¥  ê³„ì‚°ë¨\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[\n",
    "    (final_df['ì—°ë„'] >= 2019) &\n",
    "    (final_df['ì—°ë„'] <= 2024)\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['ì—°ë„'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth_flag : ê°™ì€ ì—°ë„ ì•ˆì—ì„œ ì„±ì¥ë¥ ì´ ìƒìœ„ 30%ë©´ 1\n",
    "final_df['growth_flag'] = (\n",
    "    final_df\n",
    "    .groupby('ì—°ë„')['revenue_growth']\n",
    "    .transform(lambda x: (x >= x.quantile(0.7)).astype(int))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('ì—°ë„')['growth_flag'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y : ì˜¬í•´ì˜ ì •ë³´ë¡œ ë‹¤ìŒ í•´ì— ì˜ ì„±ì¥í•  ê¸°ì—…ì¸ì§€ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œ 1ë…„ ë’¤ë¡œ ë‹¹ê²¨ì„œ ë§Œë“¦\n",
    "final_df['y'] = (\n",
    "    final_df\n",
    "    .groupby('company_norm')['growth_flag']\n",
    "    .shift(-1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = final_df.dropna(subset=['y']).copy()\n",
    "model_df['y'] = model_df['y'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['ì—°ë„'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ì»¬ëŸ¼ë“¤ë§Œ ë‚¨ê¸°ê¸°\n",
    "keep_cols = [\n",
    "    # ì‹ë³„ / ì‹œì \n",
    "    'company_norm',\n",
    "    'ì—°ë„',\n",
    "    'ê¸°ì—…ëª…',\n",
    "\n",
    "    # íŠ¹í—ˆ í”¼ì²˜\n",
    "    'patent_count_5y',\n",
    "    'patent_count_recent',\n",
    "    'ipc_diversity',\n",
    "    'patent_register_rate',\n",
    "    'patent_citation_total',\n",
    "    'patent_citation_avg',\n",
    "    'patent_citation_age_adj_total',\n",
    "    'patent_citation_age_adj_avg',\n",
    "    'no_patent_flag',\n",
    "    'patent_recent_ratio', 'citation_recent_ratio',\n",
    "       'patent_growth_rate', 'patent_growth_accel', 'new_ipc_ratio',\n",
    "       'recent_ipc_overlap', 'citation_per_patent_recent'\n",
    "\n",
    "    # ì„±ì¥ ê´€ë ¨\n",
    "    # 'revenue_growth',\n",
    "    # 'growth_flag',\n",
    "    # 'y'\n",
    "]\n",
    "\n",
    "final_df = final_df[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../../output/feature_engineering_dataset_14_patent.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ë§\n",
    "- ëª¨ë¸ : LogReg, RandomForest, LightBGM, XGBoost\n",
    "- ê²€ì¦ ë°©ì‹ : Holdout, GroupKFold, RollingValidation\n",
    "- í‰ê°€ì§€í‘œ: PR-AUC, Top-20/50 Precision, F1, Brier\n",
    "---\n",
    "> - model_df : feature + y í¬í•¨ (ì •ìƒ)\n",
    "> - ì—°ë„ ë²”ìœ„ : 2019â€“2023\n",
    "> - y : të…„ í”¼ì²˜ â†’ t+1ë…„ ì„±ì¥ ì—¬ë¶€(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "# Xë‘ yì— ë“¤ì–´ê°ˆ df ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "- ê¸°ì¡´ì— ë§Œë“  model_df ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¬ë¬´ ë°ì´í„° ì •ê·œí™”ëœ ë°ì´í„°ì™€ ì •ë‹µ ë°ì´í„° ë”°ë¡œ ë°›ì€ í›„ ê²°í•©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "### feature ë°ì´í„° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('../../data/normalized_patent_features_add.csv', encoding=\"utf-8\", encoding_errors='replace', engine=\"python\")\n",
    "feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.columns.to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "### ì •ë‹µ ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv('../../data/ì—°ë„ë³„ ì„±ì¥ì—¬ë¶€.csv', encoding=\"utf-8\", encoding_errors='replace', engine=\"python\")\n",
    "target_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_long_df = target_df.melt(\n",
    "    id_vars=\"ê¸°ì—…ëª…\",        # ê³ ì •í•  ì»¬ëŸ¼\n",
    "    var_name=\"ì—°ë„\",        # ìƒˆë¡œ ìƒê¸¸ ì—°ë„ ì»¬ëŸ¼ ì´ë¦„\n",
    "    value_name=\"y\"          # íƒ€ê²Ÿ ë³€ìˆ˜\n",
    ")\n",
    "\n",
    "target_long_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_long_df.to_csv('../../output/ì—°ë„ë³„_ì„±ì¥ì—¬ë¶€_ì»¬ëŸ¼ë³€í™˜.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ë°ì´í„° ì—°ë„ â†’ int\n",
    "feature_df[\"ì—°ë„\"] = feature_df[\"ì—°ë„\"].astype(int)\n",
    "\n",
    "# target ë°ì´í„° ì—°ë„ â†’ int\n",
    "target_long_df[\"ì—°ë„\"] = target_long_df[\"ì—°ë„\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = feature_df.merge(\n",
    "    target_long_df,\n",
    "    left_on=[\"ê¸°ì—…ëª…\", \"target_year\"],\n",
    "    right_on=[\"ê¸°ì—…ëª…\", \"ì—°ë„\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "model_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns.tolist()\n",
    "\n",
    "\n",
    "# ì™¼ìª½ ì—°ë„  â†’ ì—°ë„_x\n",
    "# ì˜¤ë¥¸ìª½ ì—°ë„ â†’ ì—°ë„_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "## Feature / Label ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Feature ê·¸ë£¹ ì •ì˜\n",
    "# -------------------------\n",
    "\n",
    "patent_cols = [\n",
    "    'patent_count_5y',\n",
    "    'patent_count_recent',\n",
    "    'ipc_diversity',\n",
    "    'patent_register_rate',\n",
    "    'patent_citation_total',\n",
    "    'patent_citation_avg',\n",
    "    'patent_citation_age_adj_total',\n",
    "    'patent_citation_age_adj_avg',\n",
    "    'no_patent_flag',\n",
    "    'patent_recent_ratio',\n",
    "       'citation_recent_ratio', 'patent_growth_rate', 'patent_growth_accel',\n",
    "       'new_ipc_ratio', 'recent_ipc_overlap', 'citation_per_patent_recent'\n",
    "]\n",
    "\n",
    "patent_emb_cols = [f'patent_emb_{i}' for i in range(50)]\n",
    "\n",
    "#====================================\n",
    "# íŠ¹í—ˆ ì •ëŸ‰ ì§€í‘œë§Œ ì“°ê³  ì‹¶ì„ ë–„ \n",
    "X = model_df[patent_cols].copy()\n",
    "\n",
    "# ì„ë² ë”© ê°™ì´ ì“°ê³  ì‹¶ì„ ë•Œ\n",
    "# X = model_df[patent_cols + patent_emb_cols].copy()\n",
    "#====================================\n",
    "y = model_df['y'].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## train/test ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Time-based Train / Test Split\n",
    "# =====================================\n",
    "\n",
    "# 1. ìµœì¢… í…ŒìŠ¤íŠ¸ ì—°ë„ ì§€ì •\n",
    "TEST_TARGET_YEAR = 2024\n",
    "\n",
    "# 2. Train / Test ì¸ë±ìŠ¤ ë¶„ë¦¬\n",
    "train_idx = model_df['target_year'] < TEST_TARGET_YEAR\n",
    "test_idx  = model_df['target_year'] == TEST_TARGET_YEAR\n",
    "\n",
    "# 3. ë¶„ë¦¬\n",
    "X_train = X.loc[train_idx].copy()\n",
    "y_train = y.loc[train_idx].copy()\n",
    "\n",
    "X_test  = X.loc[test_idx].copy()\n",
    "y_test  = y.loc[test_idx].copy()\n",
    "\n",
    "# Time-based split ê²°ê³¼\n",
    "print(\"Train target years:\", sorted(y_train.index.map(lambda i: model_df.loc[i, 'target_year']).unique()))\n",
    "print(\"Test target year:\", model_df.loc[test_idx, 'target_year'].unique())\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test NaN ê°œìˆ˜:\", y_test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ë°ì´í„°\n",
    "train_df = X_train.copy()\n",
    "train_df[\"target\"] = y_train\n",
    "train_df = train_df.dropna(subset=[\"target\"])\n",
    "\n",
    "X_train = train_df.drop(columns=\"target\")\n",
    "y_train = train_df[\"target\"]\n",
    "\n",
    "# test ë°ì´í„°\n",
    "test_df = X_test.copy()\n",
    "test_df[\"target\"] = y_test\n",
    "test_df = test_df.dropna(subset=[\"target\"])\n",
    "\n",
    "X_test = test_df.drop(columns=\"target\")\n",
    "y_test = test_df[\"target\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- 2019 â†’ 2020 (Train)\n",
    "\n",
    "- 2020 â†’ 2021 (Train)\n",
    "\n",
    "- 2021 â†’ 2022 (Train)\n",
    "\n",
    "- 2022 â†’ 2023 (Train)\n",
    "\n",
    "- 2023 â†’ 2024 (Test) âœ…\n",
    "\n",
    "ğŸ‘‰ ë¯¸ë˜ ì •ë³´ ì„ì¸ ê±° ì—†ìŒ (ë°ì´í„° ëˆ„ìˆ˜ âŒ)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "- feature ê°œìˆ˜ : 9ê°œ\n",
    "- train/test ë¹„ìœ¨ : ì•½ 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°ë„ ì •ë³´ (ë³´ì¡° ë³€ìˆ˜)\n",
    "years_train = model_df.loc[train_idx, 'target_year'].copy()\n",
    "years_test  = model_df.loc[test_idx, 'target_year'].copy()\n",
    "\n",
    "print(sorted(years_train.unique()))\n",
    "print(sorted(years_test.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "## ê³µí†µ í‰ê°€ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top_k_precision(y_true, y_proba, k):\n",
    "    \"\"\"\n",
    "    Top-K Precision ê³„ì‚°\n",
    "    - y_proba ê¸°ì¤€ ìƒìœ„ Kê°œ ì„ íƒ\n",
    "    \"\"\"\n",
    "    if len(y_true) < k:\n",
    "        k = len(y_true)\n",
    "\n",
    "    top_k_idx = np.argsort(y_proba)[::-1][:k]\n",
    "    return y_true.iloc[top_k_idx].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss\n",
    ")\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_proba):\n",
    "    \"\"\"\n",
    "    ê³µí†µ ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ (ì„±ì¥ê¸°ì—… ì˜ˆì¸¡ ëª©ì )\n",
    "    - PR-AUC\n",
    "    - Top-K Precision (K=20, 50)\n",
    "    - F1 Score\n",
    "    - Brier Score\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "        # PR-AUC\n",
    "        \"pr_auc\": average_precision_score(y_true, y_proba),\n",
    "\n",
    "        # Top-K Precision\n",
    "        \"top20_precision\": top_k_precision(y_true, y_proba, k=20),\n",
    "        \"top50_precision\": top_k_precision(y_true, y_proba, k=50),\n",
    "\n",
    "        # Classification balance\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "\n",
    "        # Probability calibration\n",
    "        \"brier\": brier_score_loss(y_true, y_proba)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "## K-fold ê²€ì¦ \n",
    "- ê³¼ì í•© ìˆëŠ”ì§€ íŒë‹¨í•˜ê¸° ìœ„í•´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "def cross_validate_overfitting_check(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Train ë°ì´í„° ë‚´ë¶€ì—ì„œ k-foldë¡œ ê³¼ì í•© ì§„ë‹¨\n",
    "    - metric: PR-AUC\n",
    "    \"\"\"\n",
    "\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    pr_auc_scores = []\n",
    "\n",
    "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        # ğŸ”¹ foldë§ˆë‹¤ ëª¨ë¸ ë³µì œ (ì¤‘ìš”)\n",
    "        fold_model = clone(model)\n",
    "\n",
    "        X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        fold_model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_val_proba = fold_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        score = average_precision_score(y_val, y_val_proba)\n",
    "        pr_auc_scores.append(score)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold} PR-AUC: {score:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"cv_pr_auc_mean\": np.mean(pr_auc_scores),\n",
    "        \"cv_pr_auc_std\": np.std(pr_auc_scores),\n",
    "        \"cv_pr_auc_min\": np.min(pr_auc_scores),\n",
    "        \"cv_pr_auc_max\": np.max(pr_auc_scores)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ + í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "MODELS = {\n",
    "    \"Logistic\": (\n",
    "        LogisticRegression(\n",
    "            max_iter=2000,\n",
    "            class_weight=\"balanced\",\n",
    "            solver=\"liblinear\"\n",
    "        ),\n",
    "        {\"C\": [0.01, 0.1, 1, 10]}\n",
    "    ),\n",
    "\n",
    "    \"RF\": (\n",
    "        RandomForestClassifier(\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\"\n",
    "        ),\n",
    "        {\n",
    "            \"n_estimators\": [300, 500],\n",
    "            \"max_depth\": [None, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 5, 10]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"XGB\": (\n",
    "        XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"aucpr\",\n",
    "            random_state=42,\n",
    "            use_label_encoder=False\n",
    "        ),\n",
    "        {\n",
    "            \"n_estimators\": [300, 600],\n",
    "            \"max_depth\": [3, 5],\n",
    "            \"learning_rate\": [0.03, 0.1],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0]\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    \"LGBM\": (\n",
    "        LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            random_state=42\n",
    "        ),\n",
    "        {\n",
    "            \"n_estimators\": [300, 600],\n",
    "            \"learning_rate\": [0.03, 0.1],\n",
    "            \"num_leaves\": [31, 63],\n",
    "            \"max_depth\": [-1, 10],\n",
    "            \"subsample\": [0.8, 1.0],\n",
    "            \"colsample_bytree\": [0.8, 1.0]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "\n",
    "pr_auc_scorer = make_scorer(\n",
    "    average_precision_score,\n",
    "    needs_proba=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# ì‹¤í—˜ ì´ë¦„ ì§€ì •\n",
    "mlflow.set_experiment(\"growth_prediction_time_based\")\n",
    "\n",
    "results = []\n",
    "TEST_TARGET_YEAR = 2024\n",
    "\n",
    "for feature_set_name, feature_cols in FEATURE_SETS.items():\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"ğŸ§ª Feature set: {feature_set_name}\")\n",
    "\n",
    "    X_feat = X_all[feature_cols]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = make_time_based_split_from_xy(\n",
    "        X=X_feat,\n",
    "        y=y_all,\n",
    "        time_series=time_series,\n",
    "        test_target_year=TEST_TARGET_YEAR\n",
    "    )\n",
    "\n",
    "    for model_name, (model, param_grid) in MODELS.items():\n",
    "        print(f\"\\nâ–¶ {model_name} tuning\")\n",
    "\n",
    "        with mlflow.start_run(\n",
    "            run_name=f\"{feature_set_name}_{model_name}\"\n",
    "        ):\n",
    "            # =========================\n",
    "            # 1. Tag\n",
    "            # =========================\n",
    "            mlflow.set_tag(\"feature_set\", feature_set_name)\n",
    "            mlflow.set_tag(\"model\", model_name)\n",
    "            mlflow.set_tag(\n",
    "                \"has_patent_embedding\",\n",
    "                \"EMB\" in feature_set_name\n",
    "            )\n",
    "\n",
    "            # =========================\n",
    "            # 2. Hyperparameter tuning\n",
    "            # =========================\n",
    "            grid = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                scoring=pr_auc_scorer,\n",
    "                cv=3,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            grid.fit(X_train, y_train)\n",
    "\n",
    "            best_model = grid.best_estimator_\n",
    "\n",
    "            # =========================\n",
    "            # 3. Prediction\n",
    "            # =========================\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            # =========================\n",
    "            # 4. Evaluation\n",
    "            # =========================\n",
    "            metrics = evaluate_model(y_test, y_pred, y_proba)\n",
    "\n",
    "            # =========================\n",
    "            # 5. MLflow logging\n",
    "            # =========================\n",
    "            mlflow.log_param(\"feature_set\", feature_set_name)\n",
    "            mlflow.log_param(\"model\", model_name)\n",
    "            mlflow.log_param(\"test_target_year\", TEST_TARGET_YEAR)\n",
    "\n",
    "            for k, v in grid.best_params_.items():\n",
    "                mlflow.log_param(f\"best_{k}\", v)\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                mlflow.log_metric(k, v)\n",
    "\n",
    "            # (ì„ íƒ) ëª¨ë¸ ì €ì¥\n",
    "            mlflow.sklearn.log_model(\n",
    "                best_model,\n",
    "                artifact_path=\"model\"\n",
    "            )\n",
    "\n",
    "            # =========================\n",
    "            # 6. ê²°ê³¼ í…Œì´ë¸”ìš© ì €ì¥\n",
    "            # =========================\n",
    "            row = {\n",
    "                \"feature_set\": feature_set_name,\n",
    "                \"model\": model_name,\n",
    "                \"n_features\": len(feature_cols),\n",
    "                \"best_params\": grid.best_params_\n",
    "            }\n",
    "            row.update(metrics)\n",
    "\n",
    "            results.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.sort_values(\n",
    "    by=[\"top20_precision\", \"pr_auc\"],\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì •ì˜(Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# Model Definitions\n",
    "# =====================================\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"XGB\": XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \"LGBM\": LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Baseline\n",
    "baseline_models = {\n",
    "    \"LogReg\": models[\"LogReg\"]\n",
    "}\n",
    "\n",
    "# Tree-based models\n",
    "tree_models = {\n",
    "    k: v for k, v in models.items()\n",
    "    if k != \"LogReg\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì „ ëª¨ë¸ ì„±ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    baseline_results[name] = auc\n",
    "    print(f\"{name} ROC-AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logreg = baseline_models[\"LogReg\"]\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"LogReg ROC-AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    brier_score_loss\n",
    ")\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, y_proba):\n",
    "    return {\n",
    "        # PR-AUC\n",
    "        \"pr_auc\": average_precision_score(y_true, y_proba),\n",
    "\n",
    "        # Top-K Precision\n",
    "        \"top20_precision\": top_k_precision(y_true, y_proba, k=20),\n",
    "        \"top50_precision\": top_k_precision(y_true, y_proba, k=50),\n",
    "\n",
    "        # Classification balance\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "\n",
    "        # Probability calibration\n",
    "        \"brier\": brier_score_loss(y_true, y_proba)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = []\n",
    "\n",
    "# 1) Tree ëª¨ë¸ë“¤\n",
    "for name, model in tree_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    metrics = evaluate_metrics(y_test, y_pred, y_proba)\n",
    "\n",
    "    baseline_results.append({\n",
    "        \"model\": name,\n",
    "        **metrics,\n",
    "        \"stage\": \"baseline (before tuning)\"\n",
    "    })\n",
    "\n",
    "# 2) Logistic Regression\n",
    "logreg = baseline_models[\"LogReg\"]\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_proba)\n",
    "\n",
    "baseline_results.append({\n",
    "    \"model\": \"LogReg\",\n",
    "    **metrics,\n",
    "    \"stage\": \"baseline (before tuning)\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "\n",
    "baseline_df = baseline_df.sort_values(\n",
    "    by=\"pr_auc\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "baseline_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "## í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹(ìš°ì„  ë³´ë¥˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def rolling_hyperparam_search(\n",
    "    model_class,\n",
    "    param_grid,\n",
    "    X, y, years,\n",
    "    start_year=2019,\n",
    "    end_year=2022\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "    for params in param_combinations:\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "        fold_scores = []\n",
    "\n",
    "        for train_end in range(start_year, end_year + 1):\n",
    "            val_year = train_end + 1\n",
    "\n",
    "            train_mask = years <= train_end\n",
    "            val_mask   = years == val_year\n",
    "\n",
    "            X_tr  = X.loc[train_mask]\n",
    "            y_tr  = y.loc[train_mask]\n",
    "\n",
    "            X_val = X.loc[val_mask]\n",
    "            y_val = y.loc[val_mask]\n",
    "\n",
    "\n",
    "            if X_tr.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            if y_tr.nunique() < 2:\n",
    "                continue\n",
    "\n",
    "\n",
    "            model = model_class(**param_dict)\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            y_pred = model.predict(X_val)\n",
    "            y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "            score = evaluate_model(y_val, y_pred, y_proba)\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        if len(fold_scores) == 0:\n",
    "            continue\n",
    "\n",
    "        avg_score = pd.DataFrame(fold_scores).mean().to_dict()\n",
    "        avg_score.update(param_dict)\n",
    "\n",
    "        results.append(avg_score)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ë³„ íŠœë‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"num_leaves\": [15, 31],\n",
    "    \"max_depth\": [-1, 5],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "lgbm_results = rolling_hyperparam_search(\n",
    "    LGBMClassifier,\n",
    "    lgbm_param_grid,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    years_train\n",
    ")\n",
    "\n",
    "lgbm_results.sort_values(\"pr_auc\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [4, 6],\n",
    "    \"learning_rate\": [0.03, 0.05],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.8],\n",
    "    \"eval_metric\": [\"logloss\"],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "xgb_results = rolling_hyperparam_search(\n",
    "    XGBClassifier,\n",
    "    xgb_param_grid,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    years_train\n",
    ")\n",
    "\n",
    "xgb_results.sort_values(\"pr_auc\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"min_samples_leaf\": [1, 3],\n",
    "    \"random_state\": [42],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "\n",
    "rf_results = rolling_hyperparam_search(\n",
    "    RandomForestClassifier,\n",
    "    rf_param_grid,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    years_train\n",
    ")\n",
    "\n",
    "rf_results.sort_values(\"pr_auc\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "### LR(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_param_grid = {\n",
    "    \"C\": [0.1, 1.0, 5.0],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\"],\n",
    "    \"max_iter\": [1000]\n",
    "}\n",
    "\n",
    "lr_results = rolling_hyperparam_search(\n",
    "    LogisticRegression,\n",
    "    lr_param_grid,\n",
    "    X_train,        \n",
    "    y_train,        \n",
    "    years_train\n",
    ")\n",
    "\n",
    "# PR-AUC ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (í•µì‹¬ ìˆ˜ì •)\n",
    "lr_results.sort_values(\"pr_auc\", ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "## ML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# 0. ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# =========================================================\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. ëª¨ë¸ ì„¤ì •\n",
    "# =========================================================\n",
    "model_configs = {\n",
    "    \"LogReg\": (\n",
    "        LogisticRegression,\n",
    "        {\n",
    "            \"C\": [0.1, 1.0, 5.0],\n",
    "            \"penalty\": [\"l2\"],\n",
    "            \"solver\": [\"lbfgs\"],\n",
    "            \"max_iter\": [1000]\n",
    "        }\n",
    "    ),\n",
    "    \"RF\": (\n",
    "        RandomForestClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [200, 400],\n",
    "            \"max_depth\": [5, 10],\n",
    "            \"min_samples_leaf\": [1, 3],\n",
    "            \"random_state\": [42],\n",
    "            \"n_jobs\": [-1]\n",
    "        }\n",
    "    ),\n",
    "    \"XGB\": (\n",
    "        XGBClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [200, 400],\n",
    "            \"max_depth\": [4, 6],\n",
    "            \"learning_rate\": [0.03, 0.05],\n",
    "            \"subsample\": [0.8],\n",
    "            \"colsample_bytree\": [0.8],\n",
    "            \"eval_metric\": [\"logloss\"],\n",
    "            \"random_state\": [42]\n",
    "        }\n",
    "    ),\n",
    "    \"LGBM\": (\n",
    "        LGBMClassifier,\n",
    "        {\n",
    "            \"n_estimators\": [200, 400],\n",
    "            \"learning_rate\": [0.03, 0.05],\n",
    "            \"num_leaves\": [15, 31],\n",
    "            \"max_depth\": [-1, 5],\n",
    "            \"random_state\": [42]\n",
    "        }\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. MLflow ì„¤ì •\n",
    "# =========================================================\n",
    "mlflow.set_experiment(\"growth_prediction_rolling\")\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. ëª¨ë¸ë³„ ë¡¤ë§ íŠœë‹ + ë¡œê¹…\n",
    "# =========================================================\n",
    "for model_name, (model_class, param_grid) in model_configs.items():\n",
    "\n",
    "    run_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(f\"\\n=== {model_name} rolling tuning ===\")\n",
    "\n",
    "    with mlflow.start_run(\n",
    "        run_name=f\"{model_name}_rolling_{run_ts}\"\n",
    "    ):\n",
    "\n",
    "        df_results = rolling_hyperparam_search(\n",
    "            model_class=model_class,\n",
    "            param_grid=param_grid,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            years=years_train,\n",
    "            start_year=2019,\n",
    "            end_year=2022\n",
    "        )\n",
    "\n",
    "        # âœ… PR-AUC ê¸°ì¤€ìœ¼ë¡œ best ì„ íƒ\n",
    "        best_row = df_results.sort_values(\n",
    "            \"pr_auc\", ascending=False\n",
    "        ).iloc[0]\n",
    "\n",
    "        best_params = {k: best_row[k] for k in param_grid.keys()}\n",
    "\n",
    "        # íƒ€ì… ì •ë¦¬\n",
    "        for k, v in best_params.items():\n",
    "            if isinstance(v, float) and k not in [\"learning_rate\"]:\n",
    "                best_params[k] = int(v)\n",
    "\n",
    "        # MLflow ë¡œê¹…\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"pr_auc\": best_row[\"pr_auc\"],\n",
    "            \"top20_precision\": best_row[\"top20_precision\"],\n",
    "            \"top50_precision\": best_row[\"top50_precision\"],\n",
    "            \"f1\": best_row[\"f1\"],\n",
    "            \"brier\": best_row[\"brier\"]\n",
    "        })\n",
    "\n",
    "        # ê²°ê³¼ CSV ì•„í‹°íŒ©íŠ¸\n",
    "        result_path = f\"{model_name}_rolling_results_{run_ts}.csv\"\n",
    "        df_results.to_csv(result_path, index=False)\n",
    "        mlflow.log_artifact(result_path)\n",
    "\n",
    "        results.append({\n",
    "            \"model\": model_name,\n",
    "            **best_params,\n",
    "            \"pr_auc\": best_row[\"pr_auc\"],\n",
    "            \"top20_precision\": best_row[\"top20_precision\"],\n",
    "            \"top50_precision\": best_row[\"top50_precision\"],\n",
    "            \"f1\": best_row[\"f1\"],\n",
    "            \"brier\": best_row[\"brier\"]\n",
    "        })\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. ì „ì²´ ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”\n",
    "# =========================================================\n",
    "summary_df = pd.DataFrame(results).sort_values(\n",
    "    \"pr_auc\", ascending=False\n",
    ")\n",
    "\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ë³„ ìµœê³  ì„±ëŠ¥ ë¹„êµ \n",
    "- ROC-AUC ìµœëŒ“ê°’ ê¸°ì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf   = rf_results.sort_values(\"pr_auc\", ascending=False).iloc[0]\n",
    "best_lgbm = lgbm_results.sort_values(\"pr_auc\", ascending=False).iloc[0]\n",
    "best_xgb  = xgb_results.sort_values(\"pr_auc\", ascending=False).iloc[0]\n",
    "best_lr  = lr_results.sort_values(\"pr_auc\", ascending=False).iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame([\n",
    "    {\"model\": \"RF\",   **best_rf},\n",
    "    {\"model\": \"LGBM\", **best_lgbm},\n",
    "    {\"model\": \"XGB\",  **best_xgb},\n",
    "    {\"model\": \"LR\",  **best_lr},\n",
    "])\n",
    "\n",
    "compare_df = compare_df[\n",
    "    [\"model\", \"pr_auc\", \"top20_precision\", \"top50_precision\", \"f1\", \"brier\"]\n",
    "]\n",
    "\n",
    "compare_df.sort_values(\"pr_auc\", ascending=False)\n",
    "\n",
    "# LGBM ì„ ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "### ìµœì¢… ëª¨ë¸ í•™ìŠµ, í…ŒìŠ¤íŠ¸ (2023 -> 2024) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = lgbm_results.sort_values(\"roc_auc\", ascending=False).iloc[0].to_dict()\n",
    "\n",
    "# # ğŸ”¥ intì—¬ì•¼ í•˜ëŠ” íŒŒë¼ë¯¸í„° ê°•ì œ ë³€í™˜\n",
    "# int_params = [\"random_state\", \"seed\", \"n_estimators\", \"num_leaves\", \"max_depth\"]\n",
    "\n",
    "# for p in int_params:\n",
    "#     if p in best_params and best_params[p] is not None:\n",
    "#         best_params[p] = int(best_params[p])\n",
    "\n",
    "# best_model = LGBMClassifier(**best_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# best_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# y_pred_test = best_model.predict(X_test)\n",
    "# y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# test_metrics = evaluate_model(y_test, y_pred_test, y_proba_test)\n",
    "# test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 1ï¸âƒ£ PR-AUC ê¸°ì¤€ìœ¼ë¡œ best íŒŒë¼ë¯¸í„° ì„ íƒ\n",
    "best_params = (\n",
    "    lgbm_results\n",
    "    .sort_values(\"pr_auc\", ascending=False)\n",
    "    .iloc[0]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ metric ì»¬ëŸ¼ ì œê±° (ì¤‘ìš”)\n",
    "metric_cols = [\"pr_auc\", \"top20_precision\", \"top50_precision\", \"f1\", \"brier\"]\n",
    "for m in metric_cols:\n",
    "    best_params.pop(m, None)\n",
    "\n",
    "# 3ï¸âƒ£ int íƒ€ì… ê°•ì œ ë³€í™˜\n",
    "int_params = [\"random_state\", \"seed\", \"n_estimators\", \"num_leaves\", \"max_depth\"]\n",
    "\n",
    "for p in int_params:\n",
    "    if p in best_params and best_params[p] is not None:\n",
    "        best_params[p] = int(best_params[p])\n",
    "\n",
    "# 4ï¸âƒ£ Best ëª¨ë¸ ì •ì˜\n",
    "best_model = LGBMClassifier(**best_params)\n",
    "\n",
    "# 5ï¸âƒ£ Train êµ¬ê°„ ì „ì²´ë¡œ ì¬í•™ìŠµ (2020â€“2023)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 6ï¸âƒ£ Final Test (2024)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_metrics = evaluate_model(y_test, y_pred_test, y_proba_test)\n",
    "test_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "## ê²€ì¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "### Hold-Out \n",
    "> - Train: 2019â€“2022\n",
    "> - Test : 2023 (â†’ 2024 ì„±ì¥ ì—¬ë¶€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_validation(model, X, y, years):\n",
    "    train_mask = years <= 2021\n",
    "    val_mask   = years == 2022\n",
    "\n",
    "    X_tr, y_tr = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    return evaluate_model(y_val, y_pred, y_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "### GroupKFold ê²€ì¦\n",
    "- ê°™ì€ ê¸°ì—…ì´ Train / Test ì— ë™ì‹œì— ë“±ì¥ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def group_kfold_validation(model, X, y, groups, n_splits=5):\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        scores.append(evaluate_model(y_val, y_pred, y_proba))\n",
    "\n",
    "    return pd.DataFrame(scores).mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "### Rolling Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_validation(model, X, y, years):\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_end in sorted(years.unique()):\n",
    "        val_year = train_end + 1\n",
    "\n",
    "        train_mask = years <= train_end\n",
    "        val_mask   = years == val_year\n",
    "\n",
    "        # âœ… pandas ê¸°ì¤€ slicing (ì¤‘ìš”)\n",
    "        X_tr  = X.loc[train_mask]\n",
    "        y_tr  = y.loc[train_mask]\n",
    "        X_val = X.loc[val_mask]\n",
    "        y_val = y.loc[val_mask]\n",
    "\n",
    "        # ğŸ”¥ ë°©ì–´ 1: ìƒ˜í”Œ ìˆ˜\n",
    "        if X_tr.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # ğŸ”¥ ë°©ì–´ 2: trainì— í´ë˜ìŠ¤ 2ê°œ ì´ìƒ\n",
    "        if y_tr.nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        # ğŸ”¥ ë°©ì–´ 3: valì— í´ë˜ìŠ¤ ì¡´ì¬\n",
    "        if y_val.nunique() < 1:\n",
    "            continue\n",
    "\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred  = model_clone.predict(X_val)\n",
    "        y_proba = model_clone.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        fold_scores.append(\n",
    "            evaluate_model(y_val, y_pred, y_proba)\n",
    "        )\n",
    "\n",
    "    if len(fold_scores) == 0:\n",
    "        return None\n",
    "\n",
    "    return pd.DataFrame(fold_scores).mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ë³„ ì „ë¶€ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "# ğŸ”¥ íŠ¸ë¦¬ ëª¨ë¸ë§Œ 3ì¢… ê²€ì¦\n",
    "for name, model in tree_models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "\n",
    "    all_results[name] = {\n",
    "        \"holdout\": holdout_validation(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            years_train\n",
    "        ),\n",
    "        \"groupkfold\": group_kfold_validation(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            groups_train\n",
    "        ),\n",
    "        \"rolling\": rolling_validation(\n",
    "            model,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            years_train\n",
    "        )\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"LGBM\"][\"rolling\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model_name, validations in all_results.items():\n",
    "    for val_type, metrics in validations.items():\n",
    "\n",
    "        if metrics is None:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"model\": model_name,\n",
    "            \"validation\": val_type\n",
    "        }\n",
    "        row.update(metrics)\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "run_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=f\"validation_summary_{run_ts}\"\n",
    "):\n",
    "\n",
    "    # 1ï¸âƒ£ ì „ì²´ ê²°ê³¼ CSV ì €ì¥\n",
    "    summary_path = f\"validation_results_summary_{run_ts}.csv\"\n",
    "    results_df.to_csv(summary_path, index=False)\n",
    "    mlflow.log_artifact(summary_path)\n",
    "\n",
    "    # 2ï¸âƒ£ í•µì‹¬ metric ìš”ì•½ ë¡œê¹…\n",
    "    for _, row in results_df.iterrows():\n",
    "        prefix = f\"{row['model']}_{row['validation']}\"\n",
    "\n",
    "        mlflow.log_metric(f\"{prefix}_pr_auc\", row[\"pr_auc\"])\n",
    "        mlflow.log_metric(f\"{prefix}_top20_precision\", row[\"top20_precision\"])\n",
    "        mlflow.log_metric(f\"{prefix}_top50_precision\", row[\"top50_precision\"])\n",
    "        mlflow.log_metric(f\"{prefix}_f1\", row[\"f1\"])\n",
    "        mlflow.log_metric(f\"{prefix}_brier\", row[\"brier\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_metrics = [\n",
    "    \"pr_auc\",\n",
    "    \"top20_precision\",\n",
    "    \"top50_precision\",\n",
    "    \"f1\",\n",
    "    \"brier\"\n",
    "]\n",
    "\n",
    "compare_table = (\n",
    "    results_df\n",
    "    .pivot_table(\n",
    "        index=\"model\",\n",
    "        columns=\"validation\",\n",
    "        values=key_metrics\n",
    "    )\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "compare_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "- â‘  ê²€ì¦ì—ì„œ ê³ ë¥¸ best_paramsë¡œ\n",
    "- â‘¡ 2023ë…„ê¹Œì§€ ëª¨ë“  ë°ì´í„°ë¡œ ì¬í•™ìŠµí•˜ê³ \n",
    "- â‘¢ 2024ë…„ ë§ í”¼ì²˜ë¥¼ ë„£ì–´\n",
    "- â‘£ 2025ë…„ ì„±ì¥ í™•ë¥ ì„ ì˜ˆì¸¡í•œë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "- ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ì— ê° í”¼ì²˜ê°€ ê¸°ì—¬í•œ ìƒëŒ€ì  ì¤‘ìš”ë„\n",
    "    - ê°’ì´ í´ìˆ˜ë¡ í”¼ì²˜ ì—¬ë¶€ì— ë”°ë¼ íŒë‹¨ì´ ë§ì´ ë°”ë€œ\n",
    "    - ê°’ì´ ì‘ì„ìˆ˜ë¡ ìˆì–´ë„ ê·¸ë§Œ ì—†ì–´ë„ ê·¸ë§Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# modelì´ í•™ìŠµì— ì‚¬ìš©í•œ feature ê¸°ì¤€\n",
    "feature_cols = model.feature_names_in_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "feature_importance.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# =====================================\n",
    "# 1. íˆíŠ¸ë§µ ëŒ€ìƒ í”¼ì²˜\n",
    "# =====================================\n",
    "corr_cols = [\n",
    "    # ê¸°ì¡´ ì •ëŸ‰\n",
    "    'patent_count_5y',\n",
    "    'patent_count_recent',\n",
    "    'ipc_diversity',\n",
    "    'patent_register_rate',\n",
    "    'patent_citation_total',\n",
    "    'patent_citation_avg',\n",
    "    'patent_citation_age_adj_total',\n",
    "    'patent_citation_age_adj_avg',\n",
    "    'no_patent_flag',\n",
    "\n",
    "    # # ğŸ”¥ ë³€í™”í˜• í”¼ì²˜\n",
    "    # 'patent_recent_ratio',\n",
    "    # 'citation_recent_ratio',\n",
    "    # 'patent_growth_rate',\n",
    "    # 'patent_growth_accel',\n",
    "    # 'new_ipc_ratio',\n",
    "    # 'recent_ipc_overlap',\n",
    "    # 'citation_per_patent_recent'\n",
    "]\n",
    "\n",
    "# =====================================\n",
    "# 2. ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "# =====================================\n",
    "corr_matrix = feature_df[corr_cols].corr()\n",
    "\n",
    "# =====================================\n",
    "# 3. ë³´ê¸° ì¢‹ê²Œ ìƒì‚¼ê°ë§Œ í‘œì‹œ (ì„ íƒ)\n",
    "# =====================================\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# =====================================\n",
    "# 4. íˆíŠ¸ë§µ ê·¸ë¦¬ê¸° (ìˆ«ì í¬í•¨)\n",
    "# =====================================\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,              # ğŸ‘ˆ ìƒì‚¼ê° ìˆ¨ê¸°ê¸° (ì„ íƒ)\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    annot=True,             # ğŸ‘ˆ ìˆ«ì í‘œì‹œ\n",
    "    fmt=\".2f\",              # ğŸ‘ˆ ì†Œìˆ˜ì  2ìë¦¬\n",
    "    annot_kws={\"size\": 9},  # ğŸ‘ˆ ìˆ«ì í¬ê¸°\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.8}\n",
    ")\n",
    "\n",
    "plt.title(\"Feature Correlation Heatmap (with values)\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
