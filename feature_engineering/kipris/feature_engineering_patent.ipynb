{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ÎùºÏù¥Î∏åÎü¨Î¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import parallel_backend\n",
    "import contextlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    from joblib import Parallel\n",
    "    old_batch_callback = Parallel.BatchCompletionCallBack\n",
    "\n",
    "    class TqdmBatchCompletionCallBack(old_batch_callback):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    Parallel.BatchCompletionCallBack = TqdmBatchCompletionCallBack\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        Parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Ïû¨Î¨¥Ï†ïÎ≥¥_final_v2(16~24) ÌååÏùº Ïó¥Í∏∞\n",
    "- Í∏∞ÏóÖ Ï†ïÎ≥¥ÎßåÏùÑ ÏúÑÌï¥ Ïó¥Ïñ¥Î≥¥Îäî ÌååÏùº\n",
    "    - Ïû¨Î¨¥ Îç∞Ïù¥ÌÑ∞Ïóê Îì±Ïû•Ìïú Î™®Îì† Í∏∞ÏóÖ\n",
    "    - Ïó∞ÎèÑÎ≥ÑÎ°ú ÏÇ¥ÏïÑ ÏûàÏóàÎçò Í∏∞ÏóÖ\n",
    "    - ÌäπÌóà Ïó¨Î∂ÄÏôÄ Î¨¥Í¥Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df = pd.read_csv('../../data/Ïû¨Î¨¥Ï†ïÎ≥¥_final_v2(16~24)_ÏàòÏ†ï_ÏµúÏ¢Ö.csv', encoding=\"utf-8\", encoding_errors='replace', engine=\"python\")\n",
    "financial_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# ÌäπÌóàÏ†ïÎ≥¥_final ÌååÏùº Ïó¥Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final = pd.read_csv('../../data/ÌäπÌóàÏ†ïÎ≥¥_final_v2.csv', encoding=\"cp949\", encoding_errors='replace', engine=\"python\")\n",
    "patent_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_final = patent_final.rename(columns={\n",
    "    'ipcNumber_IPCÏΩîÎìú': 'ipcNumber',\n",
    "    'applicationDate_Ï∂úÏõêÏùºÏûê': 'applicationDate',\n",
    "    'astrtCont_Ï¥àÎ°ù':'astrtCont',\n",
    "    'applicationNumber_Ï∂úÏõêÎ≤àÌò∏':'applicationNumber',\n",
    "     'registerDate_Îì±Î°ùÏùºÏûê':'registerDate',\n",
    "      'indexNo_ÏùºÎ†®Î≤àÌò∏':'indexNo',\n",
    " 'registerStatus_Îì±Î°ùÏÉÅÌÉú':'registerStatus',\n",
    " 'inventionTitle_Î∞úÎ™ÖÏùòÎ™ÖÏπ≠':'inventionTitle',\n",
    " 'applicantName_Ï∂úÏõêÏù∏Î™Ö':'applicantName'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Ïû†Íπê ......."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## ÌäπÌóà Îç∞Ïù¥ÌÑ∞ ÏµúÏÜå Ï†ÑÏ≤òÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df = patent_final.copy()\n",
    "\n",
    "# Ï∂úÏõêÏùº datetime Î≥¥Ïû•\n",
    "patent_df['applicationDate'] = pd.to_datetime(patent_df['applicationDate'])\n",
    "\n",
    "# Ï∂úÏõêÎÖÑÎèÑ \n",
    "patent_df['application_year'] = patent_df['applicationDate'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df['application_year'] = pd.to_numeric(\n",
    "    patent_df['application_year'],\n",
    "    errors='coerce'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_company_name(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "\n",
    "    name = str(name)\n",
    "\n",
    "    # 1. ÏÜåÎ¨∏Ïûê Î≥ÄÌôò\n",
    "    name = name.lower()\n",
    "\n",
    "    # 2. Î≤ïÏù∏ ÌëúÍ∏∞ Ï†úÍ±∞\n",
    "    name = re.sub(r'\\(Ï£º\\)|„àú|Ï£ºÏãùÌöåÏÇ¨', '', name)\n",
    "\n",
    "    # 3. Î∂àÌïÑÏöîÌïú Í≥µÎ∞± Ï†úÍ±∞\n",
    "    name = re.sub(r'\\s+', '', name)\n",
    "\n",
    "    # 4. ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞ (ÌïÑÏöî ÏµúÏÜå)\n",
    "    name = re.sub(r'[^\\wÍ∞Ä-Ìû£]', '', name)\n",
    "\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================================================\n",
    "# Îëê Îç∞Ïù¥ÌÑ∞Ïóê ÎèôÏùºÌïòÍ≤å Ï†ÅÏö© \n",
    "#=====================================================================================\n",
    "financial_df['company_norm'] = financial_df['Í∏∞ÏóÖÎ™Ö'].apply(normalize_company_name)\n",
    "patent_df['company_norm'] = patent_df['company_name'].apply(normalize_company_name)\n",
    "\n",
    "#=====================================================================================\n",
    "# Îß§Ïπ≠ ÌíàÏßà ÏßÑÎã®\n",
    "#=====================================================================================\n",
    "\n",
    "# Ïû¨Î¨¥ Í∏∞Ï§Ä Í∏∞ÏóÖ Ïàò\n",
    "financial_companies = set(financial_df['company_norm'].dropna())\n",
    "\n",
    "# ÌäπÌóà Í∏∞Ï§Ä Í∏∞ÏóÖ Ïàò\n",
    "patent_companies = set(patent_df['company_norm'].dropna())\n",
    "\n",
    "print(\"Ïû¨Î¨¥ Í∏∞ÏóÖ Ïàò:\", len(financial_companies))\n",
    "print(\"ÌäπÌóà Í∏∞ÏóÖ Ïàò:\", len(patent_companies))\n",
    "print(\"ÍµêÏßëÌï© Ïàò:\", len(financial_companies & patent_companies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_year_df = (\n",
    "    financial_df[['company_norm', 'Ïó∞ÎèÑ']]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(['company_norm', 'Ïó∞ÎèÑ'])\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# [STEP 0] Îß§Ï∂úÏï° Ïà´Ïûê Î≥ÄÌôò (Î∞òÎìúÏãú growth Í≥ÑÏÇ∞ Ï†ÑÏóê)\n",
    "# =====================================================\n",
    "\n",
    "financial_df['Îß§Ï∂úÏï°'] = (\n",
    "    financial_df['Îß§Ï∂úÏï°']\n",
    "    .astype(str)                 # ÌòπÏãú Î™®Î•º ÌÉÄÏûÖ ÌÜµÏùº\n",
    "    .str.replace(',', '')        # Ï≤ú Îã®ÏúÑ ÏΩ§Îßà Ï†úÍ±∞\n",
    "    .str.replace(' ', '')        # Í≥µÎ∞± Ï†úÍ±∞\n",
    ")\n",
    "\n",
    "financial_df['Îß§Ï∂úÏï°'] = pd.to_numeric(\n",
    "    financial_df['Îß§Ï∂úÏï°'],\n",
    "    errors='coerce'              # Ïà´Ïûê ÏïÑÎãå Í±¥ NaN\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 1] Ï†ïÎ†¨ (Ï†àÎåÄ ÏÉùÎûµ Í∏àÏßÄ)\n",
    "# =====================================================\n",
    "financial_df = financial_df.sort_values(\n",
    "    ['company_norm', 'Ïó∞ÎèÑ']\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 2] Ï†ÑÎÖÑÎèÑ Îß§Ï∂ú (lag)\n",
    "# =====================================================\n",
    "financial_df['revenue_lag_1'] = (\n",
    "    financial_df\n",
    "    .groupby('company_norm')['Îß§Ï∂úÏï°']\n",
    "    .shift(1)\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 3] Îß§Ï∂ú ÏÑ±Ïû•Î•†\n",
    "# =====================================================\n",
    "financial_df['revenue_growth'] = (\n",
    "    (financial_df['Îß§Ï∂úÏï°'] - financial_df['revenue_lag_1'])\n",
    "    / financial_df['revenue_lag_1']\n",
    ")\n",
    "# =====================================================\n",
    "# [STEP 4] ÏÑ±Ïû• Ïó¨Î∂Ä ÎùºÎ≤®\n",
    "# =====================================================\n",
    "financial_df['growth_flag'] = (\n",
    "    financial_df['revenue_growth'] > 0\n",
    ").astype(int)\n",
    "\n",
    "# =====================================================\n",
    "# [STEP 5] ÏµúÏ¢Ö ÌÉÄÍ≤ü Î≥ÄÏàò\n",
    "# =====================================================\n",
    "financial_df['y'] = financial_df['growth_flag']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## ÌäπÌóà ÌîºÏ≤ò ÏÉùÏÑ± Ìï®Ïàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def make_patent_features(company_norm, t, patent_df):\n",
    "    \"\"\"\n",
    "    company_norm √ó Ïó∞ÎèÑ(t) Í∏∞Ï§Ä ÌäπÌóà ÌîºÏ≤ò ÏÉùÏÑ±\n",
    "    - warm-up Ï†ÅÏö©: t < 2019 ‚Üí None\n",
    "    - ÎàÑÏàò Î∞©ÏßÄ: t-1 ÏãúÏ†êÍπåÏßÄÎßå ÏÇ¨Ïö©\n",
    "    \"\"\"\n",
    "\n",
    "    # ===============================\n",
    "    # 0. Warm-up Í∞ïÏ†ú\n",
    "    # ===============================\n",
    "    t = int(t)\n",
    "    if t < 2019:\n",
    "        return None\n",
    "\n",
    "    # Í∏∞ÏóÖ Í∏∞Ï§Ä ÌïÑÌÑ∞\n",
    "    df = patent_df[patent_df['company_norm'] == company_norm].copy()\n",
    "\n",
    "    # ===============================\n",
    "    # 1. Í∏∞Í∞Ñ ÌïÑÌÑ∞ (ÎàÑÏàò Î∞©ÏßÄ ÌïµÏã¨)\n",
    "    # ===============================\n",
    "    window_5y = df[\n",
    "        (df['application_year'] >= t - 4) &\n",
    "        (df['application_year'] <= t - 1)\n",
    "    ]\n",
    "\n",
    "    window_recent = df[\n",
    "        (df['application_year'] >= t - 2) &\n",
    "        (df['application_year'] <= t - 1)\n",
    "    ]\n",
    "\n",
    "    # # Îì±Î°ùÎ•† ÏΩîÌò∏Ìä∏: t-4 ~ t-3\n",
    "    # cohort_register = df[\n",
    "    #     (df['application_year'] >= t - 4) &\n",
    "    #     (df['application_year'] <= t - 3)\n",
    "    # ]\n",
    "\n",
    "    # ÌîºÏù∏Ïö© as-of cutoff\n",
    "    citation_window = window_5y[\n",
    "        window_5y['applicationDate'] <= pd.Timestamp(f\"{t-1}-12-31\")\n",
    "    ].copy()\n",
    "\n",
    "    # ===============================\n",
    "    # 2. ÌîºÏ≤ò Í≥ÑÏÇ∞\n",
    "    # ===============================\n",
    "    patent_count_5y = len(window_5y)\n",
    "    patent_count_recent = len(window_recent)\n",
    "\n",
    "    ipc_diversity = (\n",
    "        window_5y['ipcNumber']\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .str[:4]\n",
    "        .nunique()\n",
    "        if patent_count_5y > 0 else 0\n",
    "    )\n",
    "\n",
    "    # # Îì±Î°ùÎ•†: registerDate Í∏∞Ï§Ä\n",
    "    # if len(cohort_register) > 0:\n",
    "    #     patent_register_rate = (\n",
    "    #         cohort_register['registerDate'].notna().mean()\n",
    "    #     )\n",
    "    # else:\n",
    "    #     patent_register_rate = 0.0\n",
    "    # ===============================\n",
    "    # Îì±Î°ùÎ•† ÏΩîÌò∏Ìä∏: t-4 ~ t-3\n",
    "    # ===============================\n",
    "    VALID_SUCCESS_STATUS = ['Îì±Î°ù', 'Í≥µÍ∞ú']\n",
    "    cohort_register = df[\n",
    "        (df['application_year'] >= t - 4) &\n",
    "        (df['application_year'] <= t - 3)\n",
    "    ]\n",
    "\n",
    "    if len(cohort_register) > 0:\n",
    "        # Ï†ÑÏ≤¥ Ï∂úÏõê Ïàò\n",
    "        total_applications = len(cohort_register)\n",
    "\n",
    "        # Îì±Î°ù + Í≥µÍ∞ú Í±¥Ïàò\n",
    "        success_count = cohort_register[\n",
    "            cohort_register['registerStatus'].isin(['Îì±Î°ù', 'Í≥µÍ∞ú'])\n",
    "        ].shape[0]\n",
    "\n",
    "        patent_register_rate = success_count / total_applications\n",
    "    else:\n",
    "        patent_register_rate = 0.0\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # ÌîºÏù∏Ïö© (Í∏∞Î≥∏)\n",
    "    # -------------------------------\n",
    "    patent_citation_total = (\n",
    "        citation_window['ÌîºÏù∏Ïö© ÌöüÏàò'].sum()\n",
    "        if len(citation_window) > 0 else 0.0\n",
    "    )\n",
    "\n",
    "    patent_citation_avg = (\n",
    "        patent_citation_total / max(1, patent_count_5y)\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # üî• Ïó∞Î†π Î≥¥Ï†ï ÌîºÏù∏Ïö©\n",
    "    # -------------------------------\n",
    "    if len(citation_window) > 0:\n",
    "        citation_window['patent_age'] = (\n",
    "            t - citation_window['application_year']\n",
    "        ).clip(lower=1)\n",
    "\n",
    "        citation_window['citation_per_year'] = (\n",
    "            citation_window['ÌîºÏù∏Ïö© ÌöüÏàò'] / citation_window['patent_age']\n",
    "        )\n",
    "\n",
    "        patent_citation_age_adj_total = (\n",
    "            citation_window['citation_per_year'].sum()\n",
    "        )\n",
    "    else:\n",
    "        patent_citation_age_adj_total = 0.0\n",
    "\n",
    "    patent_citation_age_adj_avg = (\n",
    "        patent_citation_age_adj_total / max(1, patent_count_5y)\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # ÌäπÌóà 0Í±¥ ÌîåÎûòÍ∑∏\n",
    "    # -------------------------------\n",
    "    no_patent_flag = int(patent_count_5y == 0)\n",
    "\n",
    "    return {\n",
    "        'company_norm': company_norm,\n",
    "        'Ïó∞ÎèÑ': t,\n",
    "        'patent_count_5y': patent_count_5y,\n",
    "        'patent_count_recent': patent_count_recent,\n",
    "        'ipc_diversity': ipc_diversity,\n",
    "        'patent_register_rate': patent_register_rate,\n",
    "        'patent_citation_total': patent_citation_total,\n",
    "        'patent_citation_avg': patent_citation_avg,\n",
    "        # üî• Ï∂îÍ∞Ä ÌîºÏ≤ò\n",
    "        'patent_citation_age_adj_total': patent_citation_age_adj_total,\n",
    "        'patent_citation_age_adj_avg': patent_citation_age_adj_avg,\n",
    "        'no_patent_flag': no_patent_flag\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_feature_rows = []\n",
    "\n",
    "for row in tqdm(\n",
    "    company_year_df.itertuples(index=False),\n",
    "    total=len(company_year_df),\n",
    "    desc=\"ÌäπÌóà ÌîºÏ≤ò ÏÉùÏÑ±\"\n",
    "):\n",
    "    feat = make_patent_features(\n",
    "        company_norm=row.company_norm,\n",
    "        t=row.Ïó∞ÎèÑ,\n",
    "        patent_df=patent_df\n",
    "    )\n",
    "\n",
    "    if feat is not None:\n",
    "        patent_feature_rows.append(feat)\n",
    "\n",
    "patent_feature_df = pd.DataFrame(patent_feature_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_feature_df['Ïó∞ÎèÑ'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "- ÌäπÌóà ÌîºÏ≤ò ÏóîÏßÄÎãàÏñ¥ÎßÅ Í≥ºÏ†ïÏóêÏÑú Î°§ÎßÅ ÏúàÎèÑÏö∞Ïùò warm-up Í∏∞Í∞ÑÏùÑ Ìï®Ïàò ÎÇ¥Î∂ÄÏóêÏÑú Í∞ïÏ†úÌïòÏó¨,\n",
    "Ï∂©Î∂ÑÌïú Í≥ºÍ±∞ Îç∞Ïù¥ÌÑ∞Í∞Ä ÌôïÎ≥¥ÎêòÏßÄ ÏïäÏùÄ Ïó∞ÎèÑ(2019 Ïù¥Ï†Ñ)Í∞Ä\n",
    "ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Ïóê Ìè¨Ìï®ÎêòÏßÄ ÏïäÎèÑÎ°ù ÏàòÏ†ïÌïòÏòÄÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Ïû¨Î¨¥ Îç∞Ïù¥ÌÑ∞ÏôÄ Í≤∞Ìï©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df['Ïó∞ÎèÑ'] = pd.to_numeric(financial_df['Ïó∞ÎèÑ'], errors='coerce').astype('Int64')\n",
    "patent_feature_df['Ïó∞ÎèÑ'] = pd.to_numeric(patent_feature_df['Ïó∞ÎèÑ'], errors='coerce').astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df[['Ïó∞ÎèÑ']].dtypes, patent_feature_df[['Ïó∞ÎèÑ']].dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_df['Îß§Ï∂úÏï°'].isna().mean(), (financial_df['Îß§Ï∂úÏï°'] == 0).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_agg = (\n",
    "    financial_df\n",
    "    .groupby(['company_norm', 'Ïó∞ÎèÑ'], as_index=False)\n",
    "    .agg({\n",
    "        'Í∏∞ÏóÖÎ™Ö': 'first',\n",
    "        'ÏÇ¨ÏóÖÏûêÎì±Î°ùÎ≤àÌò∏': 'first',\n",
    "        'crno': 'first',\n",
    "        'dart_corp_code': 'first',\n",
    "        'sectors': 'first',\n",
    "        'field': 'first',\n",
    "\n",
    "        'Îß§Ï∂úÏï°': 'sum',\n",
    "        'ÏòÅÏóÖÏù¥Ïùµ': 'sum',\n",
    "        'ÎãπÍ∏∞ÏàúÏù¥Ïùµ': 'sum',\n",
    "        'ÏûêÏÇ∞Ï¥ùÍ≥Ñ': 'max',\n",
    "        'Î∂ÄÏ±ÑÏ¥ùÍ≥Ñ': 'max',\n",
    "        'ÏûêÎ≥∏Ï¥ùÍ≥Ñ': 'max',\n",
    "        'Ïó∞Íµ¨Í∞úÎ∞úÎπÑ': 'sum',\n",
    "        'CAPEX': 'sum',\n",
    "        'Ïú†ÌòïÏûêÏÇ∞_ÎãπÍ∏∞': 'max',\n",
    "        'Ïú†ÌòïÏûêÏÇ∞_Ï†ÑÍ∏∞': 'max',\n",
    "        'Ïú†ÌòïÏûêÏÇ∞_Ï¶ùÍ∞ê': 'sum'\n",
    "    })\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = financial_agg.merge(\n",
    "    patent_feature_df,\n",
    "    on=['company_norm', 'Ïó∞ÎèÑ'],\n",
    "    how='left',\n",
    "    validate='one_to_one'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(financial_agg), len(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Îß§Ï∂úÏï°'].isna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(financial_df.columns)\n",
    "print(patent_feature_df.columns)\n",
    "print(final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(financial_df), len(final_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## ÌÉÄÍπÉ(y) ÏÉùÏÑ± ‚Äî ‚Äút Ï†ïÎ≥¥Î°ú t+1 ÏÑ±Ïû• Ïó¨Î∂Ä ÏòàÏ∏°‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "money_cols = [\n",
    "    'Îß§Ï∂úÏï°','ÏòÅÏóÖÏù¥Ïùµ','ÎãπÍ∏∞ÏàúÏù¥Ïùµ',\n",
    "    'ÏûêÏÇ∞Ï¥ùÍ≥Ñ','Î∂ÄÏ±ÑÏ¥ùÍ≥Ñ','ÏûêÎ≥∏Ï¥ùÍ≥Ñ',\n",
    "    'Ïó∞Íµ¨Í∞úÎ∞úÎπÑ','CAPEX',\n",
    "    'Ïú†ÌòïÏûêÏÇ∞_ÎãπÍ∏∞','Ïú†ÌòïÏûêÏÇ∞_Ï†ÑÍ∏∞','Ïú†ÌòïÏûêÏÇ∞_Ï¶ùÍ∞ê'\n",
    "]\n",
    "\n",
    "for col in money_cols:\n",
    "    final_df[col] = (\n",
    "        final_df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(',', '', regex=False)\n",
    "    )\n",
    "    final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['Îß§Ï∂úÏï°']].head()\n",
    "final_df['Îß§Ï∂úÏï°'].isna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['revenue_growth'] = (\n",
    "    final_df\n",
    "    .groupby('company_norm')['Îß§Ï∂úÏï°']\n",
    "    .pct_change()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df[\n",
    "    (final_df['Ïó∞ÎèÑ'] >= 2019) &\n",
    "    (final_df['Ïó∞ÎèÑ'] <= 2024)\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Ïó∞ÎèÑ'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['growth_flag'] = (\n",
    "    final_df\n",
    "    .groupby('Ïó∞ÎèÑ')['revenue_growth']\n",
    "    .transform(lambda x: (x >= x.quantile(0.7)).astype(int))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('Ïó∞ÎèÑ')['growth_flag'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['y'] = (\n",
    "    final_df\n",
    "    .groupby('company_norm')['growth_flag']\n",
    "    .shift(-1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = final_df.dropna(subset=['y']).copy()\n",
    "model_df['y'] = model_df['y'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['Ïó∞ÎèÑ'].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌïÑÏöîÌïú Ïª¨ÎüºÎì§Îßå ÎÇ®Í∏∞Í∏∞\n",
    "keep_cols = [\n",
    "    # ÏãùÎ≥Ñ / ÏãúÏ†ê\n",
    "    'company_norm',\n",
    "    'Ïó∞ÎèÑ',\n",
    "    'Í∏∞ÏóÖÎ™Ö',\n",
    "\n",
    "    # ÌäπÌóà ÌîºÏ≤ò\n",
    "    'patent_count_5y',\n",
    "    'patent_count_recent',\n",
    "    'ipc_diversity',\n",
    "    'patent_register_rate',\n",
    "    'patent_citation_total',\n",
    "    'patent_citation_avg',\n",
    "    'patent_citation_age_adj_total',\n",
    "    'patent_citation_age_adj_avg',\n",
    "    'no_patent_flag',\n",
    "\n",
    "    # ÏÑ±Ïû• Í¥ÄÎ†®\n",
    "    'revenue_growth',\n",
    "    'growth_flag',\n",
    "    'y'\n",
    "]\n",
    "\n",
    "model_df = model_df[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv('../../output/feature_engineering_dataset_7_patent.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "# ÏùºÎã® .. ÎåÄÍ∏∞ (ÌèêÍ∏∞)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA ÎåÄÏÉÅ Ïª¨Îüº Ï†ïÎ¶¨\n",
    "patent_cols = [\n",
    "    'patent_count_5y',\n",
    "    'patent_count_recent',\n",
    "    'ipc_diversity',\n",
    "    'patent_register_rate',\n",
    "    'patent_citation_total',\n",
    "    'patent_citation_avg',\n",
    "    'patent_citation_age_adj_total',\n",
    "    'patent_citation_age_adj_avg',\n",
    "    'no_patent_flag'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[patent_cols].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['no_patent_flag'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('no_patent_flag')[patent_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['patent_count_5y', 'patent_count_recent']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌäπÌóàÎ•º ÎßéÏù¥ ÎÇ¥Îäî ÌöåÏÇ¨ÏùºÏàòÎ°ù IPCÎèÑ Îçî Îã§ÏñëÌï¥ÏßÄÎäî Í≤ΩÌñ•Ïù¥ ÏûàÏùå\n",
    "final_df[['patent_count_5y', 'ipc_diversity']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ï†ïÍ∑úÌôî ÎπÑÏú® ÌîºÏ≤ò\n",
    "# : Í∑úÎ™® Ìö®Í≥º(ÌäπÌóà Ïàò)Î•º Ï†úÍ±∞ÌïòÍ≥† Íµ¨Ï°∞Ï†Å Ï∞®Ïù¥Î•º Î≥¥Í∏∞ ÏúÑÌïú Î≥ÄÏàò\n",
    "# Í∞ôÏùÄ ÌäπÌóà Ïàò ÎåÄÎπÑ Í∏∞Ïà† Ìè≠ÏùÑ ÏïåÎ†§Ï§å\n",
    "final_df['ipc_diversity_ratio'] = (\n",
    "    final_df['ipc_diversity'] / final_df['patent_count_5y'].replace(0, 1)\n",
    ")\n",
    "\n",
    "final_df[['patent_count_5y', 'ipc_diversity_ratio']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['patent_register_rate'].describe()\n",
    "\n",
    "# Ï†ÄÎ∂ÑÏÇ∞ Î≥ÄÏàò -> ÎåÄÎ∂ÄÎ∂ÑÏùò Í∞íÏù¥ Í∞ôÏïÑÏÑú ÏòàÏ∏°Ïóê Í∏∞Ïó¨ÌïòÏßÄ Î™ªÌïòÎäî Î≥ÄÏàò\n",
    "# Îì±Î°ùÎ•†Ïù¥ ÏïÑÎãå 'Îì±Î°ù Í±¥Ïàò Í∏∞Î∞ò'ÏúºÎ°ú Î≥ÄÍ≤Ω -> ‚ÄúÏñºÎßàÎÇò Îì±Î°ùÎêòÏóàÎäîÍ∞Ä‚ÄùÎ•º ÏßÅÏ†ë ÌëúÌòÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['registered_patent_count'] = (\n",
    "    final_df['patent_register_rate'] * final_df['patent_count_5y']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../../output/feature_engineering_3.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['no_patent_flag'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Í∏∞Î≥∏ ÏÑ∏ÌåÖ\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ÌäπÌóà ÌôúÎèôÎüâ Î∂ÑÌè¨\n",
    "# - ÌäπÌóàÎäî ÏùºÎ∂Ä Í∏∞ÏóÖÏóê ÏßëÏ§ëÎêòÏñ¥ ÏûàÏùå\n",
    "plt.hist(final_df['patent_count_5y'], bins=50)\n",
    "plt.title('Distribution of Patent Count (5Y)')\n",
    "plt.xlabel('patent_count_5y')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ÏµúÍ∑ºÏÑ± vs ÎàÑÏ†Å ÌôúÎèôÎüâ\n",
    "\n",
    "plt.scatter(\n",
    "    final_df['patent_count_5y'],\n",
    "    final_df['patent_count_recent'],\n",
    "    alpha=0.3\n",
    ")\n",
    "plt.xlabel('patent_count_5y')\n",
    "plt.ylabel('patent_count_recent')\n",
    "plt.title('Recent vs Total Patent Activity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëâ ‚Äúipc_diversityÎäî ÌäπÌóà Ïàò Î≥µÏÇ¨Ïù∏Í∞Ä?‚Äù Í≤ÄÏ¶ù\n",
    "plt.scatter(\n",
    "    final_df['patent_count_5y'],\n",
    "    final_df['ipc_diversity'],\n",
    "    alpha=0.3\n",
    ")\n",
    "plt.xlabel('patent_count_5y')\n",
    "plt.ylabel('ipc_diversity')\n",
    "plt.title('Patent Count vs IPC Diversity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îì±Î°ùÎ•† Î∂ÑÌè¨ (Î¨∏Ï†ú ÌîºÏ≤ò ÌôïÏù∏Ïö©)\n",
    "# üëâ ‚ÄúÏôú Ïù¥ ÌîºÏ≤òÎ•º ÎåÄÏ≤¥Ìï¥Ïïº ÌñàÎäîÏßÄ‚Äù ÏãúÍ∞ÅÏ†ÅÏúºÎ°ú Ï¶ùÎ™Ö\n",
    "plt.hist(final_df['patent_register_rate'], bins=20)\n",
    "plt.title('Patent Register Rate Distribution')\n",
    "plt.xlabel('patent_register_rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(final_df['patent_citation_total'], bins=50)\n",
    "plt.title('Total Citation Count')\n",
    "plt.xlabel('patent_citation_total')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(final_df['patent_citation_age_adj_total'], bins=50)\n",
    "plt.title('Age-adjusted Citation Count')\n",
    "plt.xlabel('patent_citation_age_adj_total')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌäπÌóà Î≥¥Ïú† vs ÎØ∏Î≥¥Ïú† Í∏∞ÏóÖ ÎπÑÍµê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means = (\n",
    "    final_df\n",
    "    .groupby('no_patent_flag')[\n",
    "        ['patent_count_5y', 'patent_citation_total']\n",
    "    ]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "group_means.plot(kind='bar')\n",
    "plt.title('Patent vs No-Patent Firms')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "# Î™®Îç∏ÎßÅ\n",
    "- Î™®Îç∏ : LogReg, RandomForest, LightBGM, XGBoost\n",
    "- Í≤ÄÏ¶ù Î∞©Ïãù : Holdout, GroupKFold, RollingValidation\n",
    "- ÌèâÍ∞ÄÏßÄÌëú: PR-AUC, Top-20/50 Precision, F1, Brier\n",
    "---\n",
    "> - model_df : feature + y Ìè¨Ìï® (Ï†ïÏÉÅ)\n",
    "> - Ïó∞ÎèÑ Î≤îÏúÑ : 2019‚Äì2023\n",
    "> - y : tÎÖÑ ÌîºÏ≤ò ‚Üí t+1ÎÖÑ ÏÑ±Ïû• Ïó¨Î∂Ä(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "## Feature / Label Î∂ÑÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID / Label Ïª¨Îüº\n",
    "id_cols = ['Í∏∞ÏóÖÎ™Ö', 'company_norm', 'Ïó∞ÎèÑ']\n",
    "label_cols = ['y', 'growth_flag', 'revenue_growth', 'asset_growth']\n",
    "\n",
    "# Ïà´ÏûêÌòï ÌîºÏ≤òÎßå ÏÇ¨Ïö©\n",
    "feature_cols = (\n",
    "    model_df\n",
    "    .drop(columns=id_cols + label_cols, errors='ignore')\n",
    "    .select_dtypes(include=['int64', 'float64'])\n",
    "    .columns\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "X = model_df[feature_cols].copy()\n",
    "y = model_df['y'].copy()\n",
    "years = model_df['Ïó∞ÎèÑ'].copy()\n",
    "groups = model_df['company_norm'].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "## Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ Ìï®Ïàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_train_test(X_tr, X_te, feature_cols):\n",
    "    patent_cols = [c for c in feature_cols if c.startswith('patent_') or c == 'no_patent_flag']\n",
    "    financial_cols = [c for c in feature_cols if c not in patent_cols]\n",
    "\n",
    "    # ÌäπÌóà ‚Üí 0\n",
    "    X_tr[patent_cols] = X_tr[patent_cols].fillna(0)\n",
    "    X_te[patent_cols] = X_te[patent_cols].fillna(0)\n",
    "\n",
    "    # Ïû¨Î¨¥ ‚Üí train median\n",
    "    for col in financial_cols:\n",
    "        med = X_tr[col].median()\n",
    "        X_tr[col] = X_tr[col].fillna(med)\n",
    "        X_te[col] = X_te[col].fillna(med)\n",
    "\n",
    "    return X_tr, X_te\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=8, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \"LGBM\": lgb.LGBMClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, random_state=42\n",
    "    ),\n",
    "    \"XGB\": xgb.XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "        eval_metric=\"logloss\", random_state=42\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "## ÌèâÍ∞Ä ÏßÄÌëú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, f1_score,\n",
    "    average_precision_score, brier_score_loss\n",
    ")\n",
    "\n",
    "def top_k_precision(y_true, y_prob, k):\n",
    "    k = min(k, len(y_true))\n",
    "    idx = np.argsort(y_prob)[-k:]\n",
    "    return y_true.iloc[idx].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## Í≤ÄÏ¶ù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### Hold-Out \n",
    "> - Train: 2019‚Äì2022\n",
    "> - Test : 2023 (‚Üí 2024 ÏÑ±Ïû• Ïó¨Î∂Ä)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "X_tr = X[years <= 2022].copy()\n",
    "y_tr = y[years <= 2022]\n",
    "\n",
    "X_te = X[years == 2023].copy()\n",
    "y_te = y[years == 2023]\n",
    "\n",
    "X_tr, X_te = fill_na_train_test(X_tr, X_te, feature_cols)\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Hold-out\"):\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    prob = model.predict_proba(X_te)[:, 1]\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"validation\": \"Holdout\",\n",
    "        \"Accuracy\": accuracy_score(y_te, pred),\n",
    "        \"ROC_AUC\": roc_auc_score(y_te, prob),\n",
    "        \"PR_AUC\": average_precision_score(y_te, prob),\n",
    "        \"Top20_P\": top_k_precision(y_te, prob, 20),\n",
    "        \"Top50_P\": top_k_precision(y_te, prob, 50),\n",
    "        \"F1\": f1_score(y_te, pred),\n",
    "        \"Brier\": brier_score_loss(y_te, prob)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "### GroupKFold Í≤ÄÏ¶ù\n",
    "- Í∞ôÏùÄ Í∏∞ÏóÖÏù¥ Train / Test Ïóê ÎèôÏãúÏóê Îì±Ïû• x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"GroupKFold\"):\n",
    "    scores = []\n",
    "\n",
    "    for tr_idx, te_idx in gkf.split(X, y, groups):\n",
    "        X_tr, X_te = X.iloc[tr_idx].copy(), X.iloc[te_idx].copy()\n",
    "        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "        X_tr, X_te = fill_na_train_test(X_tr, X_te, feature_cols)\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        prob = model.predict_proba(X_te)[:, 1]\n",
    "        pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "        scores.append({\n",
    "            \"Accuracy\": accuracy_score(y_te, pred),\n",
    "            \"ROC_AUC\": roc_auc_score(y_te, prob),\n",
    "            \"PR_AUC\": average_precision_score(y_te, prob),\n",
    "            \"Top20_P\": top_k_precision(y_te, prob, 20),\n",
    "            \"Top50_P\": top_k_precision(y_te, prob, 50),\n",
    "            \"F1\": f1_score(y_te, pred),\n",
    "            \"Brier\": brier_score_loss(y_te, prob)\n",
    "        })\n",
    "\n",
    "    avg = pd.DataFrame(scores).mean().to_dict()\n",
    "    avg.update({\"model\": name, \"validation\": \"GroupKFold\"})\n",
    "    results.append(avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "### Rolling Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_years = [2021, 2022, 2023]\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Rolling\"):\n",
    "    scores = []\n",
    "\n",
    "    for test_year in rolling_years:\n",
    "        X_tr = X[years < test_year].copy()\n",
    "        y_tr = y[years < test_year]\n",
    "\n",
    "        X_te = X[years == test_year].copy()\n",
    "        y_te = y[years == test_year]\n",
    "\n",
    "        X_tr, X_te = fill_na_train_test(X_tr, X_te, feature_cols)\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        prob = model.predict_proba(X_te)[:, 1]\n",
    "        pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "        scores.append({\n",
    "            \"Accuracy\": accuracy_score(y_te, pred),\n",
    "            \"ROC_AUC\": roc_auc_score(y_te, prob),\n",
    "            \"PR_AUC\": average_precision_score(y_te, prob),\n",
    "            \"Top20_P\": top_k_precision(y_te, prob, 20),\n",
    "            \"Top50_P\": top_k_precision(y_te, prob, 50),\n",
    "            \"F1\": f1_score(y_te, pred),\n",
    "            \"Brier\": brier_score_loss(y_te, prob)\n",
    "        })\n",
    "\n",
    "    avg = pd.DataFrame(scores).mean().to_dict()\n",
    "    avg.update({\"model\": name, \"validation\": \"Rolling\"})\n",
    "    results.append(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['validation', 'PR_AUC'], ascending=[True, False])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
