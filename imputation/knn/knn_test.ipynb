{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#########################################################################\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "#########################################################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "#########################################################################\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. í•œê¸€ í°íŠ¸ ê²½ë¡œ ì„¤ì • (Windows ê¸°ë³¸: ë§‘ì€ ê³ ë”•)\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "# 2. matplotlibì— í°íŠ¸ ì ìš©\n",
    "mpl.rc(\"font\", family=font_name)\n",
    "\n",
    "# 3. ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df = pd.read_csv('../../data/ì¬ë¬´ì •ë³´_final.csv', encoding='cp949')\n",
    "jemu_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# ì „ì²´ ë°ì´í„° eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## DF í˜•íƒœ íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³ ìœ  ê¸°ì—…ëª…ë§Œ\n",
    "jemu_df[\"ê¸°ì—…ëª…\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ê¸°ì—…ì— ëŒ€í•œ í–‰ ë³´ê¸°\n",
    "jemu_df[jemu_df[\"ê¸°ì—…ëª…\"] == \"íœ´ë¹„ì˜¤ ì£¼ì‹íšŒì‚¬\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### ì»¬ëŸ¼ëª…ë“¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### ê¸°ì—…ë³„ í–‰ ê°œìˆ˜\n",
    "- ëª¨ë“  ê°’ì´ ë‹¤ 6ì´ ë‚˜ì™€ì•¼ ì •ìƒ -> ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # ëª¨ë“  í–‰ ë³´ê¸°\n",
    "jemu_df.groupby(\"ê¸°ì—…ëª…\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### ê¸°ì—…ë³„ ê²°ì¸¡ì¹˜ ë¹„ìœ¨\n",
    "- 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê±°ì˜ ë‹¤ ê²°ì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_missing_ratio = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")\n",
    "    .apply(lambda x: x.isna().mean())\n",
    ")\n",
    "\n",
    "company_missing_ratio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## ë³€ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì—…ë³„ ë¶„í¬ ë³´ê¸°\n",
    "- (ìš°ì„ ) ë³€ìˆ˜ ê¸°ì¤€ : ë§¤ì¶œì•¡\n",
    "-> ì´ë ‡ê²Œ í•˜ë©´ ë¹ˆ ê°’ í™•ì¸ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.columns = jemu_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # ëª¨ë“  í–‰ ë³´ê¸°\n",
    "jemu_df.groupby(\"ê¸°ì—…ëª…\")['ë§¤ì¶œì•¡'].count().sort_values()   # ê¸°ì—…ë³„ ë§¤ì¶œì•¡ì— ê°’ ë“¤ì–´ìˆëŠ” ê°œìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### ë§¤ì¶œì•¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_count = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")['ë§¤ì¶œì•¡']\n",
    "    .count()\n",
    ")\n",
    "\n",
    "count_distribution = sales_count.value_counts().sort_index()\n",
    "\n",
    "plt.figure()\n",
    "bars =plt.bar(\n",
    "    count_distribution.index,\n",
    "    count_distribution.values\n",
    ")\n",
    "plt.xticks(count_distribution.index)\n",
    "plt.xlabel(\"ê¸°ì—…ë³„ ë§¤ì¶œì•¡ ê°’ ê°œìˆ˜ (ì—°ë„ ìˆ˜)\")\n",
    "plt.ylabel(\"ê¸°ì—… ìˆ˜\")\n",
    "plt.title(\"ë§¤ì¶œì•¡ ë°ì´í„° ë³´ìœ  ê°œìˆ˜ë³„ ê¸°ì—… ë¶„í¬\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### ì—°êµ¬ê°œë°œë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_count = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")[\"ì—°êµ¬ê°œë°œë¹„\"]\n",
    "    .count()\n",
    ")\n",
    "\n",
    "count_distribution = sales_count.value_counts().sort_index()\n",
    "\n",
    "plt.figure()\n",
    "bars =plt.bar(\n",
    "    count_distribution.index,\n",
    "    count_distribution.values\n",
    ")\n",
    "plt.xticks(count_distribution.index)\n",
    "plt.xlabel(\"ê¸°ì—…ë³„ ì—°êµ¬ê°œë°œë¹„ ê°’ ê°œìˆ˜ (ì—°ë„ ìˆ˜)\")\n",
    "plt.ylabel(\"ê¸°ì—… ìˆ˜\")\n",
    "plt.title(\"ì—°êµ¬ê°œë°œë¹„ ë°ì´í„° ë³´ìœ  ê°œìˆ˜ë³„ ê¸°ì—… ë¶„í¬\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # ëª¨ë“  í–‰ ë³´ê¸°\n",
    "\n",
    "ales_count = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")[\"ë§¤ì¶œì•¡\"]\n",
    "    .count()\n",
    ")\n",
    "\n",
    "zero_sales_companies = sales_count[sales_count == 6]\n",
    "\n",
    "zero_sales_companies.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# KNN-test\n",
    "        1) ê°™ì€ ì—°ë„ + ê°™ì€ ì‚°ì—…(sectors/field) í›„ë³´ ì¶”ì¶œ\n",
    "        2) ì´ì›ƒ ê¸°ì¤€ ì»¬ëŸ¼ìœ¼ë¡œ KNN ì´ì›ƒ Kê°œ ì„ íƒ\n",
    "        3) ê·¸ ì´ì›ƒì„ ê³µí†µìœ¼ë¡œ ì‚¬ìš©\n",
    "        4) 8ê°œ ì¬ë¬´ ì»¬ëŸ¼ì„ ì„±ê²©ë³„ ê·œì¹™ìœ¼ë¡œ ëŒ€ì²´\n",
    "        5) KNN ì‹¤íŒ¨ ì‹œ Cold deck fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "- ì„¤ì •ê°’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ë“œ í•„í„° ì»¬ëŸ¼\n",
    "INDUSTRY_COL = \"sectors\"   # field ëŒ€ì‹  sectors ì‚¬ìš©\n",
    "\n",
    "# ğŸ”¥ [FIX] ì´ì›ƒ ê¸°ì¤€ ì»¬ëŸ¼ (ê³ ì •, ìˆ«ìë§Œ)\n",
    "NEIGHBOR_COLS = [\"ìì‚°\", \"ìë³¸\", \"ì¢…ì—…ì›_í•©ê³„\"]\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ëŒ€ì²´ ëŒ€ìƒ ì»¬ëŸ¼\n",
    "FLOW_COLS   = [\"ë§¤ì¶œì•¡\", \"ì˜ì—…ì´ìµ\", \"ë‹¹ê¸°ìˆœì´ìµ\"]\n",
    "STOCK_COLS  = [\"ë¶€ì±„\"]\n",
    "INVEST_COLS = [\"ì—°êµ¬ê°œë°œë¹„\", \"CAPEX\"]\n",
    "\n",
    "TARGET_COLS = FLOW_COLS + STOCK_COLS + INVEST_COLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "- ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0. ì»¬ëŸ¼ëª… ì •ê·œí™” (í•„ìˆ˜)\n",
    "# =========================\n",
    "# ğŸ”¥ [FIX] NBSP / ê³µë°± ë¬¸ì œ í•´ê²°\n",
    "jemu_df.columns = (\n",
    "    jemu_df.columns\n",
    "    .str.replace(\"\\xa0\", \" \", regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# ğŸ”¥ [NEW] KNN / Cold deck ì „ í•„ìˆ˜ ì „ì²˜ë¦¬\n",
    "# =========================\n",
    "# ğŸ”¥ [FIX] ì´ì›ƒ ê¸°ì¤€ ì»¬ëŸ¼ ìˆ«ì ë³€í™˜\n",
    "for col in NEIGHBOR_COLS:\n",
    "    jemu_df[col] = pd.to_numeric(jemu_df[col], errors=\"coerce\")\n",
    "\n",
    "# ì—°ë„ ìˆ«ì ë³€í™˜\n",
    "jemu_df[\"ì—°ë„\"] = pd.to_numeric(jemu_df[\"ì—°ë„\"], errors=\"coerce\")\n",
    "\n",
    "# ğŸ”¥ [FIX] ëŒ€ì²´ ëŒ€ìƒ ì»¬ëŸ¼ ìˆ«ì ë³€í™˜\n",
    "for col in TARGET_COLS:\n",
    "    jemu_df[col] = pd.to_numeric(jemu_df[col], errors=\"coerce\")\n",
    "\n",
    "# ğŸ”¥ [NEW] _filled ì»¬ëŸ¼\n",
    "for col in TARGET_COLS:\n",
    "    if f\"{col}_filled\" not in jemu_df.columns:\n",
    "        jemu_df[f\"{col}_filled\"] = jemu_df[col]\n",
    "\n",
    "# ğŸ”¥ [NEW] ì»¬ëŸ¼ë³„ imputation method ë¡œê·¸\n",
    "for col in TARGET_COLS:\n",
    "    if f\"{col}_imputation_method\" not in jemu_df.columns:\n",
    "        jemu_df[f\"{col}_imputation_method\"] = pd.NA\n",
    "\n",
    "# ğŸ”¥ [FIX] ì›ë˜ ê°’ì€ ì ˆëŒ€ KNN / COLD_DECKìœ¼ë¡œ ì°íˆì§€ ì•Šê²Œ\n",
    "for col in TARGET_COLS:\n",
    "    jemu_df.loc[\n",
    "        jemu_df[col].notna(),\n",
    "        f\"{col}_imputation_method\"\n",
    "    ] = \"ORIGINAL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "- ê¸°ì—…â€“ì—°ë„ ë‹¨ìœ„ KNN ì´ì›ƒ ì°¾ê¸° í•¨ìˆ˜ (ì™„í™” ë²„ì „)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_knn_neighbors_by_year(df, company, year, k=3):\n",
    "\n",
    "    target = df[\n",
    "        (df[\"ê¸°ì—…ëª…\"] == company) &\n",
    "        (df[\"ì—°ë„\"] == year)\n",
    "    ]\n",
    "    if target.empty:\n",
    "        return None\n",
    "\n",
    "    industry = target[INDUSTRY_COL].values[0]\n",
    "\n",
    "    # ğŸ”¥ [FIX] ì‚°ì—… ì •ë³´ ì—†ìœ¼ë©´ KNN ë¶ˆê°€\n",
    "    if pd.isna(industry):\n",
    "        return None\n",
    "\n",
    "    # ğŸ”¥ [FIX] ì´ì›ƒ ê¸°ì¤€ ì»¬ëŸ¼ ì¤‘ 2ê°œ ì´ìƒ í•„ìš”\n",
    "    if target[NEIGHBOR_COLS].notna().sum(axis=1).values[0] < 2:\n",
    "        return None\n",
    "\n",
    "    # í•˜ë“œ í•„í„°\n",
    "    candidates = df[\n",
    "        (df[\"ì—°ë„\"] == year) &\n",
    "        (df[INDUSTRY_COL] == industry) &\n",
    "        (df[\"ê¸°ì—…ëª…\"] != company)\n",
    "    ].copy()\n",
    "\n",
    "    # í›„ë³´ë„ êµ¬ì¡° ì •ë³´ 2ê°œ ì´ìƒ í•„ìš”\n",
    "    candidates = candidates[\n",
    "        candidates[NEIGHBOR_COLS].notna().sum(axis=1) >= 2\n",
    "    ]\n",
    "\n",
    "    if len(candidates) < k:\n",
    "        return None\n",
    "\n",
    "    # ê±°ë¦¬ ê³„ì‚°ìš© ë°ì´í„° êµ¬ì„±\n",
    "    X_cand = candidates[NEIGHBOR_COLS].fillna(candidates[NEIGHBOR_COLS].mean())\n",
    "    X_tgt  = target[NEIGHBOR_COLS].fillna(candidates[NEIGHBOR_COLS].mean())\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_all = pd.concat([X_cand, X_tgt])\n",
    "    X_scaled = scaler.fit_transform(X_all)\n",
    "\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(X_scaled[:-1])\n",
    "    _, idx = knn.kneighbors(X_scaled[-1].reshape(1, -1))\n",
    "\n",
    "    return candidates.iloc[idx[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "- KNN ì´ì›ƒ ê¸°ë°˜ ê²°ì¸¡ ëŒ€ì²´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_from_neighbors(neighbors):\n",
    "    result = {}\n",
    "\n",
    "    for col in FLOW_COLS:\n",
    "        v = neighbors[col].dropna()\n",
    "        if len(v) > 0:\n",
    "            result[col] = v.median()\n",
    "\n",
    "    for col in STOCK_COLS:\n",
    "        v = neighbors[col].dropna()\n",
    "        if len(v) > 0:\n",
    "            result[col] = v.median()\n",
    "\n",
    "    for col in INVEST_COLS:\n",
    "        v = neighbors[col].dropna()\n",
    "        result[col] = v.median() if len(v) > 0 else 0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "- Cold deck (KNN ë¶ˆê°€ ì‹œ ëŒ€ì²´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cold_deck_impute(df, company, year):\n",
    "\n",
    "    target = df[\n",
    "        (df[\"ê¸°ì—…ëª…\"] == company) &\n",
    "        (df[\"ì—°ë„\"] == year)\n",
    "    ]\n",
    "    if target.empty:\n",
    "        return {}\n",
    "\n",
    "    industry = target[INDUSTRY_COL].values[0]\n",
    "    result = {}\n",
    "\n",
    "    for col in TARGET_COLS:\n",
    "\n",
    "        if not pd.isna(target[col].values[0]):\n",
    "            continue\n",
    "\n",
    "        vals = df[\n",
    "            (df[\"ì—°ë„\"] == year) &\n",
    "            (df[INDUSTRY_COL] == industry)\n",
    "        ][col].dropna()\n",
    "\n",
    "        result[col] = vals.median() if len(vals) > 0 else df[col].median()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "- ì „ì²´ ì‹¤í–‰ ë£¨í”„ (KNN + Cold deck í†µí•©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in tqdm(\n",
    "    jemu_df[\"ê¸°ì—…ëª…\"].unique(),\n",
    "    desc=\"ê¸°ì—… ë‹¨ìœ„ ê²°ì¸¡ì¹˜ ë³´ì™„\"\n",
    "):\n",
    "\n",
    "    company_df = jemu_df[jemu_df[\"ê¸°ì—…ëª…\"] == company]\n",
    "\n",
    "    missing_years = company_df[\n",
    "        company_df[TARGET_COLS].isna().any(axis=1)\n",
    "    ][\"ì—°ë„\"].unique()\n",
    "\n",
    "    for year in missing_years:\n",
    "\n",
    "        neighbors = find_knn_neighbors_by_year(\n",
    "            df=jemu_df,\n",
    "            company=company,\n",
    "            year=year,\n",
    "            k=3\n",
    "        )\n",
    "\n",
    "        if neighbors is not None:\n",
    "            imputed = impute_from_neighbors(neighbors)\n",
    "            method = \"KNN\"\n",
    "        else:\n",
    "            imputed = cold_deck_impute(jemu_df, company, year)\n",
    "            method = \"COLD_DECK\"\n",
    "\n",
    "        for col, value in imputed.items():\n",
    "\n",
    "            mask = (\n",
    "                (jemu_df[\"ê¸°ì—…ëª…\"] == company) &\n",
    "                (jemu_df[\"ì—°ë„\"] == year) &\n",
    "                (jemu_df[col].isna())\n",
    "            )\n",
    "\n",
    "            # ê°’ ì±„ìš°ê¸°\n",
    "            jemu_df.loc[mask, f\"{col}_filled\"] = value\n",
    "\n",
    "            # ğŸ”¥ [FIX] ì±„ì›Œì§„ ì…€ì—ë§Œ method ê¸°ë¡\n",
    "            jemu_df.loc[mask, f\"{col}_imputation_method\"] = method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in TARGET_COLS:\n",
    "    print(col)\n",
    "    print(jemu_df[f\"{col}_imputation_method\"].value_counts())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in TARGET_COLS:\n",
    "    filled_col = f\"{col}_filled\"\n",
    "\n",
    "    filled_count = (\n",
    "        jemu_df[col].isna() &\n",
    "        jemu_df[filled_col].notna()\n",
    "    ).sum()\n",
    "\n",
    "    print(f\"{col}: ìƒˆë¡œ ì±„ì›Œì§„ ê°œìˆ˜ = {filled_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df[\"imputation_method\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========================================\n",
    "# ê³µí†µ ì„¤ì •\n",
    "# ========================================\n",
    "FINANCIAL_COLS = [\n",
    "    'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ',\n",
    "    'ìì‚°', 'ë¶€ì±„', 'ìë³¸',\n",
    "    'ì—°êµ¬ê°œë°œë¹„', 'CAPEX'\n",
    "]\n",
    "\n",
    "INDUSTRY_COL = 'sectors'\n",
    "YEAR_COL = 'ì—°ë„'\n",
    "COMPANY_COL = 'ê¸°ì—…ëª…'\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ğŸ”´ [ìˆ˜ì • 1] ì¬ë¬´ ì»¬ëŸ¼ ìˆ«ìí˜• ê°•ì œ ë³€í™˜\n",
    "# ========================================\n",
    "def ensure_numeric_financial_cols(df):\n",
    "    df = df.copy()\n",
    "    df[FINANCIAL_COLS] = df[FINANCIAL_COLS].apply(\n",
    "        pd.to_numeric, errors='coerce'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 1ë‹¨ê³„: ê¸°ì—… í”„ë¡œí•„ ìƒì„±\n",
    "# ========================================\n",
    "def create_company_profile(df):\n",
    "    company_profile = (\n",
    "        df.groupby(COMPANY_COL)\n",
    "        .agg({\n",
    "            'ë§¤ì¶œì•¡': 'median',\n",
    "            'ìì‚°': 'median',\n",
    "            INDUSTRY_COL: 'first'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    company_profile['ê·œëª¨'] = pd.cut(\n",
    "        company_profile['ë§¤ì¶œì•¡'],\n",
    "        bins=[0, 100, 500, 1000, np.inf],\n",
    "        labels=['ì†Œí˜•', 'ì¤‘ì†Œí˜•', 'ì¤‘í˜•', 'ëŒ€í˜•']\n",
    "    )\n",
    "\n",
    "    company_profile['ê·œëª¨'] = company_profile['ê·œëª¨'].cat.add_categories(['Unknown'])\n",
    "    company_profile.loc[company_profile['ë§¤ì¶œì•¡'].isnull(), 'ê·œëª¨'] = 'Unknown'\n",
    "\n",
    "    return company_profile\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 2ë‹¨ê³„: ìœ ì‚¬ ê¸°ì—… ì¤‘ì•™ê°’ ëŒ€ì²´\n",
    "# ========================================\n",
    "def impute_by_similar_companies(df, company_profile):\n",
    "    df_imputed = df.copy()\n",
    "    missing_rows = df[df[FINANCIAL_COLS].isnull().any(axis=1)]\n",
    "\n",
    "    for idx, row in missing_rows.iterrows():\n",
    "        company = row[COMPANY_COL]\n",
    "        year = row[YEAR_COL]\n",
    "\n",
    "        profile_row = company_profile[company_profile[COMPANY_COL] == company]\n",
    "        if profile_row.empty:\n",
    "            continue\n",
    "        profile = profile_row.iloc[0]\n",
    "\n",
    "        similar_companies = []\n",
    "\n",
    "        if profile['ê·œëª¨'] != 'Unknown':\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile[INDUSTRY_COL] == profile[INDUSTRY_COL]) &\n",
    "                (company_profile['ê·œëª¨'] == profile['ê·œëª¨']) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        if len(similar_companies) < 3:\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile[INDUSTRY_COL] == profile[INDUSTRY_COL]) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        if len(similar_companies) < 3 and profile['ê·œëª¨'] != 'Unknown':\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile['ê·œëª¨'] == profile['ê·œëª¨']) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        similar_data = df[\n",
    "            (df[COMPANY_COL].isin(similar_companies)) &\n",
    "            (df[YEAR_COL] == year)\n",
    "        ]\n",
    "\n",
    "        for col in FINANCIAL_COLS:\n",
    "            if pd.isnull(row[col]) and similar_data[col].dropna().shape[0] >= 3:\n",
    "                df_imputed.at[idx, col] = similar_data[col].median()\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 3ë‹¨ê³„: KNN Imputation (ì‚°ì—… + ì—°ë„)\n",
    "# ========================================\n",
    "def knn_impute_by_industry_year(df, n_neighbors=5):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    for (industry, year), group in df.groupby([INDUSTRY_COL, YEAR_COL]):\n",
    "        if len(group) <= n_neighbors:\n",
    "            continue\n",
    "\n",
    "        imputer = KNNImputer(\n",
    "            n_neighbors=min(n_neighbors, len(group) - 1),\n",
    "            weights='distance'\n",
    "        )\n",
    "\n",
    "        imputed = imputer.fit_transform(group[FINANCIAL_COLS])\n",
    "        df_imputed.loc[group.index, FINANCIAL_COLS] = imputed\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 4ë‹¨ê³„: í†µí•© ì‹¤í–‰\n",
    "# ========================================\n",
    "def hybrid_imputation(df):\n",
    "    df_result = ensure_numeric_financial_cols(df)  # ğŸ”´ ì—¬ê¸°ì„œ ë¨¼ì € ë³€í™˜\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ì´ˆê¸° ê²°ì¸¡ì¹˜: {df_result[FINANCIAL_COLS].isnull().sum().sum()}ê°œ\\n\")\n",
    "\n",
    "    company_profile = create_company_profile(df_result)\n",
    "    print(f\"ê¸°ì—… í”„ë¡œí•„ ìƒì„± ì™„ë£Œ: {len(company_profile)}ê°œ ê¸°ì—…\")\n",
    "\n",
    "    print(\"\\n[Step 1] ìœ ì‚¬ ê¸°ì—… ì¤‘ì•™ê°’ ëŒ€ì²´ ì¤‘...\")\n",
    "    df_result = impute_by_similar_companies(df_result, company_profile)\n",
    "    remaining = df_result[FINANCIAL_COLS].isnull().sum().sum()\n",
    "    print(f\"âœ“ ì™„ë£Œ | ë‚¨ì€ ê²°ì¸¡ì¹˜: {remaining}ê°œ\")\n",
    "\n",
    "    if remaining > 0:\n",
    "        print(\"\\n[Step 2] KNN ëŒ€ì²´ ì¤‘ (ì‚°ì—…+ì—°ë„ ê¸°ì¤€)...\")\n",
    "        df_result = knn_impute_by_industry_year(df_result)\n",
    "        remaining = df_result[FINANCIAL_COLS].isnull().sum().sum()\n",
    "        print(f\"âœ“ ì™„ë£Œ | ë‚¨ì€ ê²°ì¸¡ì¹˜: {remaining}ê°œ\")\n",
    "\n",
    "    print(\"\\nê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return df_result, company_profile\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 5ë‹¨ê³„: ì‹¤í–‰\n",
    "# ========================================\n",
    "df_final, company_profile = hybrid_imputation(jemu_df)\n",
    "\n",
    "print(\"\\n[ë³€ìˆ˜ë³„ ë‚¨ì€ ê²°ì¸¡ì¹˜]\")\n",
    "print(df_final[FINANCIAL_COLS].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"../../output/jemu_df_imputed.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========================================\n",
    "# ê³µí†µ ì„¤ì •\n",
    "# ========================================\n",
    "FINANCIAL_COLS = [\n",
    "    'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ',\n",
    "    'ìì‚°', 'ë¶€ì±„', 'ìë³¸',\n",
    "    'ì—°êµ¬ê°œë°œë¹„', 'CAPEX'\n",
    "]\n",
    "\n",
    "INDUSTRY_COL = 'field'\n",
    "YEAR_COL = 'ì—°ë„'\n",
    "COMPANY_COL = 'ê¸°ì—…ëª…'\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ğŸ”´ [ìˆ˜ì • 1] ì¬ë¬´ ì»¬ëŸ¼ ìˆ«ìí˜• ê°•ì œ ë³€í™˜\n",
    "# ========================================\n",
    "def ensure_numeric_financial_cols(df):\n",
    "    df = df.copy()\n",
    "    df[FINANCIAL_COLS] = df[FINANCIAL_COLS].apply(\n",
    "        pd.to_numeric, errors='coerce'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 1ë‹¨ê³„: ê¸°ì—… í”„ë¡œí•„ ìƒì„±\n",
    "# ========================================\n",
    "def create_company_profile(df):\n",
    "    company_profile = (\n",
    "        df.groupby(COMPANY_COL)\n",
    "        .agg({\n",
    "            'ë§¤ì¶œì•¡': 'median',\n",
    "            'ìì‚°': 'median',\n",
    "            INDUSTRY_COL: 'first'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    company_profile['ê·œëª¨'] = pd.cut(\n",
    "        company_profile['ë§¤ì¶œì•¡'],\n",
    "        bins=[0, 100, 500, 1000, np.inf],\n",
    "        labels=['ì†Œí˜•', 'ì¤‘ì†Œí˜•', 'ì¤‘í˜•', 'ëŒ€í˜•']\n",
    "    )\n",
    "\n",
    "    company_profile['ê·œëª¨'] = company_profile['ê·œëª¨'].cat.add_categories(['Unknown'])\n",
    "    company_profile.loc[company_profile['ë§¤ì¶œì•¡'].isnull(), 'ê·œëª¨'] = 'Unknown'\n",
    "\n",
    "    return company_profile\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 2ë‹¨ê³„: ìœ ì‚¬ ê¸°ì—… ì¤‘ì•™ê°’ ëŒ€ì²´\n",
    "# ========================================\n",
    "def impute_by_similar_companies(df, company_profile):\n",
    "    df_imputed = df.copy()\n",
    "    missing_rows = df[df[FINANCIAL_COLS].isnull().any(axis=1)]\n",
    "\n",
    "    for idx, row in missing_rows.iterrows():\n",
    "        company = row[COMPANY_COL]\n",
    "        year = row[YEAR_COL]\n",
    "\n",
    "        profile_row = company_profile[company_profile[COMPANY_COL] == company]\n",
    "        if profile_row.empty:\n",
    "            continue\n",
    "        profile = profile_row.iloc[0]\n",
    "\n",
    "        similar_companies = []\n",
    "\n",
    "        if profile['ê·œëª¨'] != 'Unknown':\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile[INDUSTRY_COL] == profile[INDUSTRY_COL]) &\n",
    "                (company_profile['ê·œëª¨'] == profile['ê·œëª¨']) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        if len(similar_companies) < 3:\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile[INDUSTRY_COL] == profile[INDUSTRY_COL]) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        if len(similar_companies) < 3 and profile['ê·œëª¨'] != 'Unknown':\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile['ê·œëª¨'] == profile['ê·œëª¨']) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        similar_data = df[\n",
    "            (df[COMPANY_COL].isin(similar_companies)) &\n",
    "            (df[YEAR_COL] == year)\n",
    "        ]\n",
    "\n",
    "        for col in FINANCIAL_COLS:\n",
    "            if pd.isnull(row[col]) and similar_data[col].dropna().shape[0] >= 3:\n",
    "                df_imputed.at[idx, col] = similar_data[col].median()\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 3ë‹¨ê³„: KNN Imputation (ì‚°ì—… + ì—°ë„)\n",
    "# ========================================\n",
    "def knn_impute_by_industry_year(df, n_neighbors=5):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    for (industry, year), group in df.groupby([INDUSTRY_COL, YEAR_COL]):\n",
    "        if len(group) <= n_neighbors:\n",
    "            continue\n",
    "\n",
    "        imputer = KNNImputer(\n",
    "            n_neighbors=min(n_neighbors, len(group) - 1),\n",
    "            weights='distance'\n",
    "        )\n",
    "\n",
    "        imputed = imputer.fit_transform(group[FINANCIAL_COLS])\n",
    "        df_imputed.loc[group.index, FINANCIAL_COLS] = imputed\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 4ë‹¨ê³„: í†µí•© ì‹¤í–‰\n",
    "# ========================================\n",
    "def hybrid_imputation(df):\n",
    "    df_result = ensure_numeric_financial_cols(df)  # ğŸ”´ ì—¬ê¸°ì„œ ë¨¼ì € ë³€í™˜\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ì´ˆê¸° ê²°ì¸¡ì¹˜: {df_result[FINANCIAL_COLS].isnull().sum().sum()}ê°œ\\n\")\n",
    "\n",
    "    company_profile = create_company_profile(df_result)\n",
    "    print(f\"ê¸°ì—… í”„ë¡œí•„ ìƒì„± ì™„ë£Œ: {len(company_profile)}ê°œ ê¸°ì—…\")\n",
    "\n",
    "    print(\"\\n[Step 1] ìœ ì‚¬ ê¸°ì—… ì¤‘ì•™ê°’ ëŒ€ì²´ ì¤‘...\")\n",
    "    df_result = impute_by_similar_companies(df_result, company_profile)\n",
    "    remaining = df_result[FINANCIAL_COLS].isnull().sum().sum()\n",
    "    print(f\"âœ“ ì™„ë£Œ | ë‚¨ì€ ê²°ì¸¡ì¹˜: {remaining}ê°œ\")\n",
    "\n",
    "    if remaining > 0:\n",
    "        print(\"\\n[Step 2] KNN ëŒ€ì²´ ì¤‘ (ì‚°ì—…+ì—°ë„ ê¸°ì¤€)...\")\n",
    "        df_result = knn_impute_by_industry_year(df_result)\n",
    "        remaining = df_result[FINANCIAL_COLS].isnull().sum().sum()\n",
    "        print(f\"âœ“ ì™„ë£Œ | ë‚¨ì€ ê²°ì¸¡ì¹˜: {remaining}ê°œ\")\n",
    "\n",
    "    print(\"\\nê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return df_result, company_profile\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 5ë‹¨ê³„: ì‹¤í–‰\n",
    "# ========================================\n",
    "df_final, company_profile = hybrid_imputation(jemu_df)\n",
    "\n",
    "print(\"\\n[ë³€ìˆ˜ë³„ ë‚¨ì€ ê²°ì¸¡ì¹˜]\")\n",
    "print(df_final[FINANCIAL_COLS].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"../../output/jemu_df_imputed_fields.csv\", index=False, encoding=\"cp949\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
