{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#########################################################################\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "#########################################################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "#########################################################################\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. í•œê¸€ í°íŠ¸ ê²½ë¡œ ì„¤ì • (Windows ê¸°ë³¸: ë§‘ì€ ê³ ë”•)\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "# 2. matplotlibì— í°íŠ¸ ì ìš©\n",
    "mpl.rc(\"font\", family=font_name)\n",
    "\n",
    "# 3. ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df = pd.read_csv('../../data/ì¬ë¬´ì •ë³´_final_v2(16~24).csv', encoding='utf-8-sig')\n",
    "jemu_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# ì „ì²´ ë°ì´í„° eda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## DF í˜•íƒœ íŒŒì•…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³ ìœ  ê¸°ì—…ëª…ë§Œ\n",
    "jemu_df[\"ê¸°ì—…ëª…\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ê¸°ì—…ì— ëŒ€í•œ í–‰ ë³´ê¸°\n",
    "jemu_df[jemu_df[\"ê¸°ì—…ëª…\"] == \"íœ´ë¹„ì˜¤ ì£¼ì‹íšŒì‚¬\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### ì»¬ëŸ¼ëª…ë“¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### ê¸°ì—…ë³„ í–‰ ê°œìˆ˜\n",
    "- ëª¨ë“  ê°’ì´ ë‹¤ 6ì´ ë‚˜ì™€ì•¼ ì •ìƒ -> ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # ëª¨ë“  í–‰ ë³´ê¸°\n",
    "jemu_df.groupby(\"ê¸°ì—…ëª…\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### ê¸°ì—…ë³„ ê²°ì¸¡ì¹˜ ë¹„ìœ¨\n",
    "- 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê±°ì˜ ë‹¤ ê²°ì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_missing_ratio = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")\n",
    "    .apply(lambda x: x.isna().mean())\n",
    ")\n",
    "\n",
    "company_missing_ratio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## ë³€ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì—…ë³„ ë¶„í¬ ë³´ê¸°\n",
    "- (ìš°ì„ ) ë³€ìˆ˜ ê¸°ì¤€ : ë§¤ì¶œì•¡\n",
    "-> ì´ë ‡ê²Œ í•˜ë©´ ë¹ˆ ê°’ í™•ì¸ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.columns = jemu_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemu_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # ëª¨ë“  í–‰ ë³´ê¸°\n",
    "jemu_df.groupby(\"ê¸°ì—…ëª…\")['ë§¤ì¶œì•¡'].count().sort_values()   # ê¸°ì—…ë³„ ë§¤ì¶œì•¡ì— ê°’ ë“¤ì–´ìˆëŠ” ê°œìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### ë§¤ì¶œì•¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_count = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")['ë§¤ì¶œì•¡']\n",
    "    .count()\n",
    ")\n",
    "\n",
    "count_distribution = sales_count.value_counts().sort_index()\n",
    "\n",
    "plt.figure()\n",
    "bars =plt.bar(\n",
    "    count_distribution.index,\n",
    "    count_distribution.values\n",
    ")\n",
    "plt.xticks(count_distribution.index)\n",
    "plt.xlabel(\"ê¸°ì—…ë³„ ë§¤ì¶œì•¡ ê°’ ê°œìˆ˜ (ì—°ë„ ìˆ˜)\")\n",
    "plt.ylabel(\"ê¸°ì—… ìˆ˜\")\n",
    "plt.title(\"ë§¤ì¶œì•¡ ë°ì´í„° ë³´ìœ  ê°œìˆ˜ë³„ ê¸°ì—… ë¶„í¬\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### ì—°êµ¬ê°œë°œë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_count = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")[\"ì—°êµ¬ê°œë°œë¹„\"]\n",
    "    .count()\n",
    ")\n",
    "\n",
    "count_distribution = sales_count.value_counts().sort_index()\n",
    "\n",
    "plt.figure()\n",
    "bars =plt.bar(\n",
    "    count_distribution.index,\n",
    "    count_distribution.values\n",
    ")\n",
    "plt.xticks(count_distribution.index)\n",
    "plt.xlabel(\"ê¸°ì—…ë³„ ì—°êµ¬ê°œë°œë¹„ ê°’ ê°œìˆ˜ (ì—°ë„ ìˆ˜)\")\n",
    "plt.ylabel(\"ê¸°ì—… ìˆ˜\")\n",
    "plt.title(\"ì—°êµ¬ê°œë°œë¹„ ë°ì´í„° ë³´ìœ  ê°œìˆ˜ë³„ ê¸°ì—… ë¶„í¬\")\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height,\n",
    "        int(height),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None) # ëª¨ë“  í–‰ ë³´ê¸°\n",
    "\n",
    "ales_count = (\n",
    "    jemu_df\n",
    "    .groupby(\"ê¸°ì—…ëª…\")[\"ë§¤ì¶œì•¡\"]\n",
    "    .count()\n",
    ")\n",
    "\n",
    "zero_sales_companies = sales_count[sales_count == 6]\n",
    "\n",
    "zero_sales_companies.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "# KNN-test\n",
    "        1) ê°™ì€ ì—°ë„ + ê°™ì€ ì‚°ì—…(sectors/field) í›„ë³´ ì¶”ì¶œ\n",
    "        2) ì´ì›ƒ ê¸°ì¤€ ì»¬ëŸ¼ìœ¼ë¡œ KNN ì´ì›ƒ Kê°œ ì„ íƒ\n",
    "        3) ê·¸ ì´ì›ƒì„ ê³µí†µìœ¼ë¡œ ì‚¬ìš©\n",
    "        4) 8ê°œ ì¬ë¬´ ì»¬ëŸ¼ì„ ì„±ê²©ë³„ ê·œì¹™ìœ¼ë¡œ ëŒ€ì²´\n",
    "        5) KNN ì‹¤íŒ¨ ì‹œ Cold deck fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### sectors ê¸°ì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =====================================================\n",
    "# 0. ê¸°ë³¸ ì„¤ì •\n",
    "# =====================================================\n",
    "FINANCIAL_COLS = [\n",
    "    'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ',\n",
    "    'ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„',\n",
    "    'ì—°êµ¬ê°œë°œë¹„', 'CAPEX'\n",
    "]\n",
    "\n",
    "COMPANY_COL = 'ê¸°ì—…ëª…'\n",
    "YEAR_COL = 'ì—°ë„'\n",
    "INDUSTRY_COL = 'sectors'\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. ìˆ«ìí˜• ë³€í™˜ (ê¸°ë³¸ ì „ì²˜ë¦¬)\n",
    "# =====================================================\n",
    "def ensure_numeric(df):\n",
    "    df = df.copy()\n",
    "    df[FINANCIAL_COLS] = df[FINANCIAL_COLS].apply(\n",
    "        pd.to_numeric, errors='coerce'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. ê¸°ì—… ë‚´ë¶€ ì‹œê³„ì—´ ë³´ê°„ (index-safe)\n",
    "# =====================================================\n",
    "def impute_by_company_timeseries(df):\n",
    "    df = df.sort_values([COMPANY_COL, YEAR_COL]).copy()\n",
    "\n",
    "    for col in FINANCIAL_COLS:\n",
    "        df[col] = (\n",
    "            df.groupby(COMPANY_COL)[col]\n",
    "            .transform(lambda x: x.interpolate(limit=1))\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. ìœ ì‚¬ ê¸°ì—… ì¤‘ì•™ê°’ ëŒ€ì²´ (ì—°ë„ ì™œê³¡ ë°©ì§€)\n",
    "# =====================================================\n",
    "def impute_by_similar_companies_safe(df):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if not row[FINANCIAL_COLS].isnull().any():\n",
    "            continue\n",
    "\n",
    "        company = row[COMPANY_COL]\n",
    "        year = row[YEAR_COL]\n",
    "        industry = row[INDUSTRY_COL]\n",
    "\n",
    "        # ê°™ì€ ì‚°ì—… + ê°™ì€ ì—°ë„\n",
    "        candidates = df[\n",
    "            (df[INDUSTRY_COL] == industry) &\n",
    "            (df[YEAR_COL] == year) &\n",
    "            (df[COMPANY_COL] != company)\n",
    "        ]\n",
    "\n",
    "        # í‘œë³¸ ìˆ˜ê°€ ì¶©ë¶„í•  ë•Œë§Œ\n",
    "        if len(candidates) < 5:\n",
    "            continue\n",
    "\n",
    "        for col in FINANCIAL_COLS:\n",
    "            if pd.isna(row[col]):\n",
    "                valid_vals = candidates[col].dropna()\n",
    "                if len(valid_vals) >= 5:\n",
    "                    df_imputed.at[idx, col] = valid_vals.median()\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. KNN Imputation (ìµœí›„ ìˆ˜ë‹¨, shape-safe)\n",
    "# =====================================================\n",
    "def knn_impute_safe(df, n_neighbors=5):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    for (industry, year), group in df.groupby([INDUSTRY_COL, YEAR_COL]):\n",
    "\n",
    "        # ì‹¤ì œ ê°’ì´ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ\n",
    "        valid_cols = [\n",
    "            c for c in FINANCIAL_COLS\n",
    "            if group[c].notna().sum() > 0\n",
    "        ]\n",
    "\n",
    "        # ìµœì†Œ ì¡°ê±´\n",
    "        if len(group) <= n_neighbors or len(valid_cols) <= 1:\n",
    "            continue\n",
    "\n",
    "        imputer = KNNImputer(\n",
    "            n_neighbors=min(n_neighbors, len(group) - 1),\n",
    "            weights='distance'\n",
    "        )\n",
    "\n",
    "        imputed_array = imputer.fit_transform(group[valid_cols])\n",
    "\n",
    "        # ndarray â†’ DataFrame (index / columns ëª…ì‹œ)\n",
    "        imputed_df = pd.DataFrame(\n",
    "            imputed_array,\n",
    "            index=group.index,\n",
    "            columns=valid_cols\n",
    "        )\n",
    "\n",
    "        df_imputed.loc[group.index, valid_cols] = imputed_df\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
    "# =====================================================\n",
    "def final_imputation_pipeline(df):\n",
    "    df = ensure_numeric(df)\n",
    "\n",
    "    print(\"â–¶ Step 1: ê¸°ì—… ë‚´ë¶€ ì‹œê³„ì—´ ë³´ê°„\")\n",
    "    df = impute_by_company_timeseries(df)\n",
    "\n",
    "    print(\"â–¶ Step 2: ìœ ì‚¬ ê¸°ì—… ì¤‘ì•™ê°’ ëŒ€ì²´ (ë³´ìˆ˜ì )\")\n",
    "    df = impute_by_similar_companies_safe(df)\n",
    "\n",
    "    print(\"â–¶ Step 3: KNN ëŒ€ì²´ (ìµœí›„ ìˆ˜ë‹¨)\")\n",
    "    df = knn_impute_safe(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6. ì‹¤í–‰\n",
    "# =====================================================\n",
    "df_final = final_imputation_pipeline(jemu_df)\n",
    "\n",
    "print(\"\\n[ìµœì¢… ë³€ìˆ˜ë³„ ë‚¨ì€ ê²°ì¸¡ì¹˜]\")\n",
    "print(df_final[FINANCIAL_COLS].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"../../output/jemu_df_imputed_sectors_ver5.csv\", index=False, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### fields ê¸°ì¤€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========================================\n",
    "# 0ë‹¨ê³„: CSV ë¡œë“œ + ì»¬ëŸ¼ëª… ì •ë¦¬\n",
    "# ========================================\n",
    "jemu_df = pd.read_csv(\n",
    "    '../../data/ì¬ë¬´ì •ë³´_final_v2(16~24).csv',\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "\n",
    "# ğŸ”´ í•µì‹¬: ì»¬ëŸ¼ëª… ì•ë’¤ ê³µë°± ì œê±°\n",
    "jemu_df.columns = jemu_df.columns.str.strip()\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ê³µí†µ ì„¤ì •\n",
    "# ========================================\n",
    "FINANCIAL_COLS = [\n",
    "    'ë§¤ì¶œì•¡', 'ì˜ì—…ì´ìµ', 'ë‹¹ê¸°ìˆœì´ìµ',\n",
    "    'ìì‚°ì´ê³„', 'ë¶€ì±„ì´ê³„', 'ìë³¸ì´ê³„',\n",
    "    'ì—°êµ¬ê°œë°œë¹„', 'CAPEX'\n",
    "]\n",
    "\n",
    "COMPANY_COL = 'ê¸°ì—…ëª…'\n",
    "YEAR_COL = 'ì—°ë„'\n",
    "INDUSTRY_COL = 'field'\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 1ë‹¨ê³„: ì¬ë¬´ ì»¬ëŸ¼ ìˆ«ìí˜• ê°•ì œ ë³€í™˜\n",
    "# ========================================\n",
    "def ensure_numeric_financial_cols(df):\n",
    "    df = df.copy()\n",
    "    df[FINANCIAL_COLS] = df[FINANCIAL_COLS].apply(\n",
    "        pd.to_numeric, errors='coerce'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 2ë‹¨ê³„: ê¸°ì—… í”„ë¡œí•„ ìƒì„±\n",
    "# ========================================\n",
    "def create_company_profile(df):\n",
    "    company_profile = (\n",
    "        df.groupby(COMPANY_COL)\n",
    "        .agg({\n",
    "            'ë§¤ì¶œì•¡': 'median',\n",
    "            'ìì‚°ì´ê³„': 'median',\n",
    "            INDUSTRY_COL: 'first'\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    company_profile['ê·œëª¨'] = pd.cut(\n",
    "        company_profile['ë§¤ì¶œì•¡'],\n",
    "        bins=[0, 100, 500, 1000, np.inf],\n",
    "        labels=['ì†Œí˜•', 'ì¤‘ì†Œí˜•', 'ì¤‘í˜•', 'ëŒ€í˜•']\n",
    "    )\n",
    "    company_profile['ê·œëª¨'] = company_profile['ê·œëª¨'].cat.add_categories(['Unknown'])\n",
    "    company_profile.loc[company_profile['ë§¤ì¶œì•¡'].isnull(), 'ê·œëª¨'] = 'Unknown'\n",
    "\n",
    "    return company_profile\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 3ë‹¨ê³„: ì¤‘ì•™ê°’ ëŒ€ì²´ + ì¶”ì \n",
    "# ========================================\n",
    "def impute_by_similar_companies(df, company_profile):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    # ğŸ”¹ ì¶”ì  ì»¬ëŸ¼ ìƒì„±\n",
    "    df_imputed['impute_method'] = np.nan\n",
    "    df_imputed['impute_source_companies'] = np.nan\n",
    "    df_imputed['impute_k'] = np.nan\n",
    "\n",
    "    missing_rows = df[df[FINANCIAL_COLS].isnull().any(axis=1)]\n",
    "\n",
    "    for idx, row in missing_rows.iterrows():\n",
    "        company = row[COMPANY_COL]\n",
    "        year = row[YEAR_COL]\n",
    "\n",
    "        profile_row = company_profile[company_profile[COMPANY_COL] == company]\n",
    "        if profile_row.empty:\n",
    "            continue\n",
    "        profile = profile_row.iloc[0]\n",
    "\n",
    "        similar_companies = []\n",
    "\n",
    "        # 1ìˆœìœ„: ì‚°ì—… + ê·œëª¨\n",
    "        if profile['ê·œëª¨'] != 'Unknown':\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile[INDUSTRY_COL] == profile[INDUSTRY_COL]) &\n",
    "                (company_profile['ê·œëª¨'] == profile['ê·œëª¨']) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        # 2ìˆœìœ„: ì‚°ì—…ë§Œ\n",
    "        if len(similar_companies) < 3:\n",
    "            similar_companies = company_profile[\n",
    "                (company_profile[INDUSTRY_COL] == profile[INDUSTRY_COL]) &\n",
    "                (company_profile[COMPANY_COL] != company)\n",
    "            ][COMPANY_COL].tolist()\n",
    "\n",
    "        similar_data = df[\n",
    "            (df[COMPANY_COL].isin(similar_companies)) &\n",
    "            (df[YEAR_COL] == year)\n",
    "        ]\n",
    "\n",
    "        used_companies = similar_data[\n",
    "            similar_data[FINANCIAL_COLS].notnull().any(axis=1)\n",
    "        ][COMPANY_COL].unique()\n",
    "\n",
    "        for col in FINANCIAL_COLS:\n",
    "            if pd.isnull(row[col]) and similar_data[col].dropna().shape[0] >= 3:\n",
    "                df_imputed.at[idx, col] = similar_data[col].median()\n",
    "                df_imputed.at[idx, 'impute_method'] = 'median_group'\n",
    "                df_imputed.at[idx, 'impute_source_companies'] = ', '.join(used_companies)\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 4ë‹¨ê³„: KNN Imputation + ì¶”ì \n",
    "# ========================================\n",
    "def knn_impute_by_industry_year(df, n_neighbors=5):\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    for (industry, year), group in df.groupby([INDUSTRY_COL, YEAR_COL]):\n",
    "        idxs = group.index\n",
    "        data = group[FINANCIAL_COLS]\n",
    "\n",
    "        if len(group) <= n_neighbors:\n",
    "            continue\n",
    "\n",
    "        for idx in idxs:\n",
    "            row = data.loc[idx]\n",
    "            if not row.isnull().any():\n",
    "                continue\n",
    "\n",
    "            valid = data.dropna()\n",
    "            if len(valid) < 2:\n",
    "                continue\n",
    "\n",
    "            distances = nan_euclidean_distances(\n",
    "                row.values.reshape(1, -1),\n",
    "                valid.values\n",
    "            )[0]\n",
    "\n",
    "            k = min(n_neighbors, len(valid))\n",
    "            nearest_idx = valid.index[np.argsort(distances)[:k]]\n",
    "            source_companies = df.loc[nearest_idx, COMPANY_COL].tolist()\n",
    "\n",
    "            for col in FINANCIAL_COLS:\n",
    "                if pd.isnull(df_imputed.at[idx, col]):\n",
    "                    df_imputed.at[idx, col] = valid.loc[nearest_idx, col].mean()\n",
    "                    df_imputed.at[idx, 'impute_method'] = 'knn'\n",
    "                    df_imputed.at[idx, 'impute_source_companies'] = ', '.join(source_companies)\n",
    "                    df_imputed.at[idx, 'impute_k'] = k\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 5ë‹¨ê³„: í†µí•© ì‹¤í–‰\n",
    "# ========================================\n",
    "def hybrid_imputation(df):\n",
    "    df_result = ensure_numeric_financial_cols(df)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ì´ˆê¸° ê²°ì¸¡ì¹˜: {df_result[FINANCIAL_COLS].isnull().sum().sum()}ê°œ\\n\")\n",
    "\n",
    "    company_profile = create_company_profile(df_result)\n",
    "\n",
    "    print(\"[Step 1] ì¤‘ì•™ê°’ ê¸°ë°˜ ë³´ì™„ ì¤‘...\")\n",
    "    df_result = impute_by_similar_companies(df_result, company_profile)\n",
    "    remaining = df_result[FINANCIAL_COLS].isnull().sum().sum()\n",
    "    print(f\"âœ“ ë‚¨ì€ ê²°ì¸¡ì¹˜: {remaining}ê°œ\")\n",
    "\n",
    "    if remaining > 0:\n",
    "        print(\"[Step 2] KNN ê¸°ë°˜ ë³´ì™„ ì¤‘...\")\n",
    "        df_result = knn_impute_by_industry_year(df_result)\n",
    "        remaining = df_result[FINANCIAL_COLS].isnull().sum().sum()\n",
    "        print(f\"âœ“ ë‚¨ì€ ê²°ì¸¡ì¹˜: {remaining}ê°œ\")\n",
    "\n",
    "    print(\"ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    return df_result, company_profile\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# 6ë‹¨ê³„: ì‹¤í–‰\n",
    "# ========================================\n",
    "df_final, company_profile = hybrid_imputation(jemu_df)\n",
    "\n",
    "print(\"\\n[ë³€ìˆ˜ë³„ ë‚¨ì€ ê²°ì¸¡ì¹˜]\")\n",
    "print(df_final[FINANCIAL_COLS].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"../../output/jemu_df_imputed_fields_ver2.csv\", index=False, encoding=\"cp949\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
